\documentclass[11pt,a4paper,english]{article}
%\usepackage[finnish]{babel}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{listings}

\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

 % Normal latex T1-fonts
\usepackage[T1]{fontenc}
 % For the pdf-conversion. Remember -Ppdf for latex!
%\usepackage[T1,mtbold,lucidacal,mtplusscr,subscriptcorrection]{mathtime}
%\usepackage{times}

 % Figures
\usepackage{graphicx,fancybox,subfigure}

 % AMS-stuff
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsbsy}

 % Misc
\usepackage{verbatim}
\usepackage{url}

% Page size
\addtolength{\hoffset}{-1cm}
\addtolength{\textwidth}{2cm}
\addtolength{\voffset}{-1cm}
\addtolength{\textheight}{2cm}

% Paragraph
\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}

% Horizontal line
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

% No page numbers
\pagestyle{empty}

% New commands:
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}


\begin{document}
\SweaveOpts{concordance=TRUE}
% \SweaveOpts{concordance=TRUE}

\section*{Bayesian Data Analysis - Assignment 4}



\HRule

\input{general_info.tex}

% General Knitr options
% (this cannot be input since the file runs knitr before LaTeX)
<<echo=FALSE,eval=TRUE>>=
options(continue="  ", prompt="> ")
knitr::opts_chunk$set(size = "small")
@



\newpage

\subsubsection*{Information on this assignment}

This assignment is related to Chapters 3 and 10. The maximum amount of points from this assignment is 6.


\textbf{Reading instructions:} Chapters 3 and 10 in BDA3, see reading instructions \href{https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes_ch3.pdf}{\textbf{here}} and \href{https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes_ch10.pdf}{\textbf{here}}

\textbf{Grading instructions:} The grading will be done in peergrade. All grading questions and evaluations for assignment 4 can be found \href{https://avehtari.github.io/BDA_course_Aalto/assignments/assignment4_rubric.md}{\textbf{here}}

\textbf{Reporting accuracy:} For posterior statistics of interest, only report digits for which the Monte Carlo standard error (MCSE) is zero. \emph{Example:} If you estimate $E(\mu)=1.234$ with MCSE($E(\mu)$) = 0.01, you should report $E(\mu)=1.2$.

To use markmyassignment for this assignment, run the following code in R:

<<echo=TRUE,eval=FALSE>>=
library(markmyassignment)
assignment_path <-
  paste("https://github.com/avehtari/BDA_course_Aalto/",
        "blob/master/assignments/tests/assignment4.yml", sep="")
set_assignment(assignment_path)
# To check your code/functions, just run
mark_my_assignment()
@


\HRule

\newpage

{\bf Bioassay model}. In this exercise, you will use a dose-response relation model that is used in Section 3.7 of the course book and in the chapter reading instructions \href{https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes_ch3.pdf}{\textbf{here}}. The used likelihood is the same, but instead of uniform priors,
we will use a bivariate normal distribution as the joint prior distribution of the parameters $\alpha$ and $\beta$.


\begin{itemize}
    \item[a)] In the prior distribution for $(\alpha,\beta)$, the marginal distributions are $\alpha \sim N(0,2^2)$ and $\beta \sim N(10,10^2)$, and the correlation between them is $\mathrm{corr}(\alpha, \beta)=0.6$. Report the mean (vector of two values) and covariance (two by two matrix) of the bivariate normal distribution.
\begin{itemize}
\item \textbf{Hint!} The mean and covariance of the bivariate normal distribution are a length--$2$ vector and a $2 \times 2$ matrix. The elements of the covariance matrix can be computed using the relation of correlation and covariance.
\end{itemize}
\item[b)] You are given 4000 independent draws from the posterior distribution
of the model. Load the draws with \texttt{ data("bioassay\_posterior")}. Report the mean as well as 5 $\%$ and 95 $\%$
quantiles separately for both $\alpha$ and $\beta$. Report also the
Monte Carlo standard errors (MCSEs) for the mean and quantile estimates.
Report as many digits for the mean and
quantiles as the MCSEs allow. In other words, leave out digits where
MCSE is nonzero (Example: if posterior mean is 2.345678 and MCSE is 0.0012345, report two digits after the decimal sign, taking into account the usual rounding rule, so you would report 2.35. Further digits do not contain useful information due to the Monte Carlo uncertainty.). Explain in words what does Monte Carlo standard error mean and how you decided the number of digits to show.
\begin{itemize}
\item \textbf{Note!} The answer is graded as correct only if the number of digits
reported is correct! The number of significant digits can be different for the mean
and quantile estimates.  In some other cases, the number of digits reported can be less than MCSE allows for practical reasons.
\item \textbf{Hint!} Quantiles can be computed with the \texttt{quantile} function. With $S$ draws, the MCSE for $\text{E}[\theta]$ is $\sqrt{\text{Var} [\theta]/S}$.
MCSE for the quantile estimates can be computed with the
\texttt{mcse\_quantile} function from the {\tt aaltobda} package.
\end{itemize}

\end{itemize}
{\bf Importance sampling}. Now we discard our posterior draws and
switch to importance sampling.




\begin{itemize}
\item[c)] Implement a function for computing the log importance ratios (log importance weights) when the importance sampling \textbf{target distribution} is the posterior distribution, and the \textbf{proposal distribution} is the prior distribution from a). Below is a test example, the functions can also be tested with \texttt{markmyassignment}. Explain in words why it's better to compute log ratios instead of ratios.
% \textbf{Note!} The values below are \emph{only} a test case, you need to use 4000 draws for {\tt alpha} and {\tt beta} in the final report. \\
\begin{itemize}
\item \textbf{Note!} The values below are \emph{only} a test case. In this c) part, you
only need to report the source code of your function, as it will be needed in
later parts.
\item \textbf{Hints!} Use the function {\tt rmvnorm} from the {\tt aaltobda} package for sampling. Non-log importance ratios are given by equation (10.3) in the course book. The fact that our proposal distribution is the same as
the prior distribution makes this task easier. The \textbf{logarithm} of the likelihood can be computed with the {\tt bioassaylp} function from the {\tt aaltobda} package. The data required for the likelihood can be loaded with {\tt data("bioassay")}.
\end{itemize}
<<echo=FALSE>>=
log_importance_weights <- function(alpha, beta) c(-8.95, -23.47, -6.02, -8.13, -16.61, -14.57)
normalized_importance_weights <- function(alpha, beta) c(0.045, 0.000, 0.852, 0.103, 0.000, 0.000)
posterior_mean <- function(alpha, beta) c(0.503, 8.275)
S_eff <- function(alpha, beta) 1.354
@
<<echo=TRUE>>=
alpha <- c(1.896, -3.6,  0.374, 0.964, -3.123, -1.581)
beta <- c(24.76, 20.04, 6.15, 18.65, 8.16, 17.4)
round(log_importance_weights(alpha, beta),2)
@
\item[d)] Implement a function for computing normalized importance ratios
from the unnormalized log ratios in c). In other words, exponentiate
the log ratios and scale them such that they sum to one. Explain in words what is the effect of exponentiating and scaling so that sum is one. Below is a test example, the functions can also be tested with \texttt{markmyassignment}.
\begin{itemize}
\item \textbf{Note!} The values below are \emph{only} a test case. In this d) part, you
only need to report the source code of your function, as it will be needed in
later parts.\\
\end{itemize}
<<echo=TRUE>>=
alpha
beta
round(normalized_importance_weights(alpha = alpha, beta = beta),3)
@
\item[e)] Sample 4000 draws of $\alpha$ and $\beta$ from the prior distribution from a). Compute and plot a histogram of the 4000 normalized importance ratios.
Use the functions you implemented in c) and d).
\item[f)] Using the importance ratios, compute the importance sampling effective sample size $S_{\text{eff}}$ and report it. 
\begin{itemize}
\item \textbf{Note!} The values below are \emph{only} a test case, you need to use 4000 draws for {\tt alpha} and {\tt beta} in the final report.
\end{itemize}
<<echo=TRUE>>=
alpha
beta
round(S_eff(alpha = alpha, beta = beta),3)
@
\begin{itemize}
\item \textbf{Hint!} Equation (10.4) in the course book.
\item \textbf{Note!} {\it BDA3 1st (2013) and 2nd (2014) printing have an error
   for $\tilde{w}(\theta^s)$ used in the effective sample size
   equation (10.4). The normalized weights equation should not have the
   multiplier S (the normalized weights should sum to one). Errata for
   the book
   \url{http://www.stat.columbia.edu/~gelman/book/errata_bda3.txt}.
   The later printings and slides have the correct equation.}
 \end{itemize}
  \item[g)] Explain in your own words what the importance sampling effective
 sample size represents. Also explain how the effective sample size is seen
 in the histogram of the weights that you plotted in e).
 \item[h)] Implement a function for computing the posterior mean using importance sampling, and compute the mean using your 4000 draws. Explain in your own words the computation for importance sampling. Below is an example how the function would work with the example values for {\tt alpha} and {\tt beta} above.
 Report the means for alpha and beta, and also the Monte Carlo standard errors (MCSEs) for the mean estimates.
 Report the number of digits for the means based on the MCSEs.
\begin{itemize}
 \item \textbf{Note!} The values below are \emph{only} a test case, you need to use 4000 draws for {\tt alpha} and {\tt beta} in the final report.
 \item \textbf{Hint!} Use the same equation for the MCSE of $\text{E}[\theta]$ as earlier ($\sqrt{\text{Var} [\theta]/S}$), but now replace $S$ with $S_{\text{eff}}$. To compute $\text{Var} [\theta]$ with importance sampling, use the identity
$\text{Var}[\theta] = \text{E}[\theta^2] - \text{E}[\theta]^2$.
 \end{itemize}
<<echo=TRUE>>=
alpha
beta
round(posterior_mean(alpha = alpha, beta = beta),3)
@
 % \item[i)] Based on how the Monte Carlo standard error (MCSE)
 % for the mean in b)
 % depends on the sample size, how many times larger or smaller do you think the
 % MCSE is now when we used importance sampling for computing the mean? You don't
 % need to calculate the MCSE again, just compare the effective sample
 % size to the true sample size.

\end{itemize}




\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
