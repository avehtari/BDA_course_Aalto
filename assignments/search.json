[
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "The exercises here refer to the lecture 1/BDA chapter 1 content, not the course infrastructure quiz. This assignment is meant to test whether or not you have sufficient knowledge to participate in the course. The first question checks that you remember basic terms of probability calculus. The second exercise checks you recognise the most important notation used throughout the course and used in BDA3. The third-fifth exercise you will solve some basic Bayes theorem questions to check your understanding on the basics of probability theory. The 6th exercise checks on whether you recall the three steps of Bayesian Data Ananlysis as mentioned in chapter 1 of BDA3. The last exercise walks you through an example of how we can use models to generate distributions for outcomes of interest, applied to a setting of a simplified Roulette table.\nThe exercises constitute 86% of the Quiz 1 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a qmd file,\nas a rendered html file\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n    \n        \n        \n        \n    \n    \n\n\n        Match the following terms with the correct definition:\nNote that the answers order and set of possible answers is the same for questions 1.1 - 1.8. Check the BDA chapter 1, the lecture slides, and Wikipedia if you are uncertain about the terms below. \n\n\n\n    \n        1.1 Probability:\n            \n        1.2 Probability mass (function): \n        1.3 Probability density (function):\n        1.4 Probability distribution: \n        1.5 Discrete probability distribution: \n        1.6 Continuous probability distribution: \n        1.7 Cumulative distribution function (cdf): \n        1.8 Likelihood:\n            \n    \n    \n    \n    \n        \n            \n        \n        \n    \n    \n            Match the following notation with the correct definition: \n    \n    \n        2.1 \\( \\sim \\):  \n        2.2 \\( \\propto \\):  \n        2.3 \\( \\text{E}[\\cdot] \\):  \n        2.4 \\( p(y | \\theta) \\): \n    \n\n    \n    \n    \n    A group of researchers has designed a new inexpensive and painless test\n        for detecting lung cancer. The test is intended to be an initial\n        screening test for the population in general. A positive result\n        (presence of lung cancer) from the test would be followed up immediately\n        with medication, surgery or more extensive and expensive test. \n    The\n        researchers know from their studies the following facts:\n    \n        Test gives a positive result in 98%  of the time when the test subject has lung cancer.\n        Test gives a negative result in  96% of the time when the test subject does not have lung cancer.\n        In general population approximately one person in 1000 has lung cancer.\n    \n    Here are some probability values that can help you figure out if you\n        copied the right conditional probabilities from the question:\n    \n        P(Test gives positive | Subject does not have lung cancer) = 4%\n        P(Test gives positive and Subject has lung cancer) = 0.098%\n            \n                \n                    this is also referred to as the joint probability of test being positive and the subject having lung cancer\n                \n            \n        \n    \n    Your goal is calculate the probability of having cancer given a positive test result: \\( P(\\text{cancer} | \\text{positive}) \\)\n    \n        3.1 Which quantity in Bayes' Theorem does this represent? \n        3.2 What is the probability of the test having a positive result, given that the test subject has cancer (P(B|A))? \n        3.3 What is the probability of having cancer (P(A))? \n        3.4 What is the probability of having a positive test (P(B))? \n        3.5 Using your previous answers, what is the probability of having cancer given a positive test?\n    \n    \n    \n    \n    We have three boxes, A, B, and C. There are\n    \n        2 red balls and 5 white balls in the box A\n        4 red balls and 1 white ball in the box B\n        1 red ball and 3 white balls in the box C.\n    \n    Consider a random experiment in which one of the boxes is randomly\n        selected and from that box, one ball is randomly picked up. After\n        observing the color of the ball it is replaced in the box it came from.\n        Suppose also that on average box A is selected 40% of the time and box B\n        10% of the time (i.e. P(A) = 0.4).\n    \n    \n        4.1 What is the probability of picking a red ball from box A? \n        4.2 What is the probability of picking a red ball from box B? \n        4.3 What is the probability of picking a red ball from box C? \n        4.4 Considering the probabilities of selecting each box, what is the probability of picking a red ball (enter as a number between 0 and 1 with 2 decimal digit accuracy)?\n        \n            4.5 If a red ball was picked, calculate the probability that it was picked from (enter as a number between 0 and 1 with 2 decimal digit accuracy):\n            \n                Box A:  \n                Box B:  \n                Box C:  \n            \n        \n    \n    \n    \n    \n    5.1 Select the three steps of Bayesian data analysis (see BDA3 p. 3): \n\n\n\n    \n    In this course, models are used to explain social and physical data, and we will be able to generate data from our models which we can use for checking how well our model does. In this example, we show how to generate outcomes from a binomial model to explain outcomes of a roulette game (there is a connection to the history of statistics). Suppose a roulette table with only red and black colours. Roulette tables won't be perfect and it's likely that the probability of red vs black is not exactly 0.5 (the tables can have adjustments that are randomized each day to avoid long term bias). \n    Suppose your model for the tables' ratio of red/black is a Binomial which takes as inputs the number of trials and a probability parameter, theta. Set theta to 0.6 (this is much bigger than what we would expect in real roulette, but makes it easier as a teaching example) and generate a series (for a sequence of 100 equally spaced trial values between 10 and 1000) of red/black ratios. Generate 1000 random draws from your model for each trial value and save the data in a Data frame with columns Ratios, Nsims and Trials. Incomplete code can be found below.\n    \n    # load the tidyverse package for data manipulation and plottinglibrary(tidyverse)# Ratio of red/black\ntheta &lt;- # declare probability parameter for the binomial model\n\n# Sequence of trials\ntrials &lt;- seq(#start value of sequence,#end value of sequence,#value for spacing)\n\n# Number of simulation draws from the model\nnsims &lt;- # number of of simulations from the binomial model\n\n# Helper function for getting the ratios\nbinom_gen &lt;- function(trials,theta,nsims){\n    df &lt;-  as.data.frame(rbinom(nsims,trials,theta)/trials) |&gt; mutate(nsims = nsims,trials = trials)\n    colnames(df) &lt;- c(\"Ratios\",\"Nsims\",\"Trials\")\n  return(df)\n}\n\n# Create a data frame containing the draws for each number of trials\nratio_60 &lt;- do.call(rbind, lapply(trials, binom_gen, theta, nsims)) # lapply applies elements in trials column to binom_gen function, which is then rowbound via do.call\n    \n    \n        6.1 Suppose you are unsure whether the code to create the data frame worked. Which of the following functions should you use in order to check on the structure of the dataframe object (assuming df below stands for a generic dataframe object)?\n        6.2 The structure checks out, but now you want to print the first 5 rows of the dataframe to check whether the values are as expected. Which of the following functions should you use?\n        6.3 The quick peek checks also out, but you would be more at ease scrolling all data, perhaps you'll find some interesting patterns. Which of the following actions allows you to scroll through the data in a separate window (for the below, we assume that you have the code loaded in an RStudio session)?\n    \n    \n    \n    \n    Now, plot a histogram of the computed ratios for 10, 50 and 1000 trials, using the code below\n    # Plot the Distributions\nsubset_df &lt;- ratio_60[ratio_60$Trials %in% c(#trial values), ] # Subset your \n\nsubset_df |&gt; ggplot(aes(Ratios)) +\n  geom_histogram(position = \"identity\" ,bins = 40) +\n  facet_grid(cols = vars(Trials))  +\n  ggtitle(\"Ratios for specific trials\")\n    \n    \n    \n        6.4 Which histogram below is the correct one for theta = 0.6?\n        6.5 What do these distributions refer to?\n        6.6 Given these histograms, which number of trials gives you the most certainty about the likely red/black ratio for that table?\n        6.7 Given the draws from the model, give an estimate about the probability p(Ratio&lt;=0.5) for the model with 1000 trials (enter as a number between 0 and 1 with 2 decimal digit accuracy). \n    \n    Suppose you are now certain that theta = 0.6, plot the probability density given 1000 trials using the code below.\n\nsize =  # number of trials\nprob =  # probability of success\n\nbinom_data &lt;- data.frame(\n  Success = 0:size,\n  Probability = dbinom(0:size, size = size, prob = prob)\n)\n\nggplot(binom_data, aes(x = Success, y = Probability)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"PMF of Binomial Distribution\", x = \"Number of Successes\", y = \"PDF\")\n\n\n\n\n    \n        6.8 Which plot of the PMF is the correct one?\n        6.9 How does the PMF plot relate to the histogram of ratios plotted earlier?\n        6.10 Given the PMF for your model, calculate the probability for 1000 trials of observing less or equal to 500 red outcomes using theta = 0.6. Use the pbinom function in R. \n    \n    Click to next page",
    "crumbs": [
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignment1.html#assignment-questions",
    "href": "assignment1.html#assignment-questions",
    "title": "Assignment 1",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n    \n        \n        \n        \n    \n    \n\n\n        Match the following terms with the correct definition:\nNote that the answers order and set of possible answers is the same for questions 1.1 - 1.8. Check the BDA chapter 1, the lecture slides, and Wikipedia if you are uncertain about the terms below. \n\n\n\n    \n        1.1 Probability:\n            \n        1.2 Probability mass (function): \n        1.3 Probability density (function):\n        1.4 Probability distribution: \n        1.5 Discrete probability distribution: \n        1.6 Continuous probability distribution: \n        1.7 Cumulative distribution function (cdf): \n        1.8 Likelihood:\n            \n    \n    \n    \n    \n        \n            \n        \n        \n    \n    \n            Match the following notation with the correct definition: \n    \n    \n        2.1 \\( \\sim \\):  \n        2.2 \\( \\propto \\):  \n        2.3 \\( \\text{E}[\\cdot] \\):  \n        2.4 \\( p(y | \\theta) \\): \n    \n\n    \n    \n    \n    A group of researchers has designed a new inexpensive and painless test\n        for detecting lung cancer. The test is intended to be an initial\n        screening test for the population in general. A positive result\n        (presence of lung cancer) from the test would be followed up immediately\n        with medication, surgery or more extensive and expensive test. \n    The\n        researchers know from their studies the following facts:\n    \n        Test gives a positive result in 98%  of the time when the test subject has lung cancer.\n        Test gives a negative result in  96% of the time when the test subject does not have lung cancer.\n        In general population approximately one person in 1000 has lung cancer.\n    \n    Here are some probability values that can help you figure out if you\n        copied the right conditional probabilities from the question:\n    \n        P(Test gives positive | Subject does not have lung cancer) = 4%\n        P(Test gives positive and Subject has lung cancer) = 0.098%\n            \n                \n                    this is also referred to as the joint probability of test being positive and the subject having lung cancer\n                \n            \n        \n    \n    Your goal is calculate the probability of having cancer given a positive test result: \\( P(\\text{cancer} | \\text{positive}) \\)\n    \n        3.1 Which quantity in Bayes' Theorem does this represent? \n        3.2 What is the probability of the test having a positive result, given that the test subject has cancer (P(B|A))? \n        3.3 What is the probability of having cancer (P(A))? \n        3.4 What is the probability of having a positive test (P(B))? \n        3.5 Using your previous answers, what is the probability of having cancer given a positive test?\n    \n    \n    \n    \n    We have three boxes, A, B, and C. There are\n    \n        2 red balls and 5 white balls in the box A\n        4 red balls and 1 white ball in the box B\n        1 red ball and 3 white balls in the box C.\n    \n    Consider a random experiment in which one of the boxes is randomly\n        selected and from that box, one ball is randomly picked up. After\n        observing the color of the ball it is replaced in the box it came from.\n        Suppose also that on average box A is selected 40% of the time and box B\n        10% of the time (i.e. P(A) = 0.4).\n    \n    \n        4.1 What is the probability of picking a red ball from box A? \n        4.2 What is the probability of picking a red ball from box B? \n        4.3 What is the probability of picking a red ball from box C? \n        4.4 Considering the probabilities of selecting each box, what is the probability of picking a red ball (enter as a number between 0 and 1 with 2 decimal digit accuracy)?\n        \n            4.5 If a red ball was picked, calculate the probability that it was picked from (enter as a number between 0 and 1 with 2 decimal digit accuracy):\n            \n                Box A:  \n                Box B:  \n                Box C:  \n            \n        \n    \n    \n    \n    \n    5.1 Select the three steps of Bayesian data analysis (see BDA3 p. 3): \n\n\n\n    \n    In this course, models are used to explain social and physical data, and we will be able to generate data from our models which we can use for checking how well our model does. In this example, we show how to generate outcomes from a binomial model to explain outcomes of a roulette game (there is a connection to the history of statistics). Suppose a roulette table with only red and black colours. Roulette tables won't be perfect and it's likely that the probability of red vs black is not exactly 0.5 (the tables can have adjustments that are randomized each day to avoid long term bias). \n    Suppose your model for the tables' ratio of red/black is a Binomial which takes as inputs the number of trials and a probability parameter, theta. Set theta to 0.6 (this is much bigger than what we would expect in real roulette, but makes it easier as a teaching example) and generate a series (for a sequence of 100 equally spaced trial values between 10 and 1000) of red/black ratios. Generate 1000 random draws from your model for each trial value and save the data in a Data frame with columns Ratios, Nsims and Trials. Incomplete code can be found below.\n    \n    # load the tidyverse package for data manipulation and plottinglibrary(tidyverse)# Ratio of red/black\ntheta &lt;- # declare probability parameter for the binomial model\n\n# Sequence of trials\ntrials &lt;- seq(#start value of sequence,#end value of sequence,#value for spacing)\n\n# Number of simulation draws from the model\nnsims &lt;- # number of of simulations from the binomial model\n\n# Helper function for getting the ratios\nbinom_gen &lt;- function(trials,theta,nsims){\n    df &lt;-  as.data.frame(rbinom(nsims,trials,theta)/trials) |&gt; mutate(nsims = nsims,trials = trials)\n    colnames(df) &lt;- c(\"Ratios\",\"Nsims\",\"Trials\")\n  return(df)\n}\n\n# Create a data frame containing the draws for each number of trials\nratio_60 &lt;- do.call(rbind, lapply(trials, binom_gen, theta, nsims)) # lapply applies elements in trials column to binom_gen function, which is then rowbound via do.call\n    \n    \n        6.1 Suppose you are unsure whether the code to create the data frame worked. Which of the following functions should you use in order to check on the structure of the dataframe object (assuming df below stands for a generic dataframe object)?\n        6.2 The structure checks out, but now you want to print the first 5 rows of the dataframe to check whether the values are as expected. Which of the following functions should you use?\n        6.3 The quick peek checks also out, but you would be more at ease scrolling all data, perhaps you'll find some interesting patterns. Which of the following actions allows you to scroll through the data in a separate window (for the below, we assume that you have the code loaded in an RStudio session)?\n    \n    \n    \n    \n    Now, plot a histogram of the computed ratios for 10, 50 and 1000 trials, using the code below\n    # Plot the Distributions\nsubset_df &lt;- ratio_60[ratio_60$Trials %in% c(#trial values), ] # Subset your \n\nsubset_df |&gt; ggplot(aes(Ratios)) +\n  geom_histogram(position = \"identity\" ,bins = 40) +\n  facet_grid(cols = vars(Trials))  +\n  ggtitle(\"Ratios for specific trials\")\n    \n    \n    \n        6.4 Which histogram below is the correct one for theta = 0.6?\n        6.5 What do these distributions refer to?\n        6.6 Given these histograms, which number of trials gives you the most certainty about the likely red/black ratio for that table?\n        6.7 Given the draws from the model, give an estimate about the probability p(Ratio&lt;=0.5) for the model with 1000 trials (enter as a number between 0 and 1 with 2 decimal digit accuracy). \n    \n    Suppose you are now certain that theta = 0.6, plot the probability density given 1000 trials using the code below.\n\nsize =  # number of trials\nprob =  # probability of success\n\nbinom_data &lt;- data.frame(\n  Success = 0:size,\n  Probability = dbinom(0:size, size = size, prob = prob)\n)\n\nggplot(binom_data, aes(x = Success, y = Probability)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"PMF of Binomial Distribution\", x = \"Number of Successes\", y = \"PDF\")\n\n\n\n\n    \n        6.8 Which plot of the PMF is the correct one?\n        6.9 How does the PMF plot relate to the histogram of ratios plotted earlier?\n        6.10 Given the PMF for your model, calculate the probability for 1000 trials of observing less or equal to 500 red outcomes using theta = 0.6. Use the pbinom function in R. \n    \n    Click to next page",
    "crumbs": [
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "template2.html",
    "href": "template2.html",
    "title": "Notebook for Assignment 2",
    "section": "",
    "text": "1 General information\nThis assignment is related to Lecture 2 and BDA3 Chapters 1 and 2. You may find an additional discussion about choosing priors in a blog post by Andrew Gelman.\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 1.\nThe reading instructions for BDA3 Chapter 2.\n\n\n\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following installs the aaltobda package:\n#| cache: true\n# Caching should be fine here\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\n\n\n\n\n2 Inference for binomial proportion\nAlgae status is monitored in 274 sites at Finnish lakes and rivers. The observations for the 2008 algae status at each site are presented in the dataset algae in the aaltobda package (‘0’: no algae, ‘1’: algae present).\nLoading the library and the data.\n\nlibrary(aaltobda)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(latex2exp)\ndata(\"algae\")\n# The data are now stored in the variable `algae`.\n# These are the values for the prior required in the assignment\nprior_alpha = 2\nprior_beta = 10\n\nLet \\(\\pi\\) be the probability of a monitoring site having detectable blue-green algae levels and \\(y\\) the observations in algae. Use a binomial model for the observations \\(y\\) and a \\(Beta(2,10)\\) prior for binomial model parameter \\(\\pi\\) to formulate a Bayesian model. Here it is not necessary to derive the posterior distribution for \\(\\pi\\) as it has already been done in the book and it suffices to refer to that derivation. Also, it is not necessary to write out the distributions; it is sufficient to use label-parameter format, e.g. \\(Beta(\\alpha,\\beta)\\).\nYour task is to perform Bayesian inference for a binomial model and answer questions based on it.\n\n\n3 Formulating probabilities\n\n\n4 Summary of the posterior distribution of \\(\\theta\\)\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful function: qbeta()\n\nbeta_point_est &lt;- function(prior_alpha, prior_beta, data) {\n    # Do computation here, and return as below.\n    \n}\nbeta_interval &lt;- function(prior_alpha, prior_beta, data, prob=0.9) {\n    # Do computation here, and return as below.\n\n\n}\n\n\n\n5 Comparison to historical records\nKeep the below name and format for the function to work with markmyassignment:\n\n# Useful function: pbeta()\n\nbeta_low &lt;- function(prior_alpha, prior_beta, data, pi_0=0.2) {\n    # Do computation here, and return as below.\n\n}\n\n\n\n6 Prior sensitivity analysis\nMake prior sensitivity analysis by testing a couple of different reasonable priors and plot the different posteriors. Try to summarise the results by one or two sentences.\n# Useful function: dbeta()\nAmend the code below to help you.\n\n# Beta distribution density function\nbeta_density &lt;- function(x, shape1, shape2) {\n  dbeta(x, shape1, shape2)\n}\n\n# Binomial likelihood density function\nbinomial_likelihood &lt;- function(x, n, k) {\n  choose(n, k) * x^k * (1 - x)^(n - k)\n}\n\n# Parameters for the Beta prior distributions\npriors &lt;- list(c(#alpha, #beta), c(#alpha, #beta), c(#alpha, #beta)) # Define three different priors here priors, (alpha, beta)\n\n# Parameters for the binomial likelihood (number of trials and successes)\nn &lt;-  # number of trials\nk &lt;-  # number of successes\n\n# Create a sequence of x values from 0 to 1\nx &lt;- seq(0, 1, length.out = 100)\n\n\n# Create a data frame with densities\ndensities_list &lt;- lapply(priors, function(prior) {\n  alpha_prior &lt;- prior[1]\n  beta_prior &lt;- prior[2]\n  alpha_posterior &lt;- alpha_prior + k\n  beta_posterior &lt;- beta_prior + n - k\n  \n  data.frame(\n    x = rep(x, 2),\n    density = c(beta_density(x, alpha_prior, beta_prior),\n                beta_density(x, alpha_posterior, beta_posterior)),\n    distribution = factor(rep(c(\"Prior\", \"Posterior\"), each = length(x))),\n    prior = paste(\"Prior: Alpha =\", alpha_prior, \"Beta =\", beta_prior)\n  )\n})\n\ndf &lt;- bind_rows(densities_list)\n\n# Plot the densities using ggplot2\nggplot(df, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  facet_wrap(~ prior, scales = \"fixed\", nrow = 3) +\n  labs(title = \"Prior and Posterior Densities for Different Priors\", \n       x = TeX(\"$\\\\theta$\"), \n       y = \"Density\", \n       color = \"Distribution\") +\n  theme_minimal()",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 2"
    ]
  },
  {
    "objectID": "template1.html",
    "href": "template1.html",
    "title": "Notebook for Assignment 1",
    "section": "",
    "text": "1 General information\nThe exercises here refer to the lecture 1/BDA chapter 1 content, not the course infrastructure quiz. This assignment is meant to test whether or not you have sufficient knowledge to participate in the course. The first question checks that you remember basic terms of probability calculus. The second exercise checks you recognise the most important notation used throughout the course and used in BDA3. The third-fifth exercise you will solve some basic Bayes theorem questions to check your understanding on the basics of probability theory. The 6th exercise checks on whether you recall the three steps of Bayesian Data Ananlysis as mentioned in chapter 1 of BDA3. The last exercise walks you through an example of how we can use models to generate distributions for outcomes of interest, applied to a setting of a simplified Roulette table.\nThis quarto document is not intended to be submitted, but to render the questions as they appear on Mycourses to be available also outside of it. The following will set-up markmyassignment to check your functions at the end of the notebook:\n\nlibrary(markmyassignment)\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/tests/assignment1.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nAssignment set:\nassignment1: Bayesian Data Analysis: Assignment 1\nThe assignment contain the following (3) tasks:\n- p_red\n- p_box\n- p_identical_twin\n\n\n\n\n2 1. Basic probability theory notation and terms\n\n\n3 2. Notation\n\n\n4 3. Bayes’ theorem 1\nIf you use pen and paper, it may help to draw pictures as follows (see also assignment_instructions#fig-workflow):\n\n\n\n\n\n\nFigure 1: Parts of Bayesian workflow\n\n\n\nSee Figure 1 for illustration of parts of Bayesian workflow.\n\n\n5 4. Bayes’ theorem 2\nThe following will help you implementing a function to calculate the required probabilities for this exercise. Keep the below name and format for the function to work with markmyassignment:\n\nboxes_test &lt;- matrix(c(2,2,1,5,5,1), ncol = 2,\n    dimnames = list(c(\"A\", \"B\", \"C\"), c(\"red\", \"white\")))\n\np_red &lt;- function(boxes) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    0.3928571\n}\n\np_box &lt;- function(boxes) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.29090909,0.07272727,0.63636364)\n}\n\n\n\n6 5. Bayes’ theorem 3\nThe R functions below might help you calculating the requited probabilities.\n\nfraternal_prob = 1/125\nidentical_prob = 1/300\n\nKeep the below name and format for the function to work with markmyassignment:\n\np_identical_twin &lt;- function(fraternal_prob, identical_prob) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    0.4545455\n}\n\n\n\n7 6. The three steps of Bayesian data analysis\n\n\n8 7. A Binomial Model for the Roulette Table\nIncomplete code can be found below.\n\n# Ratio of red/black\ntheta &lt;- # declare probability parameter for the binomial model\n\n# Sequence of trials\n\ntrials &lt;- seq(#start value of sequence,#end value of sequence,#value for spacing)\n\n# Number of simulation draws from the model\nnsims &lt;- # number of of simulations from the binomial model\n\n# Helper function for getting the ratios\nbinom_gen &lt;- function(trials,theta,nsims){\n    df &lt;-  as.data.frame(rbinom(nsims,trials,theta)/trials) |&gt; mutate(nsims = nsims,trials = trials)\n    colnames(df) &lt;- c(\"Ratios\",\"Nsims\",\"Trials\")\n  return(df)\n}\n\n# Create a data frame containing the draws for each number of trials\nratio_60 &lt;- do.call(rbind, lapply(trials, binom_gen, theta, nsims)) # lapply applies elements in trials column to binom_gen function, which is then rowbound via do.call\n\nNow plot a histogram of the computed ratios for 10, 50 and 1000 trials, using the code below\n\n# Plot the Distributions\nsubset_df60 &lt;- ratio_60[ratio_60$Trials %in% c(#trial values), ] # Subset your dataframe\n\nsubset_df60 |&gt; ggplot(aes(Ratios)) +\n  geom_histogram(position = \"identity\" ,bins = 40) +\n  facet_grid(cols = vars(Trials))  +\n  ggtitle(\"Ratios for specific trials\")\n\nSuppose you are now certain that theta = 0.6, plot the probability density given 1000 trials using the code below.\n\nsize =  # number of trials\nprob =  # probability of success\n\nbinom_data &lt;- data.frame(\n  Success = 0:size,\n  Probability = dbinom(0:size, size = size, prob = prob)\n)\n\nggplot(binom_data, aes(x = Success, y = Probability)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"PMF of Binomial Distribution\", x = \"Number of Successes\", y = \"PDF\")\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\n✔ | F W  S  OK | Context\n\n⠏ |          0 | task-1-subtask-1-tests                                         \n⠏ |          0 | p_red()                                                        \n✖ | 1        3 | p_red()\n────────────────────────────────────────────────────────────────────────────────\nFailure ('test-task-1-subtask-1-tests.R:21:3'): p_red()\np_red(boxes = boxes) not equivalent to 0.5.\n1/1 mismatches\n[1] 0.393 - 0.5 == -0.107\nError: Incorrect result for matrix(c(1,1,1,1,1,1), ncol = 2)\n────────────────────────────────────────────────────────────────────────────────\n\n⠏ |          0 | task-2-subtask-1-tests                                         \n⠏ |          0 | p_box()                                                        \n✖ | 1        3 | p_box()\n────────────────────────────────────────────────────────────────────────────────\nFailure ('test-task-2-subtask-1-tests.R:19:3'): p_box()\np_box(boxes = boxes) not equivalent to c(0.4, 0.1, 0.5).\n3/3 mismatches (average diff: 0.0909)\n[1] 0.2909 - 0.4 == -0.1091\n[2] 0.0727 - 0.1 == -0.0273\n[3] 0.6364 - 0.5 ==  0.1364\nError: Incorrect result for matrix(c(1,1,1,1,1,1), ncol = 2)\n────────────────────────────────────────────────────────────────────────────────\n\n⠏ |          0 | task-3-subtask-1-tests                                         \n⠏ |          0 | p_identical_twin()                                             \n✖ | 2        3 | p_identical_twin()\n────────────────────────────────────────────────────────────────────────────────\nFailure ('test-task-3-subtask-1-tests.R:16:3'): p_identical_twin()\np_identical_twin(fraternal_prob = 1/100, identical_prob = 1/500) not equivalent to 0.2857143.\n1/1 mismatches\n[1] 0.455 - 0.286 == 0.169\nError: Incorrect result for fraternal_prob = 1/100 and identical_prob = 1/500\n\nFailure ('test-task-3-subtask-1-tests.R:19:3'): p_identical_twin()\np_identical_twin(fraternal_prob = 1/10, identical_prob = 1/20) not equivalent to 0.5.\n1/1 mismatches\n[1] 0.455 - 0.5 == -0.0455\nError: Incorrect result for fraternal_prob = 1/10 and identical_prob = 1/20\n────────────────────────────────────────────────────────────────────────────────\n\n══ Results ═════════════════════════════════════════════════════════════════════\n── Failed tests ────────────────────────────────────────────────────────────────\nFailure ('test-task-1-subtask-1-tests.R:21:3'): p_red()\np_red(boxes = boxes) not equivalent to 0.5.\n1/1 mismatches\n[1] 0.393 - 0.5 == -0.107\nError: Incorrect result for matrix(c(1,1,1,1,1,1), ncol = 2)\n\nFailure ('test-task-2-subtask-1-tests.R:19:3'): p_box()\np_box(boxes = boxes) not equivalent to c(0.4, 0.1, 0.5).\n3/3 mismatches (average diff: 0.0909)\n[1] 0.2909 - 0.4 == -0.1091\n[2] 0.0727 - 0.1 == -0.0273\n[3] 0.6364 - 0.5 ==  0.1364\nError: Incorrect result for matrix(c(1,1,1,1,1,1), ncol = 2)\n\nFailure ('test-task-3-subtask-1-tests.R:16:3'): p_identical_twin()\np_identical_twin(fraternal_prob = 1/100, identical_prob = 1/500) not equivalent to 0.2857143.\n1/1 mismatches\n[1] 0.455 - 0.286 == 0.169\nError: Incorrect result for fraternal_prob = 1/100 and identical_prob = 1/500\n\nFailure ('test-task-3-subtask-1-tests.R:19:3'): p_identical_twin()\np_identical_twin(fraternal_prob = 1/10, identical_prob = 1/20) not equivalent to 0.5.\n1/1 mismatches\n[1] 0.455 - 0.5 == -0.0455\nError: Incorrect result for fraternal_prob = 1/10 and identical_prob = 1/20\n\n[ FAIL 4 | WARN 0 | SKIP 0 | PASS 9 ]",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 1"
    ]
  },
  {
    "objectID": "template3.html",
    "href": "template3.html",
    "title": "Notebook for Assignment 3",
    "section": "",
    "text": "This assignment is related to Lecture 3 and BDA3 Chapters 2 and 3. Use Frank Harrell’s recommendations on how to state results in Bayesian two group comparisons (and note that there is no point null hypothesis testing in this assignment).\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 2.\nThe reading instructions for BDA3 Chapter 3.\n\n\n\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"remotes\")\n    remotes::install_github(\"avehtari/BDA_course_Aalto\", subdir = \"rpackage\", upgrade=\"never\")\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/blob/master/tests/assignment3.yml\")\nset_assignment(assignment_path)    \n\nAssignment set:\nassignment3: Bayesian Data Analysis: Assignment 3\nThe assignment contain the following (6) tasks:\n- mu_point_est\n- mu_interval\n- mu_pred_interval\n- mu_pred_point_est\n- posterior_odds_ratio_point_est\n- posterior_odds_ratio_interval\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\n\n\n\n\n\nThe following installs and loads the posterior package, which allows us to use its rvar Random Variable Datatype:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggdist package along with other packages for advanced plotting functions:\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nggplot2::theme_set(theme_minimal(base_size = 14))\nif(!require(ggdist)){\n    install.packages(\"ggdist\")\n    library(ggdist)\n}\n\nLoading required package: ggdist\n\nif(!require(grid)){\n  install.packages(\"grid\")\n  library(grid)\n}\n\nLoading required package: grid\n\nif(!require(gridExtra)){\n  install.packages(\"gridExtra\")\n  library(gridExtra)\n}\n\nLoading required package: gridExtra\n\nif(!require(tidyr)){\n  install.packages(\"tidyr\")\n  library(tidyr)\n}\n\nLoading required package: tidyr",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 3"
    ]
  },
  {
    "objectID": "template3.html#setting-up-advanced-packages-posterior-and-ggdist",
    "href": "template3.html#setting-up-advanced-packages-posterior-and-ggdist",
    "title": "Notebook for Assignment 3",
    "section": "",
    "text": "The following installs and loads the posterior package, which allows us to use its rvar Random Variable Datatype:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggdist package along with other packages for advanced plotting functions:\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nggplot2::theme_set(theme_minimal(base_size = 14))\nif(!require(ggdist)){\n    install.packages(\"ggdist\")\n    library(ggdist)\n}\n\nLoading required package: ggdist\n\nif(!require(grid)){\n  install.packages(\"grid\")\n  library(grid)\n}\n\nLoading required package: grid\n\nif(!require(gridExtra)){\n  install.packages(\"gridExtra\")\n  library(gridExtra)\n}\n\nLoading required package: gridExtra\n\nif(!require(tidyr)){\n  install.packages(\"tidyr\")\n  library(tidyr)\n}\n\nLoading required package: tidyr",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 3"
    ]
  },
  {
    "objectID": "template3.html#marginal-and-probabilities-for-mu",
    "href": "template3.html#marginal-and-probabilities-for-mu",
    "title": "Notebook for Assignment 3",
    "section": "2.1 Marginal and probabilities for \\(\\mu\\)",
    "text": "2.1 Marginal and probabilities for \\(\\mu\\)\nWrite your answers and code here!\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful functions: mean(), length(), sqrt(), sum()\n# and qtnew(), dtnew() (from aaltobda)\n\nmu_point_est &lt;- function(data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    14.5\n    \n}\nmu_interval &lt;- function(data, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(13.3, 15.7)\n    \n}\n\nYou can plot the density as below if you implement mu_pdf to compute the PDF of the posterior \\(p(\\mu|y)\\) of the average hardness \\(\\mu\\).\n\nmu_pdf &lt;- function(data, x){\n    # Compute necessary parameters here.\n    # These are the correct parameters for `windshieldy_test` \n    # with the provided uninformative prior.\n    df = 3\n    location = 14.5\n    scale = 0.3817557\n    # Use the computed parameters as below to compute the PDF:\n    \n    dtnew(x, df, location, scale)\n}\n\nx_interval = mu_interval(windshieldy1, .999)\nlower_x = x_interval[1]\nupper_x = x_interval[2]\nx = seq(lower_x, upper_x, length.out=1000)\nplot(\n    x, mu_pdf(windshieldy1, x), type=\"l\", \n    xlab=TeX(r'(average hardness $\\mu$)'), \n    ylab=TeX(r'(PDF of the posterior $p(\\mu|y)$)')\n)\n\n\n\n\n\n\n\nFigure 1: PDF of the posterior \\(p(\\mu|y)\\) of the average hardness \\(\\mu\\)",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 3"
    ]
  },
  {
    "objectID": "template3.html#joint-posterior-distribution-for-mu-and-sigma",
    "href": "template3.html#joint-posterior-distribution-for-mu-and-sigma",
    "title": "Notebook for Assignment 3",
    "section": "2.2 Joint posterior distribution for \\(\\mu\\) and \\(\\sigma\\)",
    "text": "2.2 Joint posterior distribution for \\(\\mu\\) and \\(\\sigma\\)\n\n# Define the inputs for the below: Sufficient Statistics\ny &lt;- windshieldy1\nn &lt;- length(y)\ns2 &lt;- var(y)\nmy &lt;- mean(y)\n\n# helper functions to sample from and evaluate\n# scaled inverse chi-squared distribution\nrsinvchisq &lt;- function(n, nu, s2, ...) nu*s2 / rchisq(n , nu, ...)\ndsinvchisq &lt;- function(x, nu, s2){\n  exp(log(nu/2)*nu/2 - lgamma(nu/2) + log(s2)/2*nu - log(x)*(nu/2+1) - (nu*s2/2)/x)\n}\n\n\n# Sample 1000 draws from marginal posteriors\nns &lt;- 1000\nsigma2  &lt;- rsinvchisq(ns, n-1, s2)\nmu &lt;- my + sqrt(sigma2/n)*rnorm(length(sigma2))\nsigma &lt;- sqrt(sigma2)\n\n# Compute the density in a grid of ranged for the grids\nt1l &lt;- c(10, 20)\nt2l &lt;- c(0.5, 7)\nnl &lt;- c(0.001, 50)\nt1 &lt;- seq(t1l[1], t1l[2], length.out = ns)\nt2 &lt;- seq(t2l[1], t2l[2], length.out = ns)\n\n\n# Compute the exact marginal density of mu:\n# multiplication by 1./sqrt(s2/n) is due to the transformation of\n# variable z=(x-mean(y))/sqrt(s2/n), see BDA3 p. 21\npm &lt;- dt((t1-my) / sqrt(s2/n), n-1) / sqrt(s2/n)\n\n# Estimate the marginal density using samples and ad hoc Gaussian kernel approximation\npmk &lt;- density(mu, adjust = 2, n = ns, from = t1l[1], to = t1l[2])$y\n\n#Compute the exact marginal density of sigma:\n# the multiplication by 2*t2 is due to the transformation of\n# variable z=t2^2, see BDA3 p. 21\nps &lt;- dsinvchisq(t2^2, n-1, s2) * 2*t2\n\n# Estimate the marginal density using samples and ad hoc Gaussian kernel approximation\npsk &lt;- density(sigma, n = ns, from = t2l[1], to = t2l[2])$y\n\n\n# Evaluate the joint density in a grid. Note that the following is not normalized, but for plotting contours it does not matter :\n# Combine grid points into another data frame\n# with all pairwise combinations\ndfj &lt;- data.frame(t1 = rep(t1, each = length(t2)),\n                  t2 = rep(t2, length(t1)))\ndfj$z &lt;- dsinvchisq(dfj$t2^2, n-1, s2) * 2*dfj$t2 * dnorm(dfj$t1, my, dfj$t2/sqrt(n))\n# breaks for plotting the contours\ncl &lt;- seq(1e-5, max(dfj$z), length.out = 6)\n\n\n\n# Now, visualise the joint and marginal densities\ndfm &lt;- data.frame(t1, Exact = pm, Empirical = pmk) |&gt;\n  pivot_longer(cols = !t1, names_to=\"grp\", values_to=\"p\")\nmargmu &lt;- ggplot(dfm) +\n  geom_line(aes(t1, p, color = grp)) +\n  coord_cartesian(xlim = t1l) +\n  labs(title = 'Marginal of mu', x = '', y = '') +\n  scale_y_continuous(breaks = NULL) +\n  theme(legend.background = element_blank(),\n        legend.position.inside = c(0.75, 0.8),\n        legend.title = element_blank())\n\n\ndfs &lt;- data.frame(t2, Exact = ps, Empirical = psk) |&gt; \n  pivot_longer(cols = !t2, names_to=\"grp\", values_to=\"p\")\nmargsig &lt;- ggplot(dfs) +\n  geom_line(aes(t2, p, color = grp)) +\n  coord_cartesian(xlim = t2l) +\n  coord_flip() +\n  labs(title = 'Marginal of sigma', x = '', y = '') +\n  scale_y_continuous(breaks = NULL) +\n  theme(legend.background = element_blank(),\n        legend.position.inside = c(0.75, 0.8),\n        legend.title = element_blank())\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\njoint1labs &lt;- c('Samples','Exact contour')\njoint1 &lt;- ggplot() +\n  geom_point(data = data.frame(mu,sigma), aes(mu, sigma, col = '1'), size = 0.1) +\n  geom_contour(data = dfj, aes(t1, t2, z = z, col = '2'), breaks = cl) +\n  coord_cartesian(xlim = t1l,ylim = t2l) +\n  labs(title = 'Joint posterior', x = '', y = '') +\n  scale_y_continuous(labels = NULL) +\n  scale_x_continuous(labels = NULL) +\n  scale_color_manual(values=c('blue', 'black'), labels = joint1labs) +\n  guides(color = guide_legend(nrow  = 1, override.aes = list(\n    shape = c(16, NA), linetype = c(0, 1), size = c(2, 1)))) +\n  theme(legend.background = element_blank(),\n        legend.position.inside = c(0.5, 0.9),\n        legend.title = element_blank())\n\n\n# blank plot for combining the plots\nbp &lt;- grid.rect(gp = gpar(col = 'white'))\n\n\n\n\n\n\n\ngrid.arrange(joint1, margsig, margmu, bp, nrow = 2)",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 3"
    ]
  },
  {
    "objectID": "template3.html#predictive-distribution",
    "href": "template3.html#predictive-distribution",
    "title": "Notebook for Assignment 3",
    "section": "2.3 Predictive distribution",
    "text": "2.3 Predictive distribution\nWrite your answers and code here!\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful functions: mean(), length(), sqrt(), sum()\n# and qtnew(), dtnew() (from aaltobda)\n\nmu_pred_point_est &lt;- function(data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    14.5\n    \n}\nmu_pred_interval &lt;- function(data, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(11.8, 17.2)\n    \n}\n\nYou can plot the density as below if you implement mu_pred_pdf to compute the PDF of the posterior predictive \\(p(\\tilde{y}|y)\\) of a new hardness observation \\(\\tilde{y}\\).\n\nmu_pred_pdf &lt;- function(data, x){\n    # Compute necessary parameters here.\n    # These are the correct parameters for `windshieldy_test` \n    # with the provided uninformative prior.\n    df = 3\n    location = 14.5\n    scale = 0.8536316\n    # Use the computed parameters as below to compute the PDF:\n    \n    dtnew(x, df, location, scale)\n}\n\nx_interval = mu_pred_interval(windshieldy1, .999)\nlower_x = x_interval[1]\nupper_x = x_interval[2]\nx = seq(lower_x, upper_x, length.out=1000)\nplot(\n    x, mu_pred_pdf(windshieldy1, x), type=\"l\", \n    xlab=TeX(r'(new hardness observation $\\tilde{y}$)'), \n    ylab=TeX(r'(PDF of the posterior predictive $p(\\tilde{y}|y)$)')\n)\n\n\n\n\n\n\n\nFigure 2: PDF of the posterior predictive \\(p(\\tilde{y}|y)\\) of a new hardness observation \\(\\tilde{y}\\)",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 3"
    ]
  },
  {
    "objectID": "template3.html#advanced-tools-posteriors-rvar-ggdists-stat_dotsinterval",
    "href": "template3.html#advanced-tools-posteriors-rvar-ggdists-stat_dotsinterval",
    "title": "Notebook for Assignment 3",
    "section": "3.1 advanced tools (posterior’s rvar, ggdist’s stat_dotsinterval)",
    "text": "3.1 advanced tools (posterior’s rvar, ggdist’s stat_dotsinterval)\nThe posterior package’s random variable datatype rvar is a “sample-based representation of random variables” which makes handling of random samples (of draws) such as the ones contained in the above variables p0 and p1 easier. By default, it prints as the mean and standard deviation of the draws, such that rvar(p0) prints as 0.05 ± 0.021 and rvar(p1) prints as 0.1 ± 0.029.\nThe datatype is “designed to […] be able to be used inside data.frame()s and tibble()s, and to be used with distribution visualizations in the ggdist package.” The code below sets up an R data.frame() with the draws in p0 and p1 wrapped in an rvar, and uses that data frame to visualize the draws using ggdist, an R package building on ggplot2 and “designed for both frequentist and Bayesian uncertainty visualization”.\nThe below plot, Figure 3 uses ggdist’s stat_dotsinterval(), which by default visualizes\n\nan rvar’s median and central 66% and 95% intervals using a black dot and lines of varying thicknesses as when using ggdist’s stat_pointinterval() and\nan rvar’s draws using grey dots as when using ggdist’s stat_dots():\n\n\nr0 = rvar(p0)\nr1 = rvar(p1)\nggplot(data.frame(\n    rv_name=c(\"control\", \"treatment\"), rv=c(r0, r1)\n)) +\n    aes(xdist=rv, y=rv_name) + \n    labs(x=\"probabilities of death\", y=\"patient group\") + \n    stat_dotsinterval()\n\n\n\n\n\n\n\nFigure 3: Probabilities of death for the two patient groups.\n\n\n\n\n\nrvars make it easy to compute functions of random variables, such as\n\ndifferences, e.g. \\(p_0 - p_1\\): r0 - r1 computes an rvar which prints as -0.05 ± 0.037, indicating the sample mean and the sample standard deviation of the difference of the probabilities of death,\nproducts, e.g. \\(p_0 \\, p_1\\): r0 * r1 computes an rvar which prints as 0.005 ± 0.0026 which in this case has no great interpretation\n\nBelow, in Figure 4, we compute the odds ratios using the rvars and visualize its median, central intervals and draws, as above in Figure 3:\n\nrodds_ratio = (r1/(1-r1))/(r0/(1-r0))\nggplot(data.frame(\n    rv=c(rodds_ratio)\n)) +\n    aes(xdist=rv) + \n    labs(x=\"odds ratio\", y=\"relative amount of draws\") + \n    stat_dotsinterval()\n\n\n\n\n\n\n\nFigure 4: Odds ratios of the two patient groups.\n\n\n\n\n\nYou can use Figure 4 to visually check whether the answers you computed make sense.",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 3"
    ]
  },
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "The exercises here refer to the lecture 3/BDA chapters 2-3 content.\nThe exercises constitute 96% of the Quiz 3 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a rendered html file (to access the qmd file click the “&lt;/&gt; Code” button at the top right hand corner of the template)\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\nA factory has a production line for manufacturing car windshields. A sample of windshields has been taken for testing hardness. The observed hardness values \\( y_1 \\) can be found in the dataset windshieldy1 in the aaltobda package.We may assume that the observations follow a normal distribution with an unknown standard deviation \\( \\sigma \\). We wish to obtain information about the unknown average hardness \\( \\mu \\). For simplicity we assume standard uninformative prior discussed in the book, that is, \\( p(\\mu, \\sigma^2) \\propto (\\sigma^2)^{-1} \\). It is not necessary to derive the posterior distribution in this quiz, as it has already been done in the book (see section 3.2). As in the lecture, define \\(n\\) as the number of observations, \\(\\bar{y} \\) as the arithmatic mean estimate and \\(s^2 = \\frac{1}{n-1}\\sum^n_{i=1} (y_i-\\bar{y})^2\\).\n1.1 The likelihood \\( p(y|\\mu,\\sigma) \\) can be expressed as: \n1.2 The resulting joint posterior for \\(\\mu\\) and \\(\\sigma^2\\) may be expressed as: \n1.3 The resulting marginal posterior for \\(\\mu \\) may be expressed as: \n\n1.4 The resulting marginal posterior for \\(\\sigma^2 \\) may be expressed as: What can you say about the unknown \\( \\mu \\)?1.5 Compute and report the point estimate \\( E(\\mu|y) \\) (report your answer with 3 decimal digits): 1.6 Compute and report the central 95% posterior interval (report your answer with 3 decimal digits). R does not have a built in quantile function for t-distributions with non-zero mean and scale different from 1. The code template gives instructions how you can make your own function:  NB: Posterior intervals are also called credible intervals and are different from confidence intervals. 1.7 Using the code in the template, what can you say about the joint posterior of \\(\\mu,\\sigma\\)? What can you say about the hardness of the next windshield coming from the production line before actually measuring the hardness?1.7 Compute and report the point estimate \\(E(\\tilde{y}|y)\\)(report your answer with 3 decimal digits) :  1.8 Compute and report a posterior predictive 95%-interval (report your answer with 3 decimal digits):  NB: Posterior predictive intervals are different from posterior intervals of parameters of the model.\n\n\nAn experiment was performed to estimate the effect of beta-blockers on mortality of cardiac patients. A group of patients was randomly assigned to treatment and control groups: out of 674 patients receiving the control, 39 died, and out of 680 receiving the treatment, 22 died. Assume that the outcomes are independent and binomially distributed, with probabilities of death of \\( p_0 \\) and \\( p_1 \\) under the control and treatment, respectively. Set up a noninformative or weakly informative prior distribution on \\( (p_0,p_1) \\). In the below, n refers to the number of trials, y to the number of successes and \\(\\theta\\) to the probability within a binomial model.Formulate model below.2.1 Take \\(y_C\\) as the number of deaths in the control group and \\(y_T\\) as the number of deaths in the treatment group. The data model can be written as: 2.2 In the context of the data and model, the prior:  2.3 The resulting posterior with independent \\(Beta(1,1) \\) priors for \\(p_0\\) and \\(p_1\\) can be expressed as: Using the \\(Beta(1,1)\\) prior for \\(p_0\\) and \\(p_1\\) independently, summarize the posterior distribution for the odds ratio, \\( \\mathrm{OR} = (p_1/(1-p_1))/(p_0/(1-p_0)) \\). With this (and any Beta prior), a the posteriors for \\((p_0,p_1)\\) are also Beta distributions, respectively (see equations in the book). First, use rbeta() to obtain posterior draws for the posterior distributions of \\(p_0\\) and \\(p_1\\). Then use these draws and odds ratio equation above to get the posterior of the odds ratio. This is called a push-forward distribution.  Obtain at least 1000 draws. If you are unsure how to get started, check out the code template.2.4 Compute a point estimate for \\(E(\\mathrm{OR}|y_0,y_1)\\).Report the result in decimals with two decimal digits:   2.5 Compute an estimate for the posterior 95% central interval. Report the result in decimal with three decimal digits:  2.6 Now use what might be deemed a weakly informative \\(Beta(2,2)\\) prior on both probabilities \\(p_0\\) and \\(p_1\\) and discuss the sensitivity of your inference to your choice of prior density: \n2.7 Use Frank Harrell's recommendations on how to state results in Bayesian two group comparison: \n\n\nConsider a case where the same factory has two production lines for manufacturing car windshields. Independent samples from the two production lines were tested for hardness. The hardness measurements for the two samples \\( \\mathbf{y}_1 \\) and \\( \\mathbf{y}_2 \\) be found in  the datasets windshieldy1 and windshieldy2 in the aaltobda package and in this exercise we will model the measurements with two independent normal distributions respectively.For the model, we assume that standard deviations \\(\\sigma_1\\) and \\(\\sigma_2\\) of the normal models are unknown. Let \\(\\bar{y_1}\\) and \\(\\bar{y_2}\\) denote averages for  \\( \\mathbf{y}_1 \\) and \\( \\mathbf{y}_2 \\), respectively and \\(s_1^2\\), \\(s_2^2\\) denote corresponding sample variances for  \\( \\mathbf{y}_1 \\) and \\( \\mathbf{y}_2 \\), computed in a same manner as in exercise 1. Also, \\(n_1\\) and \\(n_2\\) denote number the number of samples in each dataset. Use the uninformative prior and answer the following questions:\n3.1 The data model may be expressed as: \n\n3.2 The prior can be expressed as: \n\n\n3.3 The resulting marginal posterior for \\(\\mu_1\\) can be expressed as: \n\n\n3.4 The resulting joint posterior for \\((\\mu_1,{\\sigma_1}^2)\\) can be expressed as: \n\n\n3.5 The resulting joint posterior for \\((\\mu_2,{\\sigma_2}^2)\\) can be expressed as: \nWhat can you say about \\( \\mu_d = \\mu_1 - \\mu_2 \\)?You can use the rtnew() function to sample from the posterior distributions of \\(\\mu_1\\) and \\(\\mu_2\\), and use these samples to get a sample from the distribution of the difference \\(\\mu_d = \\mu_1 - \\mu_2\\). Draw at least 10000 samples.3.6 Compute the point estimate \\( E(\\mu_d|y_1, y_2) \\). Report the result in decimals with three decimal digits: \n3.7 Compute a posterior 95%-interval. Report the result in decimals with three decimal digits: 3.8 Given this specific model, what is the probability that the means are exactly the same (\\(\\mu_1 = \\mu_2\\)) (Use Frank Harrell's recommendations)? Explain your reasoning. \n3.9 Compute the probability that \\(\\mu_1 &lt; \\mu_2\\) (same as the probability that \\(\\mu_1 - \\mu_2 &lt; 0\\)). Report the result in decimals with two decimal digits:",
    "crumbs": [
      "Assignments",
      "Assignment 3"
    ]
  },
  {
    "objectID": "assignment3.html#assignment-questions",
    "href": "assignment3.html#assignment-questions",
    "title": "Assignment 3",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\nA factory has a production line for manufacturing car windshields. A sample of windshields has been taken for testing hardness. The observed hardness values \\( y_1 \\) can be found in the dataset windshieldy1 in the aaltobda package.We may assume that the observations follow a normal distribution with an unknown standard deviation \\( \\sigma \\). We wish to obtain information about the unknown average hardness \\( \\mu \\). For simplicity we assume standard uninformative prior discussed in the book, that is, \\( p(\\mu, \\sigma^2) \\propto (\\sigma^2)^{-1} \\). It is not necessary to derive the posterior distribution in this quiz, as it has already been done in the book (see section 3.2). As in the lecture, define \\(n\\) as the number of observations, \\(\\bar{y} \\) as the arithmatic mean estimate and \\(s^2 = \\frac{1}{n-1}\\sum^n_{i=1} (y_i-\\bar{y})^2\\).\n1.1 The likelihood \\( p(y|\\mu,\\sigma) \\) can be expressed as: \n1.2 The resulting joint posterior for \\(\\mu\\) and \\(\\sigma^2\\) may be expressed as: \n1.3 The resulting marginal posterior for \\(\\mu \\) may be expressed as: \n\n1.4 The resulting marginal posterior for \\(\\sigma^2 \\) may be expressed as: What can you say about the unknown \\( \\mu \\)?1.5 Compute and report the point estimate \\( E(\\mu|y) \\) (report your answer with 3 decimal digits): 1.6 Compute and report the central 95% posterior interval (report your answer with 3 decimal digits). R does not have a built in quantile function for t-distributions with non-zero mean and scale different from 1. The code template gives instructions how you can make your own function:  NB: Posterior intervals are also called credible intervals and are different from confidence intervals. 1.7 Using the code in the template, what can you say about the joint posterior of \\(\\mu,\\sigma\\)? What can you say about the hardness of the next windshield coming from the production line before actually measuring the hardness?1.7 Compute and report the point estimate \\(E(\\tilde{y}|y)\\)(report your answer with 3 decimal digits) :  1.8 Compute and report a posterior predictive 95%-interval (report your answer with 3 decimal digits):  NB: Posterior predictive intervals are different from posterior intervals of parameters of the model.\n\n\nAn experiment was performed to estimate the effect of beta-blockers on mortality of cardiac patients. A group of patients was randomly assigned to treatment and control groups: out of 674 patients receiving the control, 39 died, and out of 680 receiving the treatment, 22 died. Assume that the outcomes are independent and binomially distributed, with probabilities of death of \\( p_0 \\) and \\( p_1 \\) under the control and treatment, respectively. Set up a noninformative or weakly informative prior distribution on \\( (p_0,p_1) \\). In the below, n refers to the number of trials, y to the number of successes and \\(\\theta\\) to the probability within a binomial model.Formulate model below.2.1 Take \\(y_C\\) as the number of deaths in the control group and \\(y_T\\) as the number of deaths in the treatment group. The data model can be written as: 2.2 In the context of the data and model, the prior:  2.3 The resulting posterior with independent \\(Beta(1,1) \\) priors for \\(p_0\\) and \\(p_1\\) can be expressed as: Using the \\(Beta(1,1)\\) prior for \\(p_0\\) and \\(p_1\\) independently, summarize the posterior distribution for the odds ratio, \\( \\mathrm{OR} = (p_1/(1-p_1))/(p_0/(1-p_0)) \\). With this (and any Beta prior), a the posteriors for \\((p_0,p_1)\\) are also Beta distributions, respectively (see equations in the book). First, use rbeta() to obtain posterior draws for the posterior distributions of \\(p_0\\) and \\(p_1\\). Then use these draws and odds ratio equation above to get the posterior of the odds ratio. This is called a push-forward distribution.  Obtain at least 1000 draws. If you are unsure how to get started, check out the code template.2.4 Compute a point estimate for \\(E(\\mathrm{OR}|y_0,y_1)\\).Report the result in decimals with two decimal digits:   2.5 Compute an estimate for the posterior 95% central interval. Report the result in decimal with three decimal digits:  2.6 Now use what might be deemed a weakly informative \\(Beta(2,2)\\) prior on both probabilities \\(p_0\\) and \\(p_1\\) and discuss the sensitivity of your inference to your choice of prior density: \n2.7 Use Frank Harrell's recommendations on how to state results in Bayesian two group comparison: \n\n\nConsider a case where the same factory has two production lines for manufacturing car windshields. Independent samples from the two production lines were tested for hardness. The hardness measurements for the two samples \\( \\mathbf{y}_1 \\) and \\( \\mathbf{y}_2 \\) be found in  the datasets windshieldy1 and windshieldy2 in the aaltobda package and in this exercise we will model the measurements with two independent normal distributions respectively.For the model, we assume that standard deviations \\(\\sigma_1\\) and \\(\\sigma_2\\) of the normal models are unknown. Let \\(\\bar{y_1}\\) and \\(\\bar{y_2}\\) denote averages for  \\( \\mathbf{y}_1 \\) and \\( \\mathbf{y}_2 \\), respectively and \\(s_1^2\\), \\(s_2^2\\) denote corresponding sample variances for  \\( \\mathbf{y}_1 \\) and \\( \\mathbf{y}_2 \\), computed in a same manner as in exercise 1. Also, \\(n_1\\) and \\(n_2\\) denote number the number of samples in each dataset. Use the uninformative prior and answer the following questions:\n3.1 The data model may be expressed as: \n\n3.2 The prior can be expressed as: \n\n\n3.3 The resulting marginal posterior for \\(\\mu_1\\) can be expressed as: \n\n\n3.4 The resulting joint posterior for \\((\\mu_1,{\\sigma_1}^2)\\) can be expressed as: \n\n\n3.5 The resulting joint posterior for \\((\\mu_2,{\\sigma_2}^2)\\) can be expressed as: \nWhat can you say about \\( \\mu_d = \\mu_1 - \\mu_2 \\)?You can use the rtnew() function to sample from the posterior distributions of \\(\\mu_1\\) and \\(\\mu_2\\), and use these samples to get a sample from the distribution of the difference \\(\\mu_d = \\mu_1 - \\mu_2\\). Draw at least 10000 samples.3.6 Compute the point estimate \\( E(\\mu_d|y_1, y_2) \\). Report the result in decimals with three decimal digits: \n3.7 Compute a posterior 95%-interval. Report the result in decimals with three decimal digits: 3.8 Given this specific model, what is the probability that the means are exactly the same (\\(\\mu_1 = \\mu_2\\)) (Use Frank Harrell's recommendations)? Explain your reasoning. \n3.9 Compute the probability that \\(\\mu_1 &lt; \\mu_2\\) (same as the probability that \\(\\mu_1 - \\mu_2 &lt; 0\\)). Report the result in decimals with two decimal digits:",
    "crumbs": [
      "Assignments",
      "Assignment 3"
    ]
  },
  {
    "objectID": "template7.html",
    "href": "template7.html",
    "title": "Notebook for Assignment 7",
    "section": "",
    "text": "1 General information\nThis assignment relates to Lecture 7 and Chapter 5.\nWe recommend using JupyterHub (which has all the needed packages pre-installed).\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 5.\n\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\nif (!require(tidybayes)) {\n    install.packages(\"tidybayes\")\n    library(tidybayes)\n}\n\nLoading required package: tidybayes\n\nif (!require(brms)) {\n    install.packages(\"brms\")\n    library(brms)\n}\n\nLoading required package: brms\n\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following objects are masked from 'package:tidybayes':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\nif (!require(metadat)) {\n  install.packages(\"metadat\")\n  library(metadat)\n}\n\nLoading required package: metadat\n\nif(!require(cmdstanr)){\n    install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n    library(cmdstanr)\n}\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.9.0\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.36.0\n\n\n- CmdStan version: 2.36.0\n\ncmdstan_installed &lt;- function(){\n  res &lt;- try(out &lt;- cmdstanr::cmdstan_path(), silent = TRUE)\n  !inherits(res, \"try-error\")\n}\nif(!cmdstan_installed()){\n    install_cmdstan()\n}\n\n\n\n2 Simulation warm-up\nHere is the function to simulate and plot observations from a hierarchical data-generating process.\n\nhierarchical_sim &lt;- function(group_pop_mean,\n                             between_group_sd,\n                             within_group_sd,\n                             n_groups,\n                             n_obs_per_group\n                             ) {\n  # Generate group means\n  group_means &lt;- rnorm(\n    n = n_groups,\n    mean = group_pop_mean,\n    sd = between_group_sd\n  )\n\n  # Generate observations\n\n  ## Create an empty vector for observations\n  y &lt;- numeric()\n  ## Create a vector for the group identifier\n  group &lt;- rep(1:n_groups, each = n_obs_per_group)\n  \n  for (j in 1:n_groups) {\n    ### Generate one group observations\n    group_y &lt;- rnorm(\n      n = n_obs_per_group,\n      mean = group_means[j],\n      sd = within_group_sd\n    )\n    ### Append the group observations to the vector\n    y &lt;- c(y, group_y)\n  }\n\n  # Combine into a data frame\n  data &lt;- data.frame(\n    group = factor(group),\n    y = y\n  )\n\n  # Plot the data\n  ggplot(data, aes(x = y, y = group)) +\n    geom_point() +\n    geom_vline(xintercept = group_pop_mean, linetype = \"dashed\")\n}\n\nExample using the function:\n\nhierarchical_sim(\n  group_pop_mean = 50,\n  between_group_sd = 5,\n  within_group_sd = 1,\n  n_groups = 10,\n  n_obs_per_group = 5\n  )\n\nError in ggplot(data, aes(x = y, y = group)): could not find function \"ggplot\"\n\n\n\n\n3 Sleep deprivation\nThe dataset sleepstudy is available by using the command data(sleepstudy, package = \"lme4\")\nBelow is some code for fitting a brms model. This model is a simple pooled model. You will need to fit a hierarchical model as explained in the assignment, but this code should help getting started.\nLoad the dataset\n\ndata(sleepstudy, package = \"lme4\")\n\nError in find.package(package, lib.loc, verbose = verbose): there is no package called 'lme4'\n\n\nSpecify the formula and observation family:\n\nsleepstudy_pooled_formula &lt;- bf(\n  Reaction ~ 1 + Days,\n  family = \"gaussian\",\n  center = FALSE\n)\n\nWe can see the parameters and default priors with\n\nget_prior(pooled_formula, data = sleepstudy)\n\nWe can then specify the priors:\n\n(sleepstudy_pooled_priors &lt;- c(\n  prior(\n    normal(400, 100),\n    class = \"b\",\n    coef = \"Intercept\"\n  ),\n  prior(\n    normal(0, 50),\n    class = \"b\",\n    coef = \"Days\"\n  ),\n  prior(\n    normal(0, 50),\n    class = \"sigma\"\n  )\n))\n\nAnd then fit the model:\n\nsleepstudy_pooled_fit &lt;- brm(\n  formula = pooled_formula,\n  prior = pooled_priors,\n  data = sleepstudy\n)\n\nWe can inspect the model fit:\n\nsummary(pooled_fit)\n\n\n\n4 School calendar\nMeta-analysis models can be fit in brms. When the standard error is known, the se() function can be used to specify it.\nThe dataset dat.konstantopoulos2011 has the observations for the school calendar intervention meta-analysis.\n\ndata(dat.konstantopoulos2011, package = \"metadat\")\n\nAs mentioned in the assignment instructions, a unique identifier for school needs to be created by combining the district and school:\n\nschoolcalendar_data &lt;- dat.konstantopoulos2011 |&gt;\n  dplyr::mutate(\n    school = factor(school),\n    district = factor(district),\n    district_school = interaction(district, school, drop = TRUE, sep = \"_\")\n  )\n\nThen the models can be fit\n\nschoolcalendar_pooled_formula &lt;- bf(\n  formula = yi | se(sqrt(vi)) ~ 1,\n  family = \"gaussian\"\n)  \n\nschoolcalendar_pooled_fit &lt;- brm(\n  formula = schoolcalendar_pooled_formula,\n  data = schoolcalendar_data\n)\n\nPredictions for a new school can be made using the posterior_epred function:\n\nnew_school &lt;- data.frame(\n  school = factor(1),\n  district = factor(1),\n  district_school = factor(\"1_1\"),\n  vi = 0 # the expectation of the prediction is not affected by the sampling variance, so this can be any number\n)\n  \n\nschoolcalendar_post_epred &lt;- posterior_epred(\n    schoolcalendar_pooled_fit,\n    newdata = new_school,\n    allow_new_levels = TRUE\n  )\n\nIt can be helpful to plot the posterior estimates. Here is a function that will do this:\n\nplot_school_posteriors &lt;- function(fit, dataset) {\n  tidybayes::add_predicted_draws(dataset, fit) |&gt;\n    ggplot(\n      aes(\n        x = .prediction,\n        y = interaction(district, school, sep = \", \", lex.order = TRUE))) +\n    tidybayes::stat_halfeye() +\n    ylab(\"District, school\") +\n    xlab(\"Posterior effect\")\n}\n\nAnd can be used as follows:\n\nplot_school_posteriors(\n  fit = schoolcalendar_pooled_fit,\n  dataset = school_calendar_data\n)",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 7"
    ]
  },
  {
    "objectID": "assignment8.html",
    "href": "assignment8.html",
    "title": "Assignment 8",
    "section": "",
    "text": "The exercises here refer to the lecture 8-9/BDA chapter 7 content.\nThe exercises constitute 96% of the Quiz 8 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a rendered html file (to access the qmd file click the “&lt;/&gt; Code” button at the top right hand corner of the template)\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\nLecture 8-9/Chapter 7 of BDA Quiz (96% of grade)\nIn order to evaluate a model, for comparison to other models or for model checking purposes, it is useful to measure how well predictions match the data. Preferably, the measure of predictive accuracy is tailored to the data-application (application specific cost-function or decision theoretic quantity, discussed more next week). But in the absence of that, we might choose from a range of scoring functions or rules mentioned in the lecture/book (see for more details on general scoring functions or rules in Gneiting and Raftery (2007)). For the below denote the target as \\( y \\) and potential covariates as \\(x\\).1.1: Which expression below is defines the log-score for observation \\(y_i \\)?\n1.2 Why is the log-score a convenient scoring rule? \n1.3 Denote by \\( \\tilde{y} \\) unseen target data with distribution \\( p_t(\\tilde{y}) \\) and by \\( y \\) target data that is conditioned on for posterior inference on model parameters. Which of the following refers to the expected log-predictive density for new data points \\( \\tilde{y}_1, \\dotsc, \\tilde{y}_n \\)? \n\n1.4 Suppose \\( \\tilde{y} = y \\), then elpd reduces to the log point-wise predictive densities (lpd) for observations \\(y_1,\\dotsc,y_n \\). Why is lpd often a bad estimate for elpd? \n\n1.5 We often use leave-one-out cross-validation (LOO-CV) to approximate out-of-sample performance. Denote by \\( y_{-i} \\) all but the \\(i\\)th observation for \\( y \\) and by \\( \\int p(y_i | \\theta)p(\\theta | y_{-i})d\\theta \\) the posterior predictive distribution for the \\(i\\)th data point based on data leaving out the \\(i\\)th data point. Which of the expressions below refers to the Bayesian LOO-CV estimate of the out-of-sample predictive fit \\(elpd_{LOO} \\)? 1.6: Instead of computing the LOO predictive densities n times for n left-out observations, a computationally much more efficient approach is to fit the model once and use importance sampling to approximate the n LOO densities in \\(elpd_{LOO} \\). Which of the below refers to the importance sampling estimate of \\(elpd_{LOO} \\)? Assume \\( \\sum_{r=1}^S \\tilde{w_i}^{(r)} = 1 \\) for all i. 1.7: Use \\( p(\\theta | x,y) \\) as the proposal distribution for \\( p(\\theta | x_{-i}, y_{-i}) \\). Derive the expression for the unnormalised importance weights \\( w_i^{(s)}  \\)(up to a constant of proportionality), assuming that the likelihood conditional on x and y can be factorised by \\( i = 1,\\dotsc,n \\) . Which of the below is proportional to the desired importance weight draw for the s-th draw of the posterior and observation i?1.8: Derive the expression for the self-normalised importance sampling estimator with the weights derived in 1.7. Which of the below is correct?The importance sampling estimator can also be extended to other scoring functions/rules. In particular, it will be of advantage for the projects to review the \\(R^2\\), Root-mean-squared-error (RMSE) which measure relative variance fit and point predictive accuracy respectively, as well as the Probability Integral Transform (PIT), and their associated cross-validated variants. These are easily implemented with BRMS fit objects. See the BRMS manual as well as the Bayes \\(R^2\\) case study further details on implementation for some of these.ELPD assesses predictions in terms of the sharpness (concentration) (for log-score this is related to negative entropy), as well as calibration (coverage) of the predictive distribution. Sharpness of the predictive distribution is rewarded since narrow predictive distributions have higher densities. On the other hand, too narrow distributions have high density in too narrow region, and lower density elsewhere. The probability intervals (e.g. central intervals) cumulative density functions of a calibrated distribution match the distribution of the target. It is possible that two different models are both well calibrated, but they have different sharpness, for example, if one of the models has additional covariate which helps to reduce the predictive uncertainty. In the below we will further discuss how to visually assess calibration. This belongs to the posterior predictive checks discussed during the lecture, and are useful to check first before formally evaluating models with ELPD (and other scoring functions/rules). 1.9: We can measure calibration by transforming the comparison between an observation and the conditional predictive distribution to a value between \\([0,1]\\). Define \\( y^{rep}_i \\) as a draw from the predictive distribution \\( p(\\tilde{y}_ i | y_i) \\), which transformation should we use?1.10: This transformation is called the probability integral transform (PIT). How should the PITs be distributed with infinite data, if the predictive distribution is correctly calibrated?When dealing with finite data, we can only hope to be close enough to uniform and you can use the ppc_loo_pit_overlay() function from bayesplot to visually check for the posterior uncertainty in the (cross-validated) PIT values. Instead of looking at the distribution of PIT values, it can be easier to examine the cumulative distribution function of the PIT values, which should be close to a 45-degree line, since the large sample distribution is uniform. The below is taken from the BRMS demo 13. Suppose the kernel density estimates of the predictive distribution and data look the following:\n\nFigure 1\n1.11: What can you say about calibration from this model for the data?1.12: Based on the model in Figure 1, which of the plots below match the ECDF plot (light blue envelope indicates regions of acceptable ECDF values)? 1.13: What is the correct interpretation of the ECDF graph? Suppose the revised model produces the following predictive distribution:\nFigure 4\n1.14: Based on the model in Figure 4, which of the plots below match the ECDF plot (light blue envelope indicates regions of acceptable ECDF values)?\n\n2.1: What makes the weights of the importance estimator for \\(elpd_{LOO}\\) be potentially unreliable with finite amount of MCMC draws?\n2.2: Assuming that importance weights have finite variance and mean, we can use the standard CLT to guarantee variance reduction at rate 1/S, where S is the number of MCMC draws. Different CLTs can be applied depending on the existence of certain fractional moments (fractional moments are more general than integer moments and are useful in describing properties of fat-tailed distributions). To estimate the number of fractional moments of the weights, we can model the tails of the importance weights using insights of extreme value theory (Pickands, 1975).  What distribution can be used to estimate the number of fractional moments?\nWe refer to the estimated value of 1/k as the k-hat value reported as a diagnostic in the loo package. Since most distributions have tails that are well approximated by GDP, we can replace tail weights of the importance weight distribution with the expected ordered statistics of the fitted GDP. In the context of LOO, we refer to this as Pareto smoothed importance sampling (PSIS-LOO).2.3: What is the rationale of replacing largest weights by the expected ordered statistics of the fitted GDP?\n2.4: Based on the above, suppose importance weights follow a standard Cauchy distribution. What k-hat value do you expect with sufficiently large number of draws?\n2.5: After what k-hat value should we seriously doubt the reliability of the Pareto smoothed importance sampling estimator? \n2.6: What does a high k-hat value indicate about the target distribution?\n2.7: What are common causes for large k-hats within the context of PSIS loo?\n2.8: What should you consider doing if you have high k-hat values?\n\n\nIn Assignment 7, you fit two different models to the sleepstudy dataset. One with varying intercepts per person and one with varying intercepts and slopes. In this exercise you will perform visual checks and leave-one-out cross-validation on these models.\nFirst, perform the following steps for the varying intercept model. This model allows for different Subjects to have different baseline Reaction times (before sleep deprivation).\nUse `pp_check(fit)` to create the default density overlay plot.\n3.1: Which of the following best describes the interpretation of the plot?\nNext try a different plot of the predictions:`pp_check(fit, type = \"intervals_grouped\", x = \"Days\", group = \"Subject\")`3.2: What does the plot present?3.3: Based on the plot, what can you say about how the model predicts the observations of individual Subjects? \nNext, use PSIS-LOO CV to estimate the elpd of the varying intercepts model.3.4: The elpd_loo estimate for the varying intercepts model is  and the standard error estimate is .The second model estimates varying intercepts and varying slopes. This model allows for different effects of Days for each Subject.Plot again the default density plot of predictions using `pp_check()`\n3.5: Which best describes the plot:Perform PSIS-LOO CV to estimate elpd_loo for the varying intercepts and slopes model. You may find that there are high Pareto-k values. These can be fixed with importance weighted moment matching at the cost of some computation, but in this case the elpd_loo will change negligibly with the improved estimates.\n3.6: The elpd_loo estimate for the varying slopes and intercepts model is  and the standard error estimate is .So far you have only performed visual posterior checks to compare the models. However, another option is to compare the leave-one-out cross validation values between the models. Use `loo_compare()` to calculate the elpd_diff between the two models.\n3.7: The elpd_diff estimate is (enter as negative value as shown in the loo_compare output)  and the standard error is 3.8: Which of these best describes the conclusions from the loo comparison:\n\nSo far you only compared the two models that were fit in the previous week. But modelling is an iterative process, and additional features of the data can be modelled. Next, you will add two extentions to the previous models, which you may have thought about already: (1) Reaction times are known to be positively skewed (2) There could be a non-linear relationship between Days and Reaction time.The first issue can be tackled by changing the observation family to a positively skewed distribution, such as log-normal.As this transforms the interpretation of the coefficients, the priors should be updated.\nUse the following priors with the lognormal observation family.\n\\(\\alpha_0 \\sim normal(\\log(250), 1)\\)\n\\(\\beta_0 \\sim normal(0, 1)\\)\n\\(\\sigma \\sim normal(0, 2)\\)\n\\(\\alpha_j \\sim normal(0, \\tau_\\alpha)\\)\n\\(\\beta_j \\sim normal(0, \\tau_\\beta)\\)\n\\(\\tau_\\alpha \\sim normal(0,  1)\\)\n\\(\\tau_\\beta \\sim normal(0,  1)\\)\nFit the varying slopes and intercept model with lognormal family.4.1 Plot the default `pp_check()`. What do you notice?Estimate the elpd_loo for the lognormal model. 4.2: The elpd_loo estimate for the lognormal model is , and the standard error estimate is .4.3 How does this compare to the other models with respect to LOO-CV?Next, to address potential non-linear effect with respect to Days, you can try with a spline term for Days. This allows for a non-linear population-level effect of Days on Reaction time. Add the term `s(Days)` to the formula for the lognormal model, and compare to the other models using pp_check and loo_compare. Use a normal(0, 1) prior on the `sDays_1` term.4.4 Based on elpd_loo comparison:4.5 Based on elpd_loo, the order of the four models from best to worst predictive performance is:",
    "crumbs": [
      "Assignments",
      "Assignment 8"
    ]
  },
  {
    "objectID": "assignment8.html#assignment-questions",
    "href": "assignment8.html#assignment-questions",
    "title": "Assignment 8",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\nLecture 8-9/Chapter 7 of BDA Quiz (96% of grade)\nIn order to evaluate a model, for comparison to other models or for model checking purposes, it is useful to measure how well predictions match the data. Preferably, the measure of predictive accuracy is tailored to the data-application (application specific cost-function or decision theoretic quantity, discussed more next week). But in the absence of that, we might choose from a range of scoring functions or rules mentioned in the lecture/book (see for more details on general scoring functions or rules in Gneiting and Raftery (2007)). For the below denote the target as \\( y \\) and potential covariates as \\(x\\).1.1: Which expression below is defines the log-score for observation \\(y_i \\)?\n1.2 Why is the log-score a convenient scoring rule? \n1.3 Denote by \\( \\tilde{y} \\) unseen target data with distribution \\( p_t(\\tilde{y}) \\) and by \\( y \\) target data that is conditioned on for posterior inference on model parameters. Which of the following refers to the expected log-predictive density for new data points \\( \\tilde{y}_1, \\dotsc, \\tilde{y}_n \\)? \n\n1.4 Suppose \\( \\tilde{y} = y \\), then elpd reduces to the log point-wise predictive densities (lpd) for observations \\(y_1,\\dotsc,y_n \\). Why is lpd often a bad estimate for elpd? \n\n1.5 We often use leave-one-out cross-validation (LOO-CV) to approximate out-of-sample performance. Denote by \\( y_{-i} \\) all but the \\(i\\)th observation for \\( y \\) and by \\( \\int p(y_i | \\theta)p(\\theta | y_{-i})d\\theta \\) the posterior predictive distribution for the \\(i\\)th data point based on data leaving out the \\(i\\)th data point. Which of the expressions below refers to the Bayesian LOO-CV estimate of the out-of-sample predictive fit \\(elpd_{LOO} \\)? 1.6: Instead of computing the LOO predictive densities n times for n left-out observations, a computationally much more efficient approach is to fit the model once and use importance sampling to approximate the n LOO densities in \\(elpd_{LOO} \\). Which of the below refers to the importance sampling estimate of \\(elpd_{LOO} \\)? Assume \\( \\sum_{r=1}^S \\tilde{w_i}^{(r)} = 1 \\) for all i. 1.7: Use \\( p(\\theta | x,y) \\) as the proposal distribution for \\( p(\\theta | x_{-i}, y_{-i}) \\). Derive the expression for the unnormalised importance weights \\( w_i^{(s)}  \\)(up to a constant of proportionality), assuming that the likelihood conditional on x and y can be factorised by \\( i = 1,\\dotsc,n \\) . Which of the below is proportional to the desired importance weight draw for the s-th draw of the posterior and observation i?1.8: Derive the expression for the self-normalised importance sampling estimator with the weights derived in 1.7. Which of the below is correct?The importance sampling estimator can also be extended to other scoring functions/rules. In particular, it will be of advantage for the projects to review the \\(R^2\\), Root-mean-squared-error (RMSE) which measure relative variance fit and point predictive accuracy respectively, as well as the Probability Integral Transform (PIT), and their associated cross-validated variants. These are easily implemented with BRMS fit objects. See the BRMS manual as well as the Bayes \\(R^2\\) case study further details on implementation for some of these.ELPD assesses predictions in terms of the sharpness (concentration) (for log-score this is related to negative entropy), as well as calibration (coverage) of the predictive distribution. Sharpness of the predictive distribution is rewarded since narrow predictive distributions have higher densities. On the other hand, too narrow distributions have high density in too narrow region, and lower density elsewhere. The probability intervals (e.g. central intervals) cumulative density functions of a calibrated distribution match the distribution of the target. It is possible that two different models are both well calibrated, but they have different sharpness, for example, if one of the models has additional covariate which helps to reduce the predictive uncertainty. In the below we will further discuss how to visually assess calibration. This belongs to the posterior predictive checks discussed during the lecture, and are useful to check first before formally evaluating models with ELPD (and other scoring functions/rules). 1.9: We can measure calibration by transforming the comparison between an observation and the conditional predictive distribution to a value between \\([0,1]\\). Define \\( y^{rep}_i \\) as a draw from the predictive distribution \\( p(\\tilde{y}_ i | y_i) \\), which transformation should we use?1.10: This transformation is called the probability integral transform (PIT). How should the PITs be distributed with infinite data, if the predictive distribution is correctly calibrated?When dealing with finite data, we can only hope to be close enough to uniform and you can use the ppc_loo_pit_overlay() function from bayesplot to visually check for the posterior uncertainty in the (cross-validated) PIT values. Instead of looking at the distribution of PIT values, it can be easier to examine the cumulative distribution function of the PIT values, which should be close to a 45-degree line, since the large sample distribution is uniform. The below is taken from the BRMS demo 13. Suppose the kernel density estimates of the predictive distribution and data look the following:\n\nFigure 1\n1.11: What can you say about calibration from this model for the data?1.12: Based on the model in Figure 1, which of the plots below match the ECDF plot (light blue envelope indicates regions of acceptable ECDF values)? 1.13: What is the correct interpretation of the ECDF graph? Suppose the revised model produces the following predictive distribution:\nFigure 4\n1.14: Based on the model in Figure 4, which of the plots below match the ECDF plot (light blue envelope indicates regions of acceptable ECDF values)?\n\n2.1: What makes the weights of the importance estimator for \\(elpd_{LOO}\\) be potentially unreliable with finite amount of MCMC draws?\n2.2: Assuming that importance weights have finite variance and mean, we can use the standard CLT to guarantee variance reduction at rate 1/S, where S is the number of MCMC draws. Different CLTs can be applied depending on the existence of certain fractional moments (fractional moments are more general than integer moments and are useful in describing properties of fat-tailed distributions). To estimate the number of fractional moments of the weights, we can model the tails of the importance weights using insights of extreme value theory (Pickands, 1975).  What distribution can be used to estimate the number of fractional moments?\nWe refer to the estimated value of 1/k as the k-hat value reported as a diagnostic in the loo package. Since most distributions have tails that are well approximated by GDP, we can replace tail weights of the importance weight distribution with the expected ordered statistics of the fitted GDP. In the context of LOO, we refer to this as Pareto smoothed importance sampling (PSIS-LOO).2.3: What is the rationale of replacing largest weights by the expected ordered statistics of the fitted GDP?\n2.4: Based on the above, suppose importance weights follow a standard Cauchy distribution. What k-hat value do you expect with sufficiently large number of draws?\n2.5: After what k-hat value should we seriously doubt the reliability of the Pareto smoothed importance sampling estimator? \n2.6: What does a high k-hat value indicate about the target distribution?\n2.7: What are common causes for large k-hats within the context of PSIS loo?\n2.8: What should you consider doing if you have high k-hat values?\n\n\nIn Assignment 7, you fit two different models to the sleepstudy dataset. One with varying intercepts per person and one with varying intercepts and slopes. In this exercise you will perform visual checks and leave-one-out cross-validation on these models.\nFirst, perform the following steps for the varying intercept model. This model allows for different Subjects to have different baseline Reaction times (before sleep deprivation).\nUse `pp_check(fit)` to create the default density overlay plot.\n3.1: Which of the following best describes the interpretation of the plot?\nNext try a different plot of the predictions:`pp_check(fit, type = \"intervals_grouped\", x = \"Days\", group = \"Subject\")`3.2: What does the plot present?3.3: Based on the plot, what can you say about how the model predicts the observations of individual Subjects? \nNext, use PSIS-LOO CV to estimate the elpd of the varying intercepts model.3.4: The elpd_loo estimate for the varying intercepts model is  and the standard error estimate is .The second model estimates varying intercepts and varying slopes. This model allows for different effects of Days for each Subject.Plot again the default density plot of predictions using `pp_check()`\n3.5: Which best describes the plot:Perform PSIS-LOO CV to estimate elpd_loo for the varying intercepts and slopes model. You may find that there are high Pareto-k values. These can be fixed with importance weighted moment matching at the cost of some computation, but in this case the elpd_loo will change negligibly with the improved estimates.\n3.6: The elpd_loo estimate for the varying slopes and intercepts model is  and the standard error estimate is .So far you have only performed visual posterior checks to compare the models. However, another option is to compare the leave-one-out cross validation values between the models. Use `loo_compare()` to calculate the elpd_diff between the two models.\n3.7: The elpd_diff estimate is (enter as negative value as shown in the loo_compare output)  and the standard error is 3.8: Which of these best describes the conclusions from the loo comparison:\n\nSo far you only compared the two models that were fit in the previous week. But modelling is an iterative process, and additional features of the data can be modelled. Next, you will add two extentions to the previous models, which you may have thought about already: (1) Reaction times are known to be positively skewed (2) There could be a non-linear relationship between Days and Reaction time.The first issue can be tackled by changing the observation family to a positively skewed distribution, such as log-normal.As this transforms the interpretation of the coefficients, the priors should be updated.\nUse the following priors with the lognormal observation family.\n\\(\\alpha_0 \\sim normal(\\log(250), 1)\\)\n\\(\\beta_0 \\sim normal(0, 1)\\)\n\\(\\sigma \\sim normal(0, 2)\\)\n\\(\\alpha_j \\sim normal(0, \\tau_\\alpha)\\)\n\\(\\beta_j \\sim normal(0, \\tau_\\beta)\\)\n\\(\\tau_\\alpha \\sim normal(0,  1)\\)\n\\(\\tau_\\beta \\sim normal(0,  1)\\)\nFit the varying slopes and intercept model with lognormal family.4.1 Plot the default `pp_check()`. What do you notice?Estimate the elpd_loo for the lognormal model. 4.2: The elpd_loo estimate for the lognormal model is , and the standard error estimate is .4.3 How does this compare to the other models with respect to LOO-CV?Next, to address potential non-linear effect with respect to Days, you can try with a spline term for Days. This allows for a non-linear population-level effect of Days on Reaction time. Add the term `s(Days)` to the formula for the lognormal model, and compare to the other models using pp_check and loo_compare. Use a normal(0, 1) prior on the `sDays_1` term.4.4 Based on elpd_loo comparison:4.5 Based on elpd_loo, the order of the four models from best to worst predictive performance is:",
    "crumbs": [
      "Assignments",
      "Assignment 8"
    ]
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "Assignment 5",
    "section": "",
    "text": "The exercises here refer to the lecture 5/BDA chapter 11 content. The main topics for this assignment are the MCSE and importance sampling.\nThe exercises constitute 96% of the Quiz 5 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a rendered html file (to access the qmd file click the “&lt;/&gt; Code” button at the top right hand corner of the template)\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\n\n\nAs you've learned in the previous assignments, in some cases we have closed form solution for useful posterior summaries for parameter vector \\( \\theta \\). 1.1 Why are Monte Carlo and other sampling based methods for posterior evaluation of functions \\( f(\\theta) \\) convenient?\n\n    \n        \n            \n        \n    \nWe now briefly review some Monte Carlo methods. Assume we want to obtain draws from \\(p(\\theta|y)\\). Possibly the simplest way, is to apply grid sampling (see lecture 4). Briefly, the general idea of this method is to identify range of values for \\(\\theta\\) which captures almost all the mass of the posterior distribution, divide this range into grid (small intervals for 1D case, small squares for 2D case and so on), compute the unnormalised posterior density at a grid of values, normalize them by approximating the distribution as a step function over the grid and setting the total probability in the grid to 1. Then we can sample from the discrete distribution over values of a grid (more information can be found on page 76 of BDA3). However, this approach poses a certain challenge for the case of multivariate \\(\\theta\\).\n\n    \n        \n            1.2 What is the main issue of grid sampling:\n        \n    \nWe may try to apply more elaborated methods such as rejection sampling (page 264 of BDA3). Rejection sampling is based on defining a positive function \\(g(\\theta)\\), so that we can obtain draws from the probability density proportional to \\(p(\\theta)\\) and accept those draws according to a certain rule (check lecture 4).1.3 : What problem(s) appear with rejection sampling:\n\n    \nThe most popular way to obtain posterior draws nowadays is MCMC. 2.1 What is a Markov chain?2.2 Which of the following is not a Markov chain?2.3 In question 2.2 we assumed discrete sequences. For the continuous case, we can use conditional transition distribution \\( T_t(\\theta^t |\\theta^{t-1}) \\) for a set of random variables \\( \\theta^1,\\theta^2,\\dotsc \\) to describe the probability density \\( p(\\theta^t | \\theta^1, \\dotsc , \\theta^{t-1}) = p(\\theta^t | \\theta^{t-1}) \\), given some initial point \\( \\theta^0 \\). What are the two steps we need to prove for the Markov chain to eventually produce valid series of draws from the posterior \\( p(\\theta |y) \\)?2.4 What are the necessary and sufficient conditions to prove that a Markov chain has a unique stationary distribution?2.5 Why is it often necessary to discard the first draws of the MCMC chain?2.6 Why might MCMC be preferable to grid and rejection sampling? \n\nThe Metropolis-Hastings algorithm is a relatively simple MCMC algorithm, yet it is foundational for more advanced algorithms, such as the Hamiltonian Monte Carlo algorithm you will encounter later in the course. Later in this assignment, you will implement the Metropolis algorithm (page 278 of BDA3). Denote the proposal distribution at time \\( t \\) for parameter vector \\( \\theta^t \\) conditional on \\( \\theta^{t-1} \\) as \\( J_t(\\theta^t|\\theta^{t-1}) \\). For simplicity, we consider here symmetric proposal distributions (otherwise the algorithm would be known as the Metropolis-Hastings algorithm). \n3.1: What is a main idea behind the Metropolis algorithm:3.2: Denote the current proposal by \\( \\theta^*\\) at time t from the proposal distribution \\( J_t(\\theta^* | \\theta^{t-1}) \\). Which one is the correct acceptance ratio, \\( r \\):3.3: Which one is the correct rule for accepting the proposal? Denote the acceptance ratio you've determined in 3.2 by \\(r\\). Set \\( \\theta^t \\) equal to:3.4 Assume the posterior surface has a unique mode. What would eventually happen to the MCMC chain if adopting the rule \\(\\theta^*\\) iff \\( r &gt; 1 \\) and \\( \\theta^{t-1} \\) otherwise?3.5 Retain the assumption made in question 3.4. Why is the posterior mode alone not generally useful for posterior expectations?\n\n\nSuppose you've successfully obtained multiple chains of MCMC draws from the Metropolis algorithm. Remember that the goal for the MCMC chains is to firstly converge to some unique distribution, and that all chains converge to the same distribution (with the hope of that being \\(p(\\theta|y)\\)). You would now like to check if your chains can be trusted to have done so, after having discarded an appropriate amount of draws you used for warm-up.  There are multiple convergence diagnostics and we will discuss some of them here. \nOne way is to investigate the trace plot: check visually whether the chains converged to the same distribution. If they have, we say the chains have mixed. To do this, we plot them in the same figure and observe if something went wrong. Below you are given an example with two chains. Look at them carefully and answer questions below.\n\n\nFigure 1: \n\n4.1: Can you say that your chains converged to the same distribution based on Figure 1:\n\n    \n\nFigure 2: \n4.2: Can you say that your chains are mixing well based on Figure 2:\n\n    \n\n\nTrace plot inspection can be useful when parameter space is small, however, when dealing with large spaces, it becomes inconvenient to analyse trace plots of each parameter separately, therefore we would like to also have some quantitative metrics for investigating convergence. One of them is called Rhat. There are different versions of it, for instance, version from BDA3 book(page 285). The much improved version you will use throughout the course is based on Vehtari et al. (2021). Let's look at the book version to understand why it is preferred to use the modified version.5.1: What is the definition of Rhat from the BDA3 book: 5.2: Which range of values for Rhat would are a good indicator for convergence (see lecture 5)?Imagine a situation where one chain converged to \\(N(0,1)\\) distribution and the other one to Student t with 3 degrees of freedom. The trace plot then looks like:\nFigure 3: 5.3: What do you observe:\n\n    5.4: However, despite of this issue, the Rhat value from the book equals 0.999859, indicating good convergence of the chains. What can be the explanation for this:\n\n    On the contrary, Rhat value from Vehtari et al paper equals 1.39025,  much bigger than recommended 1.01, resolving the above problem. You can find more examples about new Rhat in the paper but also this demo.\n\nAnother useful quantity is the effective sample size. \n\n6.1: Why can we not rely on total sample size of draws from MCMC? \n\n6.2: Suppose you have obtained \\( S \\) draws from your posterior with MCMC. We define the effective sample size as \\( S_{eff} = S/\\tau \\). What does \\( \\tau \\) refer to in this context? 6.3: Look at the trace plots below. For which sequences do you expect HIGHER effective sample size:\n\n\n6.4: Select the autocorrelation function below corresponding to the chains in Figure 4 of the previous question.\n\n\n\n\nIn this exercise, you will implement the Metropolis algorithm. Here you are provided code to get you started fro this part of the assignment. You are provided with the code for a Metropolis algorithm, however, it contains three errors. Your task is to find these errors, correct them and answer the following questions below. \n7.1: Lets denote \"bioassaylp(alpha_propose, beta_propose, x, y, n) - bioassaylp(alpha_previous, beta_previous, x, y, n) + dmvnorm(c(alpha_propose, beta_propose), prior_mean, prior_sigma, TRUE) - dmvnorm(c(alpha_previous, beta_previous), prior_mean, prior_sigma, TRUE)\" as expression 1. How should we correct error 1:\n\n\n    7.2: Lets denote \"if(runif(1) &gt; density_ratio(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n))\" as expression 2. How should we correct error 2:\n\n    7.3: How should we correct error 3:\n\n    After you corrected the errors, you may run sampling. Investigate the code in the notebook and answer the questions below.7.4: How many chains did we run:  .7.5: How many draws including warm-up have we obtained for each individual chain:  .7.6: What is the warm-up length: .7.7: After performing sampling, let's check the convergence of the chains. The next code chunk will produce trace plots. Which one is the correct one:\n\n    \n    \n    \nAfter looking at trace plots, compute Rhat values for both alpha and beta:7.8: Rhat for alpha=, Rhat for beta=\nIn addition to Rhat, compute ESS for for the mean and 0.25 quantile of alpha and beta:7.9: ESS mean for alpha=, ESS mean for beta=.7.10: ESS q0.25 for alpha=, ESS q0.25 for beta=.Let us compare ESS of independent draws and MCMC draws. Use 4000 independent draws from the posterior distribution of the model in the dataset bioassay_posterior in the aaltobda package from Assignment 4.7.11: ESS mean of alpha for bioassay_posterior =, ESS mean of beta for bioassay_posterior =7.12: ESS q0.25 of alpha for bioassay_posterior =, ESS q0.25 of beta for bioassay_posterior =7.13: Visualise scatter plot of posterior draws. Which one is the correct figure:",
    "crumbs": [
      "Assignments",
      "Assignment 5"
    ]
  },
  {
    "objectID": "assignment5.html#assignment-questions",
    "href": "assignment5.html#assignment-questions",
    "title": "Assignment 5",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\n\n\nAs you've learned in the previous assignments, in some cases we have closed form solution for useful posterior summaries for parameter vector \\( \\theta \\). 1.1 Why are Monte Carlo and other sampling based methods for posterior evaluation of functions \\( f(\\theta) \\) convenient?\n\n    \n        \n            \n        \n    \nWe now briefly review some Monte Carlo methods. Assume we want to obtain draws from \\(p(\\theta|y)\\). Possibly the simplest way, is to apply grid sampling (see lecture 4). Briefly, the general idea of this method is to identify range of values for \\(\\theta\\) which captures almost all the mass of the posterior distribution, divide this range into grid (small intervals for 1D case, small squares for 2D case and so on), compute the unnormalised posterior density at a grid of values, normalize them by approximating the distribution as a step function over the grid and setting the total probability in the grid to 1. Then we can sample from the discrete distribution over values of a grid (more information can be found on page 76 of BDA3). However, this approach poses a certain challenge for the case of multivariate \\(\\theta\\).\n\n    \n        \n            1.2 What is the main issue of grid sampling:\n        \n    \nWe may try to apply more elaborated methods such as rejection sampling (page 264 of BDA3). Rejection sampling is based on defining a positive function \\(g(\\theta)\\), so that we can obtain draws from the probability density proportional to \\(p(\\theta)\\) and accept those draws according to a certain rule (check lecture 4).1.3 : What problem(s) appear with rejection sampling:\n\n    \nThe most popular way to obtain posterior draws nowadays is MCMC. 2.1 What is a Markov chain?2.2 Which of the following is not a Markov chain?2.3 In question 2.2 we assumed discrete sequences. For the continuous case, we can use conditional transition distribution \\( T_t(\\theta^t |\\theta^{t-1}) \\) for a set of random variables \\( \\theta^1,\\theta^2,\\dotsc \\) to describe the probability density \\( p(\\theta^t | \\theta^1, \\dotsc , \\theta^{t-1}) = p(\\theta^t | \\theta^{t-1}) \\), given some initial point \\( \\theta^0 \\). What are the two steps we need to prove for the Markov chain to eventually produce valid series of draws from the posterior \\( p(\\theta |y) \\)?2.4 What are the necessary and sufficient conditions to prove that a Markov chain has a unique stationary distribution?2.5 Why is it often necessary to discard the first draws of the MCMC chain?2.6 Why might MCMC be preferable to grid and rejection sampling? \n\nThe Metropolis-Hastings algorithm is a relatively simple MCMC algorithm, yet it is foundational for more advanced algorithms, such as the Hamiltonian Monte Carlo algorithm you will encounter later in the course. Later in this assignment, you will implement the Metropolis algorithm (page 278 of BDA3). Denote the proposal distribution at time \\( t \\) for parameter vector \\( \\theta^t \\) conditional on \\( \\theta^{t-1} \\) as \\( J_t(\\theta^t|\\theta^{t-1}) \\). For simplicity, we consider here symmetric proposal distributions (otherwise the algorithm would be known as the Metropolis-Hastings algorithm). \n3.1: What is a main idea behind the Metropolis algorithm:3.2: Denote the current proposal by \\( \\theta^*\\) at time t from the proposal distribution \\( J_t(\\theta^* | \\theta^{t-1}) \\). Which one is the correct acceptance ratio, \\( r \\):3.3: Which one is the correct rule for accepting the proposal? Denote the acceptance ratio you've determined in 3.2 by \\(r\\). Set \\( \\theta^t \\) equal to:3.4 Assume the posterior surface has a unique mode. What would eventually happen to the MCMC chain if adopting the rule \\(\\theta^*\\) iff \\( r &gt; 1 \\) and \\( \\theta^{t-1} \\) otherwise?3.5 Retain the assumption made in question 3.4. Why is the posterior mode alone not generally useful for posterior expectations?\n\n\nSuppose you've successfully obtained multiple chains of MCMC draws from the Metropolis algorithm. Remember that the goal for the MCMC chains is to firstly converge to some unique distribution, and that all chains converge to the same distribution (with the hope of that being \\(p(\\theta|y)\\)). You would now like to check if your chains can be trusted to have done so, after having discarded an appropriate amount of draws you used for warm-up.  There are multiple convergence diagnostics and we will discuss some of them here. \nOne way is to investigate the trace plot: check visually whether the chains converged to the same distribution. If they have, we say the chains have mixed. To do this, we plot them in the same figure and observe if something went wrong. Below you are given an example with two chains. Look at them carefully and answer questions below.\n\n\nFigure 1: \n\n4.1: Can you say that your chains converged to the same distribution based on Figure 1:\n\n    \n\nFigure 2: \n4.2: Can you say that your chains are mixing well based on Figure 2:\n\n    \n\n\nTrace plot inspection can be useful when parameter space is small, however, when dealing with large spaces, it becomes inconvenient to analyse trace plots of each parameter separately, therefore we would like to also have some quantitative metrics for investigating convergence. One of them is called Rhat. There are different versions of it, for instance, version from BDA3 book(page 285). The much improved version you will use throughout the course is based on Vehtari et al. (2021). Let's look at the book version to understand why it is preferred to use the modified version.5.1: What is the definition of Rhat from the BDA3 book: 5.2: Which range of values for Rhat would are a good indicator for convergence (see lecture 5)?Imagine a situation where one chain converged to \\(N(0,1)\\) distribution and the other one to Student t with 3 degrees of freedom. The trace plot then looks like:\nFigure 3: 5.3: What do you observe:\n\n    5.4: However, despite of this issue, the Rhat value from the book equals 0.999859, indicating good convergence of the chains. What can be the explanation for this:\n\n    On the contrary, Rhat value from Vehtari et al paper equals 1.39025,  much bigger than recommended 1.01, resolving the above problem. You can find more examples about new Rhat in the paper but also this demo.\n\nAnother useful quantity is the effective sample size. \n\n6.1: Why can we not rely on total sample size of draws from MCMC? \n\n6.2: Suppose you have obtained \\( S \\) draws from your posterior with MCMC. We define the effective sample size as \\( S_{eff} = S/\\tau \\). What does \\( \\tau \\) refer to in this context? 6.3: Look at the trace plots below. For which sequences do you expect HIGHER effective sample size:\n\n\n6.4: Select the autocorrelation function below corresponding to the chains in Figure 4 of the previous question.\n\n\n\n\nIn this exercise, you will implement the Metropolis algorithm. Here you are provided code to get you started fro this part of the assignment. You are provided with the code for a Metropolis algorithm, however, it contains three errors. Your task is to find these errors, correct them and answer the following questions below. \n7.1: Lets denote \"bioassaylp(alpha_propose, beta_propose, x, y, n) - bioassaylp(alpha_previous, beta_previous, x, y, n) + dmvnorm(c(alpha_propose, beta_propose), prior_mean, prior_sigma, TRUE) - dmvnorm(c(alpha_previous, beta_previous), prior_mean, prior_sigma, TRUE)\" as expression 1. How should we correct error 1:\n\n\n    7.2: Lets denote \"if(runif(1) &gt; density_ratio(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n))\" as expression 2. How should we correct error 2:\n\n    7.3: How should we correct error 3:\n\n    After you corrected the errors, you may run sampling. Investigate the code in the notebook and answer the questions below.7.4: How many chains did we run:  .7.5: How many draws including warm-up have we obtained for each individual chain:  .7.6: What is the warm-up length: .7.7: After performing sampling, let's check the convergence of the chains. The next code chunk will produce trace plots. Which one is the correct one:\n\n    \n    \n    \nAfter looking at trace plots, compute Rhat values for both alpha and beta:7.8: Rhat for alpha=, Rhat for beta=\nIn addition to Rhat, compute ESS for for the mean and 0.25 quantile of alpha and beta:7.9: ESS mean for alpha=, ESS mean for beta=.7.10: ESS q0.25 for alpha=, ESS q0.25 for beta=.Let us compare ESS of independent draws and MCMC draws. Use 4000 independent draws from the posterior distribution of the model in the dataset bioassay_posterior in the aaltobda package from Assignment 4.7.11: ESS mean of alpha for bioassay_posterior =, ESS mean of beta for bioassay_posterior =7.12: ESS q0.25 of alpha for bioassay_posterior =, ESS q0.25 of beta for bioassay_posterior =7.13: Visualise scatter plot of posterior draws. Which one is the correct figure:",
    "crumbs": [
      "Assignments",
      "Assignment 5"
    ]
  },
  {
    "objectID": "assignment9.html",
    "href": "assignment9.html",
    "title": "Assignment 9",
    "section": "",
    "text": "The exercises here refer to the lecture 9-10 and BDA3 Chapter 9 content.\nThe exercises constitute 96% of the Quiz 9 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a rendered html file (to access the qmd file click the “&lt;/&gt; Code” button at the top right hand corner of the template)\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\nLecture 9-10/Chapter 9 of BDA Quiz (96% of grade)\n\n\nThe coefficient of determination, \\( R^2 \\), measures the proportion of variance explained by the model compared to the total variance of the model. This metric can be easily extended to a Bayesian definition. Let \\( \\tilde{y} \\) denote future data. Suppose a model uses covariates X to model the target y with parameters \\( \\theta \\). Define \\( \\mu_n = E[\\tilde{y}_n |X_n,\\theta] \\) as the expected predictor for future observations for all n and \\( \\epsilon_n =  \\tilde{y}_n - \\mu_n \\) as the modeled residual. \n1.1: While for certain priors the implied probability distribution for Bayes \\( R^2 \\) may be derived analytically, we can generally find the push-forward distribution with Monte-Carlo Integration. Which of the below correctly characterises the s-th draw from the Bayes \\(R^2\\) distribution?\n\n1.2 What is the intuition behind the Bayesian \\(R^2\\)? \n1.3: Assume a normal observation model with variance \\(\\sigma^2\\) and the predictor terms includes covariates X and coefficients \\( \\beta \\). Which of the below is the correct expression for a draw from the Bayes-\\(R^2\\) distribution?\n1.4: With some further assumptions, we can formulate Bayes-\\( R^2 \\) similarly for other observation families. For logistic regression, define \\( \\mu_n^{(s)} = logit^{-1}(X_n^T\\beta^{(s)}) = \\pi_n^{(s)} \\) and \\( E[var( \\epsilon_n^{(s)}) | \\theta^{(s)}] = \\pi_n^{(s)}(1-\\pi_n^{(s)})   \\). Which of the below is the correct expression for a draw from the Bayes-\\(R^2\\) distribution?\n\nFor other GLMs, it is not so straighforward to define the Bayes-\\( R^2 \\), so in this course, we recommend showing the Bayes-\\( R^2 \\) only for normal and logistic regression models. \nThe prior-predictive distribution of \\(R^2\\) is also useful to look at in order to understand the impact of the prior choices on the expected amount of variance fit. For the below, assume \\( y_i \\sim normal(\\beta^TX_i,\\sigma) \\). Assume the covariates, \\(X \\in \\mathbb{R}^{N \\times p} \\), have been scaled to have 0 mean and variance 1, and p = 26.\n1.5: Assume standard normal priors for \\(\\beta\\) and an exponential prior with rate 1/3 for \\(\\sigma\\). Draw from the priors 4000 times, and generate prior predictive values for Bayes-\\(R^2\\). Which of the figures below refers to the correct implied \\(R^2\\) distribution?\n\n1.6: With these priors you can derive the variance of the predictor term. What is the standard deviation of the predictor term?\nYou may also put a prior directly on the Bayesian-\\( R^2 \\). This is simplest for the normal linear regression model and implies a joint prior for \\( (\\beta,\\sigma) \\), where we specify beliefs about the \\( R^2 \\) and learn the rest of the hyper-parameters in the prior for \\( \\beta \\) via partial pooling. In the  prior hierarchy below, the beta distribution is parameterised in terms of a location \\( \\mu_{R^2}\\) and scale \\( \\sigma_{R^2} \\), where the relationship to the usual parameterisation of the \\(beta (\\alpha,\\beta)\\) distribution is \\( \\alpha = \\mu_{R^2}\\sigma_{R^2}, \\beta = (1-\\mu_{R^2})\\sigma_{R^2}  \\):\n\n\\( \\beta_j  \\sim normal(0, \\sqrt(\\tau^2\\psi_j\\sigma^2)) \\)\\( \\tau^2 = R^2/(1-R^2) \\)\\( R^2 \\sim beta(\\mu_{R^2},\\sigma_{R^2}) \\) \\( \\psi \\sim Dir(\\xi) \\)\\( \\sigma \\sim \\pi() \\) (some distribution)\n\nHere, we use the relationship between the variance of the predictor term \\( X\\beta \\) and \\(R^2\\) to relate inference on the \\( R^2 \\) space to the population variance of \\( \\beta \\), \\(\\tau^2\\). If you are curious about this relationship, Zhang et al. (2022) provide derivations.  \\( \\tau^2 \\) is the population variance for the coefficients \\( \\beta \\), which is allocated to individual coefficients via a weight vector \\( \\psi \\). Positivity of weights \\( \\psi  \\) and sum to 1 constraint are enforced by assuming a Dirichlet distribution as prior. You may interpret \\( \\psi \\) as determining the importance of a variable in explaining the variance of the target data, \\(y\\) (larger \\( \\psi_j \\) compared to \\( \\psi_{-j} \\) means that the j-th coefficient has larger variance and thus the j-th covariate contributes relatively more to the fraction of variance explained, \\( R^2 \\) ). The concentrations of the Dirichlet distribution, \\( \\xi \\) can be used to encode prior information about the relative importance of covariates in terms of the fraction of variance explained. In absence of such prior knowledge, which is likely your starting point of your analysis, you may set these concentrations to 1. This implies that you think the covariates have equal importance. If you want to enforce sparsity on the coefficient vector, try setting to \\( \\xi = 0.3 \\) (this pushes weights to the edges of the p-dimensional simplex)\n\n\n1.8: Assume that \\( \\sigma \\sim exp(1/3) \\), \\( \\mu_{R^2} = 1/3, \\sigma_{R^2} = 3 \\) and \\( \\xi_j = 1 \\) for all j in 1 to p. Which of the below distributions should the prior predictive Bayes-\\(R^2\\) be closest to? Assume the beta distributions below are parameterised in terms of location and scale.\n1.9: Generate the prior predictive Bayes-\\(R^2\\) using the \\(R^2 \\) prior in 1.8 and and exponential prior with rate 1/3 for \\(\\sigma\\). Draw from the priors 4000 times, and generate prior predictive values for Bayes-\\(R^2\\). Which of the figures below refers to the correct implied \\(R^2\\) distribution?\nWe generally recommend setting the prior for the \\( R^2 \\) with \\( \\mu_{R^2} = 1/3, \\sigma_{R^2} = 3 \\). This is weakly informative toward lower \\( R^2 \\) which may help regularising the coefficients' posterior variance, particularly in higher dimensions. You may experiment in your projects with those hyper-parameters in order to gauge sensitivity. \nBRMS has the R2 prior implemented, and here some cautionary notes: \n\n    The implementation of the prior BRMS assumes you have scaled the covariates to have variance 1, so please pass scaled covariates to the brm function (the target variable should stay as is for easier model comparison).\n    The connection between R2 prior and model R2 is only exact for the normal model\n    We still recommend using the R2 prior in BRMS for all observation families, particularly when you have many covariates and you would otherwise use normal independent priors \n\n\nFor those who want to dig deeper, how would the prior for \\( \\beta \\) need to be adjusted so that the \\( R^2 \\) of the model is invariant to changes in the scale of X? \n\n\n\nNow we apply these priors to a data set in which the goal is to predict Portoguese students' final period math grade based on a moderately large set of covariates (p = 26), including social background and past schooling information.\nUse the data preparation steps in the code template, and estimate a model with normal(0,1) priors on the regression coefficients, and otherwise use default priors.\n2.1: Plot the marginal posteriors of the coefficients with this prior, what do you observe?2.2: Compute and plot the prior and posterior Bayes-\\(R^2\\) distributions. Which of the figures below refers to the correct the implied \\(R^2\\) distribution with normal(0,1) priors on the regression coefficients?\n2.3: Compute the mean of the posterior R2 distribution  and the mean of the loo R2 .2.4: What does the difference between the mean of the posterior R2 and LOO cross-validated R2 distribution indicate?\n\n\n2.5: Now use the \\( R^2 \\) prior with \\( \\mu_{R^2} = 1/3, \\sigma_{R^2} = 3 \\) and concentration values of 1, otherwise use default priors from BRMS. Plot the marginal posteriors of the coefficients with this prior, what do you observe compared to the marginal posteriors of the normal(0,1) prior?\n2.6: Compute and plot the prior and posterior Bayes-\\(R^2\\) distributions. Which of the figures below refers to the correct the implied \\(R^2\\) distribution using the \\( R^2 \\) prior ?\n\n2.7: Compute the mean of the posterior predictive R2 distribution  and the mean of the loo R2 .\n2.8: What does the difference between the mean of the posterior R2 and LOO cross-validated R2 distribution indicate?\n\n3. Bayesian Decision theory\n3.1 Which of the following are steps of decision analysis according to BDA3? \n\n\n\nAssume we created a model that estimates life expectancy of a person based on various covariates such as gender, history of diseases and so on. We conducted inference in a Bayesian way by obtaining samples of the parameters of our model. \nA 80-year-old man with an apparently malignant tumor in the lung must decide between the three options of radiotherapy, surgery, or no treatment. He visits us and asks to use our model to help him with his decision. A priori doctors told the man that there is a 80% chance that the tumor is malignant. By using our marvellous model, we sampled posterior predictive draws (ppd) for all cases which are interesting for us. To keep things simpler, we have obtained only 5 posterior draws from the distribution of the predicted remaining lifetime.\n\n    if the man has lung cancer and radiotherapy is performed, ppd of his life expectancy are: [4.4, 5.3, 5.1, 3.2, 4.9]\n    if the man has lung cancer and surgery is done, which is dangerous for this age and doctors give 30% chance of mortality, ppd of his life expectancy in a case of successful surgery are: [5.9, 6.3, 6.2, 5.7, 7]\n    if the man has lung cancer and no treatment is given, ppd of his life expectancy are: [1.1, 0.7, 0.9, 1.7, 0.4]\n    if the man does not have lung cancer (no malignant tumor),  ppd of his life expectancy are: [6.8, 5.5, 8.8, 7.4, 9]. Assume also that if man is healthy, radiotherapy or successful surgery do not affect his life expectancy, however he still has 30% of dying during the surgery \n\n\n\n    \n        \n            We shall determine the decision that maximizes patient’s life expectancy. Compute expected life expectancy for the above cases using posterior predictive draws and given probabilities:\n            4.1: man does not have lung cancer (no malignant tumor) and no treatment is given or radiotherapy is performed: \n            4.2: man does not have lung cancer (no malignant tumor) and surgery is done: \n            4.3: man has lung cancer and performs radiotherapy: \n            4.4: man has lung cancer and surgery is done: \n            4.5: man has lung cancer and no treatment is given: \n            Then, using these quantities, compute expected life expectancy under each treatment (you should use information that there is 20% chance that the man does not have lung cancer (no malignant tumor)):\n            4.6: with radiotherapy: \n            4.7: with surgery: \n            4.8: with no treatment: \n            4.9: What should the man choose to maximize his expected life expectancy?",
    "crumbs": [
      "Assignments",
      "Assignment 9"
    ]
  },
  {
    "objectID": "assignment9.html#assignment-questions",
    "href": "assignment9.html#assignment-questions",
    "title": "Assignment 9",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\nLecture 9-10/Chapter 9 of BDA Quiz (96% of grade)\n\n\nThe coefficient of determination, \\( R^2 \\), measures the proportion of variance explained by the model compared to the total variance of the model. This metric can be easily extended to a Bayesian definition. Let \\( \\tilde{y} \\) denote future data. Suppose a model uses covariates X to model the target y with parameters \\( \\theta \\). Define \\( \\mu_n = E[\\tilde{y}_n |X_n,\\theta] \\) as the expected predictor for future observations for all n and \\( \\epsilon_n =  \\tilde{y}_n - \\mu_n \\) as the modeled residual. \n1.1: While for certain priors the implied probability distribution for Bayes \\( R^2 \\) may be derived analytically, we can generally find the push-forward distribution with Monte-Carlo Integration. Which of the below correctly characterises the s-th draw from the Bayes \\(R^2\\) distribution?\n\n1.2 What is the intuition behind the Bayesian \\(R^2\\)? \n1.3: Assume a normal observation model with variance \\(\\sigma^2\\) and the predictor terms includes covariates X and coefficients \\( \\beta \\). Which of the below is the correct expression for a draw from the Bayes-\\(R^2\\) distribution?\n1.4: With some further assumptions, we can formulate Bayes-\\( R^2 \\) similarly for other observation families. For logistic regression, define \\( \\mu_n^{(s)} = logit^{-1}(X_n^T\\beta^{(s)}) = \\pi_n^{(s)} \\) and \\( E[var( \\epsilon_n^{(s)}) | \\theta^{(s)}] = \\pi_n^{(s)}(1-\\pi_n^{(s)})   \\). Which of the below is the correct expression for a draw from the Bayes-\\(R^2\\) distribution?\n\nFor other GLMs, it is not so straighforward to define the Bayes-\\( R^2 \\), so in this course, we recommend showing the Bayes-\\( R^2 \\) only for normal and logistic regression models. \nThe prior-predictive distribution of \\(R^2\\) is also useful to look at in order to understand the impact of the prior choices on the expected amount of variance fit. For the below, assume \\( y_i \\sim normal(\\beta^TX_i,\\sigma) \\). Assume the covariates, \\(X \\in \\mathbb{R}^{N \\times p} \\), have been scaled to have 0 mean and variance 1, and p = 26.\n1.5: Assume standard normal priors for \\(\\beta\\) and an exponential prior with rate 1/3 for \\(\\sigma\\). Draw from the priors 4000 times, and generate prior predictive values for Bayes-\\(R^2\\). Which of the figures below refers to the correct implied \\(R^2\\) distribution?\n\n1.6: With these priors you can derive the variance of the predictor term. What is the standard deviation of the predictor term?\nYou may also put a prior directly on the Bayesian-\\( R^2 \\). This is simplest for the normal linear regression model and implies a joint prior for \\( (\\beta,\\sigma) \\), where we specify beliefs about the \\( R^2 \\) and learn the rest of the hyper-parameters in the prior for \\( \\beta \\) via partial pooling. In the  prior hierarchy below, the beta distribution is parameterised in terms of a location \\( \\mu_{R^2}\\) and scale \\( \\sigma_{R^2} \\), where the relationship to the usual parameterisation of the \\(beta (\\alpha,\\beta)\\) distribution is \\( \\alpha = \\mu_{R^2}\\sigma_{R^2}, \\beta = (1-\\mu_{R^2})\\sigma_{R^2}  \\):\n\n\\( \\beta_j  \\sim normal(0, \\sqrt(\\tau^2\\psi_j\\sigma^2)) \\)\\( \\tau^2 = R^2/(1-R^2) \\)\\( R^2 \\sim beta(\\mu_{R^2},\\sigma_{R^2}) \\) \\( \\psi \\sim Dir(\\xi) \\)\\( \\sigma \\sim \\pi() \\) (some distribution)\n\nHere, we use the relationship between the variance of the predictor term \\( X\\beta \\) and \\(R^2\\) to relate inference on the \\( R^2 \\) space to the population variance of \\( \\beta \\), \\(\\tau^2\\). If you are curious about this relationship, Zhang et al. (2022) provide derivations.  \\( \\tau^2 \\) is the population variance for the coefficients \\( \\beta \\), which is allocated to individual coefficients via a weight vector \\( \\psi \\). Positivity of weights \\( \\psi  \\) and sum to 1 constraint are enforced by assuming a Dirichlet distribution as prior. You may interpret \\( \\psi \\) as determining the importance of a variable in explaining the variance of the target data, \\(y\\) (larger \\( \\psi_j \\) compared to \\( \\psi_{-j} \\) means that the j-th coefficient has larger variance and thus the j-th covariate contributes relatively more to the fraction of variance explained, \\( R^2 \\) ). The concentrations of the Dirichlet distribution, \\( \\xi \\) can be used to encode prior information about the relative importance of covariates in terms of the fraction of variance explained. In absence of such prior knowledge, which is likely your starting point of your analysis, you may set these concentrations to 1. This implies that you think the covariates have equal importance. If you want to enforce sparsity on the coefficient vector, try setting to \\( \\xi = 0.3 \\) (this pushes weights to the edges of the p-dimensional simplex)\n\n\n1.8: Assume that \\( \\sigma \\sim exp(1/3) \\), \\( \\mu_{R^2} = 1/3, \\sigma_{R^2} = 3 \\) and \\( \\xi_j = 1 \\) for all j in 1 to p. Which of the below distributions should the prior predictive Bayes-\\(R^2\\) be closest to? Assume the beta distributions below are parameterised in terms of location and scale.\n1.9: Generate the prior predictive Bayes-\\(R^2\\) using the \\(R^2 \\) prior in 1.8 and and exponential prior with rate 1/3 for \\(\\sigma\\). Draw from the priors 4000 times, and generate prior predictive values for Bayes-\\(R^2\\). Which of the figures below refers to the correct implied \\(R^2\\) distribution?\nWe generally recommend setting the prior for the \\( R^2 \\) with \\( \\mu_{R^2} = 1/3, \\sigma_{R^2} = 3 \\). This is weakly informative toward lower \\( R^2 \\) which may help regularising the coefficients' posterior variance, particularly in higher dimensions. You may experiment in your projects with those hyper-parameters in order to gauge sensitivity. \nBRMS has the R2 prior implemented, and here some cautionary notes: \n\n    The implementation of the prior BRMS assumes you have scaled the covariates to have variance 1, so please pass scaled covariates to the brm function (the target variable should stay as is for easier model comparison).\n    The connection between R2 prior and model R2 is only exact for the normal model\n    We still recommend using the R2 prior in BRMS for all observation families, particularly when you have many covariates and you would otherwise use normal independent priors \n\n\nFor those who want to dig deeper, how would the prior for \\( \\beta \\) need to be adjusted so that the \\( R^2 \\) of the model is invariant to changes in the scale of X? \n\n\n\nNow we apply these priors to a data set in which the goal is to predict Portoguese students' final period math grade based on a moderately large set of covariates (p = 26), including social background and past schooling information.\nUse the data preparation steps in the code template, and estimate a model with normal(0,1) priors on the regression coefficients, and otherwise use default priors.\n2.1: Plot the marginal posteriors of the coefficients with this prior, what do you observe?2.2: Compute and plot the prior and posterior Bayes-\\(R^2\\) distributions. Which of the figures below refers to the correct the implied \\(R^2\\) distribution with normal(0,1) priors on the regression coefficients?\n2.3: Compute the mean of the posterior R2 distribution  and the mean of the loo R2 .2.4: What does the difference between the mean of the posterior R2 and LOO cross-validated R2 distribution indicate?\n\n\n2.5: Now use the \\( R^2 \\) prior with \\( \\mu_{R^2} = 1/3, \\sigma_{R^2} = 3 \\) and concentration values of 1, otherwise use default priors from BRMS. Plot the marginal posteriors of the coefficients with this prior, what do you observe compared to the marginal posteriors of the normal(0,1) prior?\n2.6: Compute and plot the prior and posterior Bayes-\\(R^2\\) distributions. Which of the figures below refers to the correct the implied \\(R^2\\) distribution using the \\( R^2 \\) prior ?\n\n2.7: Compute the mean of the posterior predictive R2 distribution  and the mean of the loo R2 .\n2.8: What does the difference between the mean of the posterior R2 and LOO cross-validated R2 distribution indicate?\n\n3. Bayesian Decision theory\n3.1 Which of the following are steps of decision analysis according to BDA3? \n\n\n\nAssume we created a model that estimates life expectancy of a person based on various covariates such as gender, history of diseases and so on. We conducted inference in a Bayesian way by obtaining samples of the parameters of our model. \nA 80-year-old man with an apparently malignant tumor in the lung must decide between the three options of radiotherapy, surgery, or no treatment. He visits us and asks to use our model to help him with his decision. A priori doctors told the man that there is a 80% chance that the tumor is malignant. By using our marvellous model, we sampled posterior predictive draws (ppd) for all cases which are interesting for us. To keep things simpler, we have obtained only 5 posterior draws from the distribution of the predicted remaining lifetime.\n\n    if the man has lung cancer and radiotherapy is performed, ppd of his life expectancy are: [4.4, 5.3, 5.1, 3.2, 4.9]\n    if the man has lung cancer and surgery is done, which is dangerous for this age and doctors give 30% chance of mortality, ppd of his life expectancy in a case of successful surgery are: [5.9, 6.3, 6.2, 5.7, 7]\n    if the man has lung cancer and no treatment is given, ppd of his life expectancy are: [1.1, 0.7, 0.9, 1.7, 0.4]\n    if the man does not have lung cancer (no malignant tumor),  ppd of his life expectancy are: [6.8, 5.5, 8.8, 7.4, 9]. Assume also that if man is healthy, radiotherapy or successful surgery do not affect his life expectancy, however he still has 30% of dying during the surgery \n\n\n\n    \n        \n            We shall determine the decision that maximizes patient’s life expectancy. Compute expected life expectancy for the above cases using posterior predictive draws and given probabilities:\n            4.1: man does not have lung cancer (no malignant tumor) and no treatment is given or radiotherapy is performed: \n            4.2: man does not have lung cancer (no malignant tumor) and surgery is done: \n            4.3: man has lung cancer and performs radiotherapy: \n            4.4: man has lung cancer and surgery is done: \n            4.5: man has lung cancer and no treatment is given: \n            Then, using these quantities, compute expected life expectancy under each treatment (you should use information that there is 20% chance that the man does not have lung cancer (no malignant tumor)):\n            4.6: with radiotherapy: \n            4.7: with surgery: \n            4.8: with no treatment: \n            4.9: What should the man choose to maximize his expected life expectancy?",
    "crumbs": [
      "Assignments",
      "Assignment 9"
    ]
  },
  {
    "objectID": "assignment6.html",
    "href": "assignment6.html",
    "title": "Assignment 6",
    "section": "",
    "text": "The exercises here refer to the lecture 6/BDA chapter 12 content. The main topics for this assignment are the MCSE and importance sampling.\nThe exercises constitute 96% of the Quiz 6 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a rendered html file (to access the qmd file click the “&lt;/&gt; Code” button at the top right hand corner of the template)\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\n\nThis week's assignment focuses on building the foundations for using frontier MCMC methods and the probabilistic programming language Stan. We will directly code in Stan, but later assignments will use the brms package for estimating Stan models. \n\n\n1.1: What is the intuition behind HMC as described in the course lectures?  In order to generate good proposals, HMC uses the Hamiltonian function and it's partial derivatives to generate a path along the surface of the log posterior. As in the lecture, define \\( \\phi \\) as the momentum variable which is of the same dimension as the parameter vector \\( \\theta \\). The Hamiltonian function has two terms \\( U(\\theta) \\) and \\( K(\\phi) \\).\n1.2 What is the intuition behind the term \\( U( \\theta ) \\)? \n1.3 What is the intuition behind the term \\( K( \\phi ) \\)? \n1.4 The partial derivatives of the Hamiltonian, also known as Hamilton's equations, determine how \\( \\theta \\) and \\( \\phi \\) change during MCMC. What problem occurs when implementing Hamilton's equations computationally? \n1.5 All HMC implementations on the computer need to discretise the simulated trajectory dictated by Hamilton's equations. Which computational method does Stan (and most other HMC-based algorithms) use for discretisation? \n\n\n1.6: It is not necessary in this course to know the computational details behind the leapfrog integrator, only that it is applied for L steps along the Hamiltonian trajectory with step size, \\(\\epsilon\\). The figure below by Neal (2012) shows dynamic simulation in the joint position-momentum space using leapfrog method. Based on these figures, which of the following statements is false?\n\nFigure 1HMC has two general steps at each iteration of the MCMC chain. Denote the current state of the MCMC chain as t, then1) we draw a new momentum variable \\( \\phi \\) (often assumed to distributed marginally Gaussian) and2) perform a Metropolis update with \\( r=\\exp\\left(-H(\\theta^*,\\phi^*)+H(\\theta^{(t-1)},\\phi^{(t-1)})\\right) \\), where Hamiltonian dynamics are used to produce the proposal.The two parameters of the algorithm, number of steps L and step size \\(\\epsilon\\), need to be tuned. 1.7: What can happen eventually, when allowing the trajectory length, defined as step size times number of steps, \\(\\epsilon L\\), to be long enough? Check out this interactive demo (algorithm=HamiltonianMC, target=standard) and set Leapfrog steps equal to 75 for visual intuition (if the demo freezes, close the demo, restart and instead of sliders, make the control changes by editing the values in the numeric fields). Do not adjust anything else in the demo. To avoid this behaviour that static HMC with fixed integration time (number of steps times the step size) may have, the No-U-Turn (NUTS) algorithm by Hoffman and Gelman (2014) performs automatic tuning: neither the step size nor number of steps need be specified by the user. NUTS uses a tree-building algorithm (see the slides) to adaptively determine the number of steps, L,  while the step size is adapted during the warm-up phase according to a target average acceptance ratio. To gain some more intuition on the behaviour of the adaptivity of NUTS, open the interactive demo again with his link (algorithm=EfficientNUTS, target=banana). Set Autoplay delay to around 500, and set Leapfrog \\(\\delta\\) t to 0.03. This algorithm corresponds to Algorithm 3 in Hoffman and Gelman (2014), where for a fixed \\( \\epsilon \\), the algorithm adaptively determines the number of steps, L.1.8: What do you observe?1.9: On the other hand, set Leapfrog \\(\\delta\\) t to 0.6, all else equal. What do you observe?The user does not need to select the stepsize directly. Stan includes also adaptation of the step size in the warmup phase using stochastic optimization called dual averaging. The user specifies a target acceptance ratio (in Stan actually target for expected discretization error), with argument adapt_delta, and a number of iterations during which adaptation of \\( \\epsilon L \\) occurs (warm-up draws). Open, the interactive demo again with this link (algorithm=DualAveragingNUTS, target=banana), and adjust the Autoplay delay to around 70, but otherwise keep the default options, particularly, keep the target acceptance ratio (here \\(\\delta\\)) at 0.65. On the top left-hand corner m/M_adapt tells you how many draws have been taken compared to number of warm-up draws. Wait until m/M_adapt is at least 50/200.1.10: What do you observe with the first couple of iterations? 1.11: What do you observe with sufficient warm-up? 1.12: Now set the target acceptance ratio to 0.95. What do you observe?1.13: Now set the target acceptance ratio to the smallest possible value. What do you observe?The current Stan HMC-NUTS implementation has some further enhancements, but we will not go to details of those. The main algorithm paramaters are adapt_delta and max_treedepth options.adapt_delta specifies the target expected discretization error (in the same scale as the average proposal acceptance ratio), during the warm-up phase and max_treedepth determines the maximum number of tree doublings in dynamic simulation and thus determine also the maximum number of steps taken. The default in most packages using Stan is setting adapt_delta=0.8. 1.14: What should happen when you increase adapt_delta, all else equal?max_treedepth controls the maximum number of doublings in the tree-building algorithm and thus controls the maximum number of steps in Hamiltonian simulation. This allows the sampler to explore further away in the distribution, which can be beneficial when dealing with complex posteriors. The default in Stan is max_treedepth = 10. 1.15: What is the main cost to increasing the max_treedepth?1.16: Despite the adaptated step-szie, you may encounter challenging posteriors, e.g. with highly varying curvature in log-density. What can happen if the step-size is too big compared to the curvature of the log-density? \n\n\nFrom 2018 to 2023, we have been keeping track of assignment submissions for the BDA course given the number of submissions for the 1st assignment. We will fit a simple linear model to answer two questions of interest:\n\n    What is the trend of student retention as measured by assignment submissions?\n    Given the submission rates for assignments 1–8, how many students will complete the final 9th assignment (and potentially pass the course)?\n\nBelow is broken Stan code for a linear model. In the following, we write the equations following the Stan distributional definitions. See Stan documentation for the definitions related to the normal distribution.\n\\(p(y | x, \\alpha, \\beta, \\sigma) = \\text{normal}(y | \\alpha + \\beta x, \\sigma) \\) (normal model)\\(p(\\alpha, \\beta, \\sigma) \\propto \\text{const.} \\) (improper flat prior)\nIn both the statistical model above and in the Stan model below, \\(x \\in \\mathbb{R}^N\\) and \\(y \\in \\mathbb{R}^N \\) are vectors of the covariates / predictors (the assignment number) and vectors of the observation (proportions of students who have handed in the respective assignment). \\(\\alpha \\in \\mathbb{R}\\) is the unknown scalar intercept, \\(\\beta \\in \\mathbb{R}\\) is the unknown scalar slope and \\(\\sigma \\in \\mathbb{R}_{&gt;0}\\) is the unknown scalar observation standard deviation. The statistical model further implies\\( p(y_{pred.} | x_{pred.}, \\alpha, \\beta, \\sigma) = \\text{normal}(y_{pred.} | \\alpha + \\beta x_{pred.}, \\sigma) \\)as the predictive distribution for a new observation \\(y_{pred.}\\) at a given new covariate value \\( x_{pred.} \\). The broken Stan model code: \n\ndata {\n    // number of data points\n    int&lt;lower=0&gt; N; \n    // covariate / predictor\n    vector[N] x; \n    // observations\n    vector[N] y; \n    // number of covariate values to make predictions at\n    int&lt;lower=0&gt; N_predictions;\n    // covariate values to make predictions at\n    vector[N_predictions] x_predictions; \n}\nparameters {\n    // intercept\n    real alpha; \n    // slope\n    real beta; \n    // the standard deviation should be constrained to be positive\n    real&lt;upper=0&gt; sigma; \n}\ntransformed parameters {\n    // deterministic transformation of parameters and data\n    vector[N] mu = alpha + beta * x // linear model\n}\nmodel {\n    // observation model\n    y ~ normal(mu, sigma); \n}\ngenerated quantities {\n    // compute the means for the covariate values at which to make predictions\n    vector[N_predictions] mu_pred = alpha + beta * x_predictions;\n    // sample from the predictive distribution normal(mu_pred, sigma).\n    array[N_predictions] real y_pred = normal_rng(to_array_1d(mu), sigma);\n}\nFirstly, let's review some Stan syntax.\n\n2.1: What is the function of the data block? \n2.2 What is the function of the parameters block? \n\n\n2.3 Can you use statements (e.g. real&lt;lower=0&gt; theta = lambda^2) in the parameters code block, where lambda is some other variable? \n2.4: What is the function of the transformed parameters block?\n2.5: What is the function of the model block? \n2.6: As you've learned in the lecture or from the Stan documentation, log densities can be added to the target density either via the distribution statement using ~ or via the log probability increment statement using target +=. Furthermore, we don't need to include constant terms. Assume the model block has a line   theta ~ normal(0,1);. How could you equivalently increment the log density to get the same increment (ignoring the possible difference in the constants)?\n2.7: Why can the normalising constant(s) be dropped when using MCMC (this holds for e.g. variational inference and optimisation too)?\n\n\nStan language allows writing the models as usually written in books and articles. As you've learned during the course, a collection of distribution statements define a joint distribution as a product of component distributions. \nSuppose your model is the following:\n\\( p(y|\\mu,\\sigma) = \\text{normal}(y|\\mu,\\sigma) \\)\\( p(\\mu) = \\text{normal}(\\mu|0,1) \\)\\( p(\\sigma) = \\text{normal}^+(\\sigma|0,10) \\)\n\n2.8: What are correct ways to write your model in the model block? In the below, assume that there is a line-break after each semi-colon, and that the variables have been appropriately declared in the parameter blocks.\nWhen writing complicated models, it may happen that some distribution statement is accidentally repeated twice. Check out this page in the Stan manual to see what happens in this case. \n2.9: What is the function of the generated quantities block?\n\nNow, let's return to the student retention model code, shown above.\n2.10: What are the three mistakes in the Stan model code above? \nYou may find some of the mistakes in the code using Stan syntax checker. If you copy the Stan code to a file ending .stan and open it in RStudio (you can also choose from RStudio menu File \\(\\rightarrow\\)New File\\(\\rightarrow\\)Stan file to create a new Stan file), the editor will show you some syntax errors. More syntax errors might be detected by clicking `Check’ in the bar just above the Stan file in the RStudio editor. Note that some of the errors in the presented Stan code may not be syntax errors.\nUse the code in the template to first compile your model using CmdStanR (which is a handy interface for CmdStan which transplies Stan model code to C++ which is compiled to executable program which can do the actual sampling), run the inference with the supplied data, and finally create the plot to answer the following questions. \n\nDefine the term of the model \\( \\mu = \\alpha + \\beta x \\) as the linear predictor.\n2.11: What is the solid red line plotting?\n2.12: What are the dashed red lines referring to?\n2.13: How and why are these different from the corresponding grey lines?\n2.14: What is the general trend of student retention as measured by the assignment submissions?\n2.15: Does it do a good job predicting the proportion of students who submit the final 9th assignment?\n2.16: What modeling choice could you make to improve the prediction for the given data set?\n\n\nAnother benefit of the HMC-NUTS algorithm over simpler non-gradient based MCMC algorithms, is that we have access to many diagnostic tools related to the posterior geometry that we would otherwise not have. This feedback is helpful for modeling and also for debugging code, and therefore an essential part of the Bayesian workflow. A model type which is likely to cause problems is logistic regression with complete separation in the data. This creates an unbounded likelihood.\n3.1: Why is it problematic to use flat, improper priors for this likelihood?\nUsing the data generated from the template, compile and run the following Stan model:\n\n// logistic regression\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; M;\n  array[N] int&lt;lower=0,upper=1&gt; y;\n  matrix[N,M] x;\n}\nparameters {\n  real alpha;\n  vector[M] beta;\n}\nmodel {\n  y ~ bernoulli_logit_glm(x, alpha, beta);\n}3.2: You can use the function [fit object name]$diagnostic summary() to check for the number of divergent transitions and max_treedepth exceedences. What do you see?3.3: You can examine the problematic behaviour of MCMC  by looking at parameter specific sampling diagnostics using the summarize_draws function discussed last week. To gain visual intuition use bayesplot's mcmc_pairs function to plot histograms and bivariate scatter plots of the posteriors. What do you observe?Before thinking about changing the model, a first step should be to check for any easy mistakes made in the Stan code. The Stan compiler has a pedantic mode to help spot such issues. By default the pedantic mode is not enabled, but we can use option pedantic = TRUE at compilation time, or after compilation with the check_syntax method.3.4: Use the function [Stan model]$check_syntax(pedantic = TRUE). What warning message(s) do you get?3.5: Set normal(0,10) priors for both parameters, what do you find from the MCMC output?As you've learned during the course, using proper priors, even when they are wide, are always preferable to stabilise inference and make the model generative. You'll learn next week more about priors. 3.6: Sometimes, when adjusting Stan model code you may have removed a variable from the model block, but left the declaration in the parameters block. Add such a variable to your model. What do you see from convergence diagnostics (it may also help you visualise the MCMC chains using mcmc_pairs and mcmc_trace)? 3.7: Use check_syntax(pedantic = TRUE), would you have been able to detect this problem from the output?A further important problem is that of high correlation between parameters in the posterior, which may lead to slow exploration and divergent transitions. Sometimes, we can address this by slightly re-writing the model. Check out the lecture's discussion the Kilpisjärvi case study. More on that in the weeks to follow.  \n\nNow, we re-investigate the Bioassay model from last week with Stan. If you need a reminder about the model and likelihood definition, check out section 3.7 in BDA3. To make the implementation simpler, we consider the following priors:\nalpha ~ normal(0,2)\nbeta ~ normal(10,10)\n4.1: What is the difference in the prior to last week?\n4.2: Which pre-built function can you use in Stan to compute the likelihood? \nUse the code hints in the template to complete your Stan model. For questions about declarations and functionality of Stan, your first point of reference should always be the Stan Manual (it's been recently revised, be sure to open at least version 2.35). Use 4 chains, with 1000 warmup and 2000 total draws each, use default options for adapt_delta and max_treedepth, and use seed = 4911.  Compile your model, define the data inputs needed, sample from the posterior, and answer the following. To make sure that your model is correct, compare a scatter plot of alpha and beta to last week (the priors are not exactly the same, but the posterior should be quite similar to last week as the priors are relatively weak):\n4.3: Did the Stan model produce any warnings about the sampling efficiency? \n4.4: Use the Rhat function from the posterior package, rhat_basic(), (used in last week's assignment). The Rhat for for alpha  and beta  . \n4.5: The ESS mean for alpha= and for beta=.\n4.6: ESS q0.05 for alpha=, ESS q0.05 for beta=.\nPlot the autocorrelation function for the draws for the chains of alpha and beta using the mcmc_acf function from the bayesplot package and compare that to the autocorrelation function from the Metropolis-Hastings (MH) algorithm you developed last week. You don't need to re-do the model for the MH algorithm with the new priors, but for better comparison this is what you should do outside of this exercise. \n4.7: What do you see?",
    "crumbs": [
      "Assignments",
      "Assignment 6"
    ]
  },
  {
    "objectID": "assignment6.html#assignment-questions",
    "href": "assignment6.html#assignment-questions",
    "title": "Assignment 6",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\n\nThis week's assignment focuses on building the foundations for using frontier MCMC methods and the probabilistic programming language Stan. We will directly code in Stan, but later assignments will use the brms package for estimating Stan models. \n\n\n1.1: What is the intuition behind HMC as described in the course lectures?  In order to generate good proposals, HMC uses the Hamiltonian function and it's partial derivatives to generate a path along the surface of the log posterior. As in the lecture, define \\( \\phi \\) as the momentum variable which is of the same dimension as the parameter vector \\( \\theta \\). The Hamiltonian function has two terms \\( U(\\theta) \\) and \\( K(\\phi) \\).\n1.2 What is the intuition behind the term \\( U( \\theta ) \\)? \n1.3 What is the intuition behind the term \\( K( \\phi ) \\)? \n1.4 The partial derivatives of the Hamiltonian, also known as Hamilton's equations, determine how \\( \\theta \\) and \\( \\phi \\) change during MCMC. What problem occurs when implementing Hamilton's equations computationally? \n1.5 All HMC implementations on the computer need to discretise the simulated trajectory dictated by Hamilton's equations. Which computational method does Stan (and most other HMC-based algorithms) use for discretisation? \n\n\n1.6: It is not necessary in this course to know the computational details behind the leapfrog integrator, only that it is applied for L steps along the Hamiltonian trajectory with step size, \\(\\epsilon\\). The figure below by Neal (2012) shows dynamic simulation in the joint position-momentum space using leapfrog method. Based on these figures, which of the following statements is false?\n\nFigure 1HMC has two general steps at each iteration of the MCMC chain. Denote the current state of the MCMC chain as t, then1) we draw a new momentum variable \\( \\phi \\) (often assumed to distributed marginally Gaussian) and2) perform a Metropolis update with \\( r=\\exp\\left(-H(\\theta^*,\\phi^*)+H(\\theta^{(t-1)},\\phi^{(t-1)})\\right) \\), where Hamiltonian dynamics are used to produce the proposal.The two parameters of the algorithm, number of steps L and step size \\(\\epsilon\\), need to be tuned. 1.7: What can happen eventually, when allowing the trajectory length, defined as step size times number of steps, \\(\\epsilon L\\), to be long enough? Check out this interactive demo (algorithm=HamiltonianMC, target=standard) and set Leapfrog steps equal to 75 for visual intuition (if the demo freezes, close the demo, restart and instead of sliders, make the control changes by editing the values in the numeric fields). Do not adjust anything else in the demo. To avoid this behaviour that static HMC with fixed integration time (number of steps times the step size) may have, the No-U-Turn (NUTS) algorithm by Hoffman and Gelman (2014) performs automatic tuning: neither the step size nor number of steps need be specified by the user. NUTS uses a tree-building algorithm (see the slides) to adaptively determine the number of steps, L,  while the step size is adapted during the warm-up phase according to a target average acceptance ratio. To gain some more intuition on the behaviour of the adaptivity of NUTS, open the interactive demo again with his link (algorithm=EfficientNUTS, target=banana). Set Autoplay delay to around 500, and set Leapfrog \\(\\delta\\) t to 0.03. This algorithm corresponds to Algorithm 3 in Hoffman and Gelman (2014), where for a fixed \\( \\epsilon \\), the algorithm adaptively determines the number of steps, L.1.8: What do you observe?1.9: On the other hand, set Leapfrog \\(\\delta\\) t to 0.6, all else equal. What do you observe?The user does not need to select the stepsize directly. Stan includes also adaptation of the step size in the warmup phase using stochastic optimization called dual averaging. The user specifies a target acceptance ratio (in Stan actually target for expected discretization error), with argument adapt_delta, and a number of iterations during which adaptation of \\( \\epsilon L \\) occurs (warm-up draws). Open, the interactive demo again with this link (algorithm=DualAveragingNUTS, target=banana), and adjust the Autoplay delay to around 70, but otherwise keep the default options, particularly, keep the target acceptance ratio (here \\(\\delta\\)) at 0.65. On the top left-hand corner m/M_adapt tells you how many draws have been taken compared to number of warm-up draws. Wait until m/M_adapt is at least 50/200.1.10: What do you observe with the first couple of iterations? 1.11: What do you observe with sufficient warm-up? 1.12: Now set the target acceptance ratio to 0.95. What do you observe?1.13: Now set the target acceptance ratio to the smallest possible value. What do you observe?The current Stan HMC-NUTS implementation has some further enhancements, but we will not go to details of those. The main algorithm paramaters are adapt_delta and max_treedepth options.adapt_delta specifies the target expected discretization error (in the same scale as the average proposal acceptance ratio), during the warm-up phase and max_treedepth determines the maximum number of tree doublings in dynamic simulation and thus determine also the maximum number of steps taken. The default in most packages using Stan is setting adapt_delta=0.8. 1.14: What should happen when you increase adapt_delta, all else equal?max_treedepth controls the maximum number of doublings in the tree-building algorithm and thus controls the maximum number of steps in Hamiltonian simulation. This allows the sampler to explore further away in the distribution, which can be beneficial when dealing with complex posteriors. The default in Stan is max_treedepth = 10. 1.15: What is the main cost to increasing the max_treedepth?1.16: Despite the adaptated step-szie, you may encounter challenging posteriors, e.g. with highly varying curvature in log-density. What can happen if the step-size is too big compared to the curvature of the log-density? \n\n\nFrom 2018 to 2023, we have been keeping track of assignment submissions for the BDA course given the number of submissions for the 1st assignment. We will fit a simple linear model to answer two questions of interest:\n\n    What is the trend of student retention as measured by assignment submissions?\n    Given the submission rates for assignments 1–8, how many students will complete the final 9th assignment (and potentially pass the course)?\n\nBelow is broken Stan code for a linear model. In the following, we write the equations following the Stan distributional definitions. See Stan documentation for the definitions related to the normal distribution.\n\\(p(y | x, \\alpha, \\beta, \\sigma) = \\text{normal}(y | \\alpha + \\beta x, \\sigma) \\) (normal model)\\(p(\\alpha, \\beta, \\sigma) \\propto \\text{const.} \\) (improper flat prior)\nIn both the statistical model above and in the Stan model below, \\(x \\in \\mathbb{R}^N\\) and \\(y \\in \\mathbb{R}^N \\) are vectors of the covariates / predictors (the assignment number) and vectors of the observation (proportions of students who have handed in the respective assignment). \\(\\alpha \\in \\mathbb{R}\\) is the unknown scalar intercept, \\(\\beta \\in \\mathbb{R}\\) is the unknown scalar slope and \\(\\sigma \\in \\mathbb{R}_{&gt;0}\\) is the unknown scalar observation standard deviation. The statistical model further implies\\( p(y_{pred.} | x_{pred.}, \\alpha, \\beta, \\sigma) = \\text{normal}(y_{pred.} | \\alpha + \\beta x_{pred.}, \\sigma) \\)as the predictive distribution for a new observation \\(y_{pred.}\\) at a given new covariate value \\( x_{pred.} \\). The broken Stan model code: \n\ndata {\n    // number of data points\n    int&lt;lower=0&gt; N; \n    // covariate / predictor\n    vector[N] x; \n    // observations\n    vector[N] y; \n    // number of covariate values to make predictions at\n    int&lt;lower=0&gt; N_predictions;\n    // covariate values to make predictions at\n    vector[N_predictions] x_predictions; \n}\nparameters {\n    // intercept\n    real alpha; \n    // slope\n    real beta; \n    // the standard deviation should be constrained to be positive\n    real&lt;upper=0&gt; sigma; \n}\ntransformed parameters {\n    // deterministic transformation of parameters and data\n    vector[N] mu = alpha + beta * x // linear model\n}\nmodel {\n    // observation model\n    y ~ normal(mu, sigma); \n}\ngenerated quantities {\n    // compute the means for the covariate values at which to make predictions\n    vector[N_predictions] mu_pred = alpha + beta * x_predictions;\n    // sample from the predictive distribution normal(mu_pred, sigma).\n    array[N_predictions] real y_pred = normal_rng(to_array_1d(mu), sigma);\n}\nFirstly, let's review some Stan syntax.\n\n2.1: What is the function of the data block? \n2.2 What is the function of the parameters block? \n\n\n2.3 Can you use statements (e.g. real&lt;lower=0&gt; theta = lambda^2) in the parameters code block, where lambda is some other variable? \n2.4: What is the function of the transformed parameters block?\n2.5: What is the function of the model block? \n2.6: As you've learned in the lecture or from the Stan documentation, log densities can be added to the target density either via the distribution statement using ~ or via the log probability increment statement using target +=. Furthermore, we don't need to include constant terms. Assume the model block has a line   theta ~ normal(0,1);. How could you equivalently increment the log density to get the same increment (ignoring the possible difference in the constants)?\n2.7: Why can the normalising constant(s) be dropped when using MCMC (this holds for e.g. variational inference and optimisation too)?\n\n\nStan language allows writing the models as usually written in books and articles. As you've learned during the course, a collection of distribution statements define a joint distribution as a product of component distributions. \nSuppose your model is the following:\n\\( p(y|\\mu,\\sigma) = \\text{normal}(y|\\mu,\\sigma) \\)\\( p(\\mu) = \\text{normal}(\\mu|0,1) \\)\\( p(\\sigma) = \\text{normal}^+(\\sigma|0,10) \\)\n\n2.8: What are correct ways to write your model in the model block? In the below, assume that there is a line-break after each semi-colon, and that the variables have been appropriately declared in the parameter blocks.\nWhen writing complicated models, it may happen that some distribution statement is accidentally repeated twice. Check out this page in the Stan manual to see what happens in this case. \n2.9: What is the function of the generated quantities block?\n\nNow, let's return to the student retention model code, shown above.\n2.10: What are the three mistakes in the Stan model code above? \nYou may find some of the mistakes in the code using Stan syntax checker. If you copy the Stan code to a file ending .stan and open it in RStudio (you can also choose from RStudio menu File \\(\\rightarrow\\)New File\\(\\rightarrow\\)Stan file to create a new Stan file), the editor will show you some syntax errors. More syntax errors might be detected by clicking `Check’ in the bar just above the Stan file in the RStudio editor. Note that some of the errors in the presented Stan code may not be syntax errors.\nUse the code in the template to first compile your model using CmdStanR (which is a handy interface for CmdStan which transplies Stan model code to C++ which is compiled to executable program which can do the actual sampling), run the inference with the supplied data, and finally create the plot to answer the following questions. \n\nDefine the term of the model \\( \\mu = \\alpha + \\beta x \\) as the linear predictor.\n2.11: What is the solid red line plotting?\n2.12: What are the dashed red lines referring to?\n2.13: How and why are these different from the corresponding grey lines?\n2.14: What is the general trend of student retention as measured by the assignment submissions?\n2.15: Does it do a good job predicting the proportion of students who submit the final 9th assignment?\n2.16: What modeling choice could you make to improve the prediction for the given data set?\n\n\nAnother benefit of the HMC-NUTS algorithm over simpler non-gradient based MCMC algorithms, is that we have access to many diagnostic tools related to the posterior geometry that we would otherwise not have. This feedback is helpful for modeling and also for debugging code, and therefore an essential part of the Bayesian workflow. A model type which is likely to cause problems is logistic regression with complete separation in the data. This creates an unbounded likelihood.\n3.1: Why is it problematic to use flat, improper priors for this likelihood?\nUsing the data generated from the template, compile and run the following Stan model:\n\n// logistic regression\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; M;\n  array[N] int&lt;lower=0,upper=1&gt; y;\n  matrix[N,M] x;\n}\nparameters {\n  real alpha;\n  vector[M] beta;\n}\nmodel {\n  y ~ bernoulli_logit_glm(x, alpha, beta);\n}3.2: You can use the function [fit object name]$diagnostic summary() to check for the number of divergent transitions and max_treedepth exceedences. What do you see?3.3: You can examine the problematic behaviour of MCMC  by looking at parameter specific sampling diagnostics using the summarize_draws function discussed last week. To gain visual intuition use bayesplot's mcmc_pairs function to plot histograms and bivariate scatter plots of the posteriors. What do you observe?Before thinking about changing the model, a first step should be to check for any easy mistakes made in the Stan code. The Stan compiler has a pedantic mode to help spot such issues. By default the pedantic mode is not enabled, but we can use option pedantic = TRUE at compilation time, or after compilation with the check_syntax method.3.4: Use the function [Stan model]$check_syntax(pedantic = TRUE). What warning message(s) do you get?3.5: Set normal(0,10) priors for both parameters, what do you find from the MCMC output?As you've learned during the course, using proper priors, even when they are wide, are always preferable to stabilise inference and make the model generative. You'll learn next week more about priors. 3.6: Sometimes, when adjusting Stan model code you may have removed a variable from the model block, but left the declaration in the parameters block. Add such a variable to your model. What do you see from convergence diagnostics (it may also help you visualise the MCMC chains using mcmc_pairs and mcmc_trace)? 3.7: Use check_syntax(pedantic = TRUE), would you have been able to detect this problem from the output?A further important problem is that of high correlation between parameters in the posterior, which may lead to slow exploration and divergent transitions. Sometimes, we can address this by slightly re-writing the model. Check out the lecture's discussion the Kilpisjärvi case study. More on that in the weeks to follow.  \n\nNow, we re-investigate the Bioassay model from last week with Stan. If you need a reminder about the model and likelihood definition, check out section 3.7 in BDA3. To make the implementation simpler, we consider the following priors:\nalpha ~ normal(0,2)\nbeta ~ normal(10,10)\n4.1: What is the difference in the prior to last week?\n4.2: Which pre-built function can you use in Stan to compute the likelihood? \nUse the code hints in the template to complete your Stan model. For questions about declarations and functionality of Stan, your first point of reference should always be the Stan Manual (it's been recently revised, be sure to open at least version 2.35). Use 4 chains, with 1000 warmup and 2000 total draws each, use default options for adapt_delta and max_treedepth, and use seed = 4911.  Compile your model, define the data inputs needed, sample from the posterior, and answer the following. To make sure that your model is correct, compare a scatter plot of alpha and beta to last week (the priors are not exactly the same, but the posterior should be quite similar to last week as the priors are relatively weak):\n4.3: Did the Stan model produce any warnings about the sampling efficiency? \n4.4: Use the Rhat function from the posterior package, rhat_basic(), (used in last week's assignment). The Rhat for for alpha  and beta  . \n4.5: The ESS mean for alpha= and for beta=.\n4.6: ESS q0.05 for alpha=, ESS q0.05 for beta=.\nPlot the autocorrelation function for the draws for the chains of alpha and beta using the mcmc_acf function from the bayesplot package and compare that to the autocorrelation function from the Metropolis-Hastings (MH) algorithm you developed last week. You don't need to re-do the model for the MH algorithm with the new priors, but for better comparison this is what you should do outside of this exercise. \n4.7: What do you see?",
    "crumbs": [
      "Assignments",
      "Assignment 6"
    ]
  },
  {
    "objectID": "template9.html",
    "href": "template9.html",
    "title": "Notebook for Assignment 9",
    "section": "",
    "text": "This assignment relates to Lectures 9-10 and Chapter 9 of BDA3\nWe recommend using JupyterHub (which has all the needed packages pre-installed).\n\nReading instructions: - For background on Bayes-R2 - The reading instructions for BDA3 Chapter 9 (decision analysis).\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\nif (!require(brms)) {\n    install.packages(\"brms\")\n    library(brms)\n}\n\nLoading required package: brms\n\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\nif(!require(cmdstanr)){\n    install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n    library(cmdstanr)\n}\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.9.0\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.36.0\n\n\n- CmdStan version: 2.36.0\n\ncmdstan_installed &lt;- function(){\n  res &lt;- try(out &lt;- cmdstanr::cmdstan_path(), silent = TRUE)\n  !inherits(res, \"try-error\")\n}\nif(!cmdstan_installed()){\n    install_cmdstan()\n}\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nif(!require(bayesplot)){\n    install.packages(\"bayesplot\")\n    library(bayesplot)\n}\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.13.0\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:brms':\n\n    rhat\n\nif(!require(dplyr)){\n    install.packages(\"dplyr\")\n    library(dplyr)\n}\n\nLoading required package: dplyr\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nif(!require(tidyr)){\n    install.packages(\"tidyr\")\n    library(tidyr)\n}\n\nLoading required package: tidyr\n\nif(!require(matrixStats)){\n    install.packages(\"matrixStats\")\n    library(matrixStats)\n}\n\nLoading required package: matrixStats\n\n\n\nAttaching package: 'matrixStats'\n\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\nif(!require(ggdist)){\n    install.packages(\"ggdist\")\n    library(ggdist)\n}\n\nLoading required package: ggdist\n\n\n\nAttaching package: 'ggdist'\n\n\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\nif(!require(tinytable)){\n    install.packages(\"tinytable\")\n    library(tinytable)\n}\n\nLoading required package: tinytable\n\n\n\nAttaching package: 'tinytable'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    theme_default\n\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\n\nThe following object is masked from 'package:brms':\n\n    theme_default\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\nif(!require(patchwork)){\n    install.packages(\"patchwork\")\n    library(patchwork)\n}\n\nLoading required package: patchwork\n\nif(!require(mvtnorm)){\n    install.packages(\"mvtnorm\")\n    library(mvtnorm)\n}\n\nLoading required package: mvtnorm\n\ntheme_set(bayesplot::theme_default(base_family = \"sans\"))",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 9"
    ]
  },
  {
    "objectID": "template9.html#data-prep",
    "href": "template9.html#data-prep",
    "title": "Notebook for Assignment 9",
    "section": "3.1 Data Prep",
    "text": "3.1 Data Prep\n\n# Load the data\nstudent &lt;- read.csv(url('https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Student/data/student-merged.csv'))\n\n# Predictors to be used\npredictors &lt;- c(\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"traveltime\",\"studytime\",\"failures\",\"schoolsup\",\"famsup\",\"paid\",\"activities\", \"nursery\", \"higher\", \"internet\", \"romantic\",\"famrel\",\"freetime\",\"goout\",\"Dalc\",\"Walc\",\"health\",\"absences\")\np &lt;- length(predictors)\n\n# To reduce variability us the median grades based on those three\n# exams for each topic, students with non-zero grades are selected\ngrades &lt;- c(\"G1mat\",\"G2mat\",\"G3mat\",\"G1por\",\"G2por\",\"G3por\")\nstudent &lt;- student %&gt;%\n  mutate(across(matches(\"G[1-3]...\"), ~na_if(.,0))) %&gt;%\n  mutate(Gmat = rowMedians(as.matrix(select(.,matches(\"G.mat\"))), na.rm=TRUE),\n         Gpor = rowMedians(as.matrix(select(.,matches(\"G.por\"))), na.rm=TRUE))\nstudent_Gmat &lt;- subset(student, is.finite(Gmat), select=c(\"Gmat\",predictors))\nstudent_Gmat &lt;- student_Gmat[is.finite(rowMeans(student_Gmat)),]\nstudent_Gpor &lt;- subset(student, is.finite(Gpor), select=c(\"Gpor\",predictors))\n(nmat &lt;- nrow(student_Gmat))\n\n[1] 382\n\n# Look at the data\nhead(student_Gmat) |&gt; tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Gmat\n                school\n                sex\n                age\n                address\n                famsize\n                Pstatus\n                Medu\n                Fedu\n                traveltime\n                studytime\n                failures\n                schoolsup\n                famsup\n                paid\n                activities\n                nursery\n                higher\n                internet\n                romantic\n                famrel\n                freetime\n                goout\n                Dalc\n                Walc\n                health\n                absences\n              \n        \n        \n        \n                \n                  10\n                  0\n                  0\n                  15\n                  0\n                  0\n                  1\n                  1\n                  1\n                  2\n                  4\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  0\n                  3\n                  1\n                  2\n                  1\n                  1\n                  1\n                  2\n                \n                \n                  6\n                  0\n                  0\n                  15\n                  0\n                  0\n                  1\n                  1\n                  1\n                  1\n                  2\n                  2\n                  1\n                  1\n                  0\n                  0\n                  0\n                  1\n                  1\n                  1\n                  3\n                  3\n                  4\n                  2\n                  4\n                  5\n                  2\n                \n                \n                  13\n                  0\n                  0\n                  15\n                  0\n                  0\n                  1\n                  2\n                  2\n                  1\n                  1\n                  0\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  0\n                  0\n                  4\n                  3\n                  1\n                  1\n                  1\n                  2\n                  8\n                \n                \n                  9\n                  0\n                  0\n                  15\n                  0\n                  0\n                  1\n                  2\n                  4\n                  1\n                  3\n                  0\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  0\n                  4\n                  3\n                  2\n                  1\n                  1\n                  5\n                  2\n                \n                \n                  10\n                  0\n                  0\n                  15\n                  0\n                  0\n                  1\n                  3\n                  3\n                  2\n                  3\n                  2\n                  0\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  4\n                  2\n                  1\n                  2\n                  3\n                  3\n                  8\n                \n                \n                  12\n                  0\n                  0\n                  15\n                  0\n                  0\n                  1\n                  3\n                  4\n                  1\n                  3\n                  0\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  1\n                  0\n                  4\n                  3\n                  2\n                  1\n                  1\n                  5\n                  2\n                \n        \n      \n    \n\n\n# Visualise the distributions of median math scores\np1 &lt;- ggplot(student_Gmat, aes(x=Gmat)) + geom_dots() + labs(x='Median math exam score')\np1\n\n\n\n\n\n\n\n# Some data transformation for non-binary predictors to have standard\n# deviation 1\nstudentstd_Gmat &lt;- student_Gmat\nGmatbin&lt;-apply(student_Gmat[,predictors], 2, function(x) {length(unique(x))==2})\nstudentstd_Gmat[,predictors[!Gmatbin]] &lt;-scale(student_Gmat[,predictors[!Gmatbin]])\nstudentstd_Gpor &lt;- student_Gpor\nGporbin&lt;-apply(student_Gpor[,predictors], 2, function(x) {length(unique(x))==2})\nstudentstd_Gpor[,predictors[!Gporbin]] &lt;-scale(student_Gpor[,predictors[!Gporbin]])\n\n# Set Seed for reproducibility\nSEED &lt;- 2132",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 9"
    ]
  },
  {
    "objectID": "template9.html#normal-model",
    "href": "template9.html#normal-model",
    "title": "Notebook for Assignment 9",
    "section": "3.2 Normal Model",
    "text": "3.2 Normal Model\nEstimate model\n\n# Estimate Model\nfit1 &lt;- brm(Gmat ~ ., data = studentstd_Gmat,\n             normalize=FALSE,\n            seed = SEED)\n\nCompiling Stan program...\n\n\nError in .fun(model_code = .x1): Boost not found; call install.packages('BH')\n\n\nVisualise posteriors\n\n# Plot marginal posteriors of the coefficients\ndrawsmu &lt;- as_draws_df(fit1, variable=paste0('b_',predictors)) |&gt;\n  set_variables(predictors)\n\nError: object 'fit1' not found\n\np &lt;- mcmc_areas(drawsmu,\n                prob_outer=0.98, area_method = \"scaled height\") +\n  xlim(c(-3,3))\n\nError: object 'drawsmu' not found\n\np &lt;- p + scale_y_discrete(limits = rev(levels(p$data$parameter)))\n\nError in p$data: $ operator is invalid for atomic vectors\n\np\n\n[1] 26\n\n\nNow, find prior predictive R2\n\nX &lt;- studentstd_Gmat[,2:dim(student_Gmat)[2]] \n\nppR2_1&lt;-numeric()\nsims &lt;- 4000\n\nfor (i in 1:sims) {\n  sigma2 &lt;- rstudent_t(1,3,0,3)^2\n  beta &lt;- rnorm(length(predictors))\n  mu &lt;- as.matrix(X)%*%as.vector(beta)\n  muvar &lt;- var(mu)\n  ppR2_1[i] &lt;- muvar/(muvar+sigma2)\n}\n\nPlot prior predictive R2 vs posterior R2\n\ndata &lt;- data.frame(Prior=ppR2_1,Posterior=bayes_R2(fit1, summary=FALSE)) \n\nError: object 'fit1' not found\n\nnames(data) &lt;- c(\"Prior\",\"Posterior\")\n\nError in names(data) &lt;- c(\"Prior\", \"Posterior\"): names() applied to a non-vector\n\nmcmc_hist(data,\n          breaks=seq(0,1,length.out=100),\n          facet_args = list(nrow = 2)) +\n  facet_text(size = 13) +\n  scale_x_continuous(limits = c(0,1), expand = c(0, 0),\n                     labels = c(\"0\",\"0.25\",\"0.5\",\"0.75\",\"1\")) +\n  theme(axis.line.y = element_blank()) +\n  xlab(\"Bayesian R^2\")\n\nError in dim(x) &lt;- length(x): invalid first argument, must be vector (list or atomic)\n\n\nBayes-R2 and LOO-R2\n\nbayes_R2(fit1) |&gt; as.data.frame() |&gt; tt()\n\nError: object 'fit1' not found\n\nloo_R2(fit1) |&gt; as.data.frame() |&gt; tt()\n\nError: object 'fit1' not found",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 9"
    ]
  },
  {
    "objectID": "template9.html#r2-model",
    "href": "template9.html#r2-model",
    "title": "Notebook for Assignment 9",
    "section": "3.3 R2 Model",
    "text": "3.3 R2 Model\nEstimate the model, amend the code below\n\nfit2 &lt;- brm(Gmat ~ ., data = studentstd_Gmat,\n            seed = SEED,\n            normalize = FALSE,\n            prior=c(prior(R2D2(mean_R2 = 0.5, prec_R2 = 1, cons_D2 = 1,\n                               autoscale = TRUE),class=b)),\n            backend = \"cmdstanr\")\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.7 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.7 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.7 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 3.3 seconds.\n\n\nVisualise Posteriors\n\n# Plot marginal posteriors\ndraws2 &lt;- as_draws_df(fit2, variable=paste0('b_',predictors)) |&gt;\n  set_variables(predictors)\np &lt;- mcmc_areas(draws2,\n                prob_outer=0.98, area_method = \"scaled height\") +\n  xlim(c(-3,3))\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\np &lt;- p + scale_y_discrete(limits = rev(levels(p$data$parameter)))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\np\n\n\n\n\n\n\n\n\nFind prior predictive R2. This should be equal to the prior you set on R2 if all predictors are scaled to have unit variance. Since binary predictors were not standardised, the prior predictive might look slightly different, let’s compute it for illustration\n\nppR2_2&lt;-numeric()\nsims &lt;- 4000\n\nfor (i in 1:sims) {\n  sigma2 &lt;- rstudent_t(1,3,0,3)^2\n  R2 &lt;- rbeta(1,1,2)\n  tau2 &lt;- R2/(1-R2)\n  psi &lt;- as.numeric(rdirichlet(1,rep(1,dim(X)[2])))\n  beta &lt;- rnorm(dim(X)[2])*sqrt(sigma2*tau2*psi)\n  mu &lt;- as.matrix(X)%*%as.vector(beta)\n  muvar &lt;- var(mu)\n  ppR2_2[i] &lt;- muvar/(muvar+sigma2)\n}\n\nNow, find the predictive R2 and compare to the posterior.\n\n# Prior vs posterior R2\ndata &lt;- data.frame(Prior=ppR2_2,Posterior=bayes_R2(fit2, summary=FALSE)) \nnames(data) &lt;- c(\"Prior\",\"Posterior\")\nmcmc_hist(data,\n          breaks=seq(0,1,length.out=100),\n          facet_args = list(nrow = 2)) +\n  facet_text(size = 13) +\n  scale_x_continuous(limits = c(0,1), expand = c(0, 0),\n                     labels = c(\"0\",\"0.25\",\"0.5\",\"0.75\",\"1\")) +\n  theme(axis.line.y = element_blank()) +\n  xlab(\"Bayesian R^2\")\n\n\n\n\n\n\n\n\nSummaries of R2 and LOO-R2\n\n# Bayes-R2 and LOO-R2\nbayes_R2(fit2) |&gt; as.data.frame() |&gt; tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Estimate\n                Est.Error\n                Q2.5\n                Q97.5\n              \n        \n        \n        \n                \n                  0.2528188\n                  0.03621541\n                  0.1795898\n                  0.3231523\n                \n        \n      \n    \n\n\nloo_R2(fit2) |&gt; as.data.frame() |&gt; tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Estimate\n                Est.Error\n                Q2.5\n                Q97.5\n              \n        \n        \n        \n                \n                  0.2154697\n                  0.03272183\n                  0.148575\n                  0.2761246",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 9"
    ]
  },
  {
    "objectID": "template6.html",
    "href": "template6.html",
    "title": "Notebook for Assignment 6",
    "section": "",
    "text": "This assignment is related to Lecture 6 and Chapter 12.\nWe recommend using JupyterHub (which has all the needed packages pre-installed).\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 12.\n\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\nThe following installs and loads the posterior package which imports the rhat_basic() function:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggplot2 package and the bayesplot package\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nif(!require(bayesplot)){\n    install.packages(\"bayesplot\")\n    library(bayesplot)\n}\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.13.0\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:posterior':\n\n    rhat\n\nif(!require(dplyr)){\n    install.packages(\"dplyr\")\n    library(dplyr)\n}\n\nLoading required package: dplyr\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nif(!require(tidyr)){\n    install.packages(\"tidyr\")\n    library(tidyr)\n}\n\nLoading required package: tidyr\n\n# Some additional set-up to make plots legible\nggplot2::theme_set(theme_minimal(base_size = 14))\nbayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))\n\nThe following installs and loads the cmdstanr package and tries to install cmdstan.\n\nif(!require(cmdstanr)){\n    install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n    library(cmdstanr)\n}\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.9.0\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.36.0\n\n\n- CmdStan version: 2.36.0\n\ncmdstan_installed &lt;- function(){\n  res &lt;- try(out &lt;- cmdstanr::cmdstan_path(), silent = TRUE)\n  !inherits(res, \"try-error\")\n}\nif(!cmdstan_installed()){\n    install_cmdstan()\n}",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 6"
    ]
  },
  {
    "objectID": "template6.html#data-preparation-and-sampling-from-the-posterior",
    "href": "template6.html#data-preparation-and-sampling-from-the-posterior",
    "title": "Notebook for Assignment 6",
    "section": "2.1 Data preparation and sampling from the posterior",
    "text": "2.1 Data preparation and sampling from the posterior\nData assembly happens here:\n\n# These are our observations y: the proportion of students handing in each assignment (1-8),\n# sorted by year (row-wise) and assignment (column-wise).\n# While the code suggest a matrix structure, \n# the result will actually be a vector of length N = no_years * no_assignments\npropstudents&lt;-c(c(176, 174, 158, 135, 138, 129, 126, 123)/176,\n                c(242, 212, 184, 177, 174, 172, 163, 156)/242,\n                c(332, 310, 278, 258, 243, 242, 226, 224)/332,\n                c(301, 269, 231, 232, 217, 208, 193, 191)/301,\n                c(245, 240, 228, 217, 206, 199, 191, 182)/245,\n                c(264, 249, 215, 221, 215, 206, 192, 186)/264)\n# These are our predictors x: for each observation, the corresponding assignment number.\nassignment &lt;- rep(1:8, 6)\n# These are in some sense our test data: the proportion of students handing in the last assignment (9),\n# sorted by year. \n# Usually, we would not want to split our data like that and instead\n# use e.g. Leave-One-Out Cross-Validation (LOO-CV, see e.g. http://mc-stan.org/loo/index.html)\n# to evaluate model performance.\npropstudents9 = c(121/176, 153/242, 218/332, 190/301, 175/245, 179/264)\n# The total number of assignments\nno_assignments = 9\n# The assignment numbers for which we want to generate predictions\nx_predictions = 1:no_assignments\n# (Cmd)Stan(R) expects the data to be passed in the below format:\nmodel_data = list(N=length(assignment),\n                 x=assignment,\n                 y=propstudents,\n                 no_predictions=no_assignments,\n                 x_predictions=x_predictions)\n\nSampling from the posterior distribution happens here:\n\n# This reads the file at the specified path and tries to compile it. \n# If it fails, an error is thrown.\nretention_model = cmdstan_model(\"assignment6_linear_model.stan\")\n# This \"out &lt;- capture.output(...)\" construction suppresses output from cmdstanr\n# See also https://github.com/stan-dev/cmdstanr/issues/646\nout &lt;- capture.output(\n    # Sampling from the posterior distribution happens here:\n    fit &lt;- retention_model$sample(data=model_data, refresh=0, show_messages=FALSE)\n)\n\nDraws postprocessing happens here:\n\n# This extracts the draws from the sampling result as a data.frame.\ndraws_df = fit$draws(format=\"draws_df\")\n\n# This does some data/draws wrangling to compute the 5, 50 and 95 percentiles of \n# the mean at the specified covariate values (x_predictions). \n# It can be instructive to play around with each of the data processing steps\n# to find out what each step does, e.g. by removing parts from the back like \"|&gt;  gather(pct,y,-x)\"\n# and printing the resulting data.frame.\nmu_quantiles_df = draws_df |&gt; \n      subset_draws(variable = c(\"mu_pred\")) |&gt; \n      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |&gt; \n      mutate(x = 1:9) |&gt; \n      pivot_longer(c(q5, q50, q95), names_to = c(\"pct\"))\n# Same as above, but for the predictions.\ny_quantiles_df = draws_df |&gt; \n      subset_draws(variable = c(\"y_pred\")) |&gt; \n      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |&gt; \n      mutate(x = 1:9) |&gt; \n      pivot_longer(c(q5, q50, q95), names_to = c(\"pct\"))\n\nPlotting happens here:\n\nggplot() +\n  # scatter plot of the training data:  \n  geom_point(\n    aes(x, y, color=assignment), \n    data=data.frame(x=assignment, y=propstudents, assignment=\"1-8\")\n) +\n  # scatter plot of the test data:\n  geom_point(\n    aes(x, y, color=assignment), \n    data=data.frame(x=no_assignments, y=propstudents9, assignment=\"9\")\n) +\n  # you have to tell us what this plots:\n  geom_line(aes(x,y=value,linetype=pct), data=mu_quantiles_df, color='grey', linewidth=1.5) +\n  # you have to tell us what this plots:\n  geom_line(aes(x,y=value,linetype=pct), data=y_quantiles_df, color='red') +\n  # adding xticks for each assignment:\n  scale_x_continuous(breaks=1:no_assignments) +\n  # adding labels to the plot:\n  labs(y=\"assignment submission %\", x=\"assignment number\") +\n  # specifying that line types repeat:\n  scale_linetype_manual(values=c(2,1,2)) +\n  # Specify colours of the observations:\n  scale_colour_manual(values = c(\"1-8\"=\"black\", \"9\"=\"blue\")) +\n  # remove the legend for the linetypes:\n  guides(linetype=\"none\")",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 6"
    ]
  },
  {
    "objectID": "template6.html#quick-check-for-sampling-convergence",
    "href": "template6.html#quick-check-for-sampling-convergence",
    "title": "Notebook for Assignment 6",
    "section": "2.2 Quick check for sampling convergence",
    "text": "2.2 Quick check for sampling convergence\nIf your model is correctly implemented, sampling from the posterior distribution should have been successful. You can check whether Stan thinks that sampling succeeded by inspecting the output of the below command, which you should be able to interpret with a little help from the CmdStan User’s Guide.\n\nfit$cmdstan_diagnose()",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 6"
    ]
  },
  {
    "objectID": "template6.html#improper-posterior",
    "href": "template6.html#improper-posterior",
    "title": "Notebook for Assignment 6",
    "section": "3.1 Improper Posterior",
    "text": "3.1 Improper Posterior\nAn unbounded likelihood without a proper prior can lead to an improper posterior. We recommend to always use proper priors (integral over a proper distribution is finite) to guarantee proper posteriors.\nA commonly used model that can have unbounded likelihood is logistic regression with complete separation in data.\n\n3.1.1 Data\nUnivariate continous predictor \\(x\\), binary target \\(y\\), and the two classes are completely separable, which leads to unbounded likelihood.\n\nset.seed(48927+4)\nM=1;\nN=10;\nx=matrix(sort(rnorm(N)),ncol=M)\ny=rep(c(0,1), each=N/2)\ndata_logit &lt;-list(M = M, N = N, x = x, y = y)\ndata.frame(data_logit) |&gt;\n  ggplot(aes(x, y)) +\n  geom_point(size = 3, shape=1, alpha=0.6) +\n  scale_y_continuous(breaks=c(0,1))\n\n\n\n\n\n\n\n\n\n\n3.1.2 Compile and Sample from the following model\n// logistic regression\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; M;\n  array[N] int&lt;lower=0,upper=1&gt; y;\n  matrix[N,M] x;\n}\nparameters {\n  real alpha;\n  vector[M] beta;\n}\nmodel {\n  y ~ bernoulli_logit_glm(x, alpha, beta);\n}\n\n\n3.1.3 Convergence diagnostics\n\n# Get the summary diagnostics using [fit object name]]$diagnostic_summary()\n\n# Get summary statistics from your chains using summarize_draws() (hint: look at how we used the function last week)\n\n# Plot histograms and bivariate scatter plots using mcmc_pairs(). See for guidance on how to use the function here: https://mc-stan.org/bayesplot/reference/MCMC-scatterplots.html\n\n# To plot the tracplot of individual chains, use the mcmc_trace() function. See for guidance on how to use the function here: https://mc-stan.org/bayesplot/reference/MCMC-traces.html",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 6"
    ]
  },
  {
    "objectID": "template6.html#run-model-and-analyse-output",
    "href": "template6.html#run-model-and-analyse-output",
    "title": "Notebook for Assignment 6",
    "section": "4.1 Run model and analyse output",
    "text": "4.1 Run model and analyse output\n\n# Load data\ndata =list(n = bioassay$n, x = bioassay$x, y = bioassay$y, N = nrow(bioassay))\n\n# Compile Model\nmod &lt;- cmdstan_model(# your stan model location)\n\n# Estimate model\nout &lt;- capture.output(\n  # Sampling from the posterior distribution happens here:\n  fit &lt;- mod$sample(data=data, refresh=0, show_messages=FALSE, seed = 4711, chains = 4, iter_warmup = 1000, \n                    iter_sampling = 3000)\n)\n\n# This extracts the draws from the sampling result as a data.frame.\ndraws_df = fit$draws(format=\"draws_df\")\n\n# This is what you'll need for convergence diagnostics\nsummarise_draws(draws_df, Rhat=rhat_basic, ESS= ess_mean, ~ess_quantile(.x, probs = 0.05))\n\n# Scatter plot of the draws\nmcmc_scatter(draws_df, pars=c(\"alpha\", \"beta\"))\n\n# Plot the autocorrelation function and compare to last week\nmcmc_acf(draws_df, pars = c(\"alpha\",\"beta\"))",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 6"
    ]
  },
  {
    "objectID": "assignment_instructions.html",
    "href": "assignment_instructions.html",
    "title": "Assignment instructions",
    "section": "",
    "text": "In addition to R-markdown, Quarto can be used to write the assignment reports. This template contains essentially the same information as the old R-markdown template but we illustrate how you can use Quarto for the assignments.\nSome useful resources to get started with Quarto (also an example of a list):\n\nGetting started with Quarto and Rstudio from the official webpage\nA comprehensive user guide from the official webpage\nMarkdown basics\nQuarto FAQ for R-markdown users\nAwesome Quarto - list by Mickaël Canouil\n\nTo create your assignment, you can use the assignment-specific templates (recommended, see e.g. the links at the top of assignment 1) or remove the formatting instructions and use this file as a template. Keep the header (the first lines of this file between two lines of —) as it sets the author name to be anonymous, and you can set the title to match the assignment number.\nAs with R-markdown, you can use the text editor of your choice, but RStudio’s editor is probably the easiest and you can choose the formatting (e.g. section headings, bolding, lists, figures, etc.) from the toolbar. Switching between the source and visual mode allows the quick preview of your formatting.\nNote The report should be anonymous and submitted to peergrade.io as assignmentX.pdf. Aalto JupyterHub has everything installed and you should be able to render the templates to pdf without any further set-up, but if there are problems contact the TAs or get more information on this from the Quarto documentation. Alternatively, if you have problem with creating a PDF file, start by creating an HTML file and the just print the HTML to a PDF. You may also use other software to create the report PDF, but follow the general instructions in this file (see the pdf version of the template file).",
    "crumbs": [
      "General instructions",
      "Assignment instructions"
    ]
  },
  {
    "objectID": "assignment_instructions.html#a",
    "href": "assignment_instructions.html#a",
    "title": "Assignment instructions",
    "section": "5.1 a)",
    "text": "5.1 a)\nFor each subtask include necessary textual explanation, equations, code and figures so that the answer to the question flows naturally. You can think what kind of report would you like to review, and what kind of information would make it easier where there is error (if there are errors).",
    "crumbs": [
      "General instructions",
      "Assignment instructions"
    ]
  },
  {
    "objectID": "template8.html",
    "href": "template8.html",
    "title": "Notebook for Assignment 8",
    "section": "",
    "text": "1 General information\nThis assignment relates to Lectures 8-9 and Chapter 7 of BDA3\nWe recommend using JupyterHub (which has all the needed packages pre-installed).\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 6 (posterior predictive checking).\nThe reading instructions for BDA3 Chapter 7 (predictive performance).\nThe ’loo‘ package vignette on the basics of LOO shows an example of how to modify Stan code and use the package with Stan models.\nAlso read about PSIS-LOO in the PSIS-LOO paper.\nCV-FAQ includes a lot of informative answers to frequent questions and misconceptions.\n\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\nif (!require(brms)) {\n    install.packages(\"brms\")\n    library(brms)\n}\n\nLoading required package: brms\n\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\nif(!require(cmdstanr)){\n    install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n    library(cmdstanr)\n}\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.9.0\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.36.0\n\n\n- CmdStan version: 2.36.0\n\ncmdstan_installed &lt;- function(){\n  res &lt;- try(out &lt;- cmdstanr::cmdstan_path(), silent = TRUE)\n  !inherits(res, \"try-error\")\n}\nif(!cmdstan_installed()){\n    install_cmdstan()\n}\n\n\n\n2 Sleep deprivation\nThe dataset sleepstudy is available by using the command data(sleepstudy, package = \"lme4\")\nBelow is some code for fitting a brms model. This model is a simple pooled model. You will need to fit a hierarchical model as explained in the assignment, but this code should help getting started.\nLoad the dataset\n\ndata(sleepstudy, package = \"lme4\")\n\nError in find.package(package, lib.loc, verbose = verbose): there is no package called 'lme4'\n\n\nSpecify the formula and observation family:\n\nsleepstudy_pooled_formula &lt;- bf(\n  Reaction ~ 1 + Days,\n  family = \"gaussian\",\n  center = FALSE\n)\n\nWe can then specify the priors:\n\n(sleepstudy_pooled_priors &lt;- c(\n  prior(\n    normal(250, 100),\n    class = \"b\",\n    coef = \"Intercept\"\n  ),\n  prior(\n    normal(0, 20),\n    class = \"b\",\n    coef = \"Days\"\n  ),\n  prior(\n    normal(0, 100),\n    class = \"sigma\"\n  )\n))\n\n            prior class      coef group resp dpar nlpar   lb   ub source\n normal(250, 100)     b Intercept                       &lt;NA&gt; &lt;NA&gt;   user\n    normal(0, 20)     b      Days                       &lt;NA&gt; &lt;NA&gt;   user\n   normal(0, 100) sigma                                 &lt;NA&gt; &lt;NA&gt;   user\n\n\nAnd then fit the model:\n\nsleepstudy_pooled_fit &lt;- brm(\n  formula = sleepstudy_pooled_formula,\n  prior = sleepstudy_pooled_priors,\n  data = sleepstudy\n)\n\nError: object 'sleepstudy' not found\n\n\nWe can add the leave-one-out CV criterion to the fit object, and then view the output\n\nsleepstudy_pooled_fit &lt;- add_criterion(\n  sleepstudy_pooled_fit,\n  criterion = \"loo\"\n)\n\nError: object 'sleepstudy_pooled_fit' not found\n\nloo(sleepstudy_pooled_fit)\n\nError: object 'sleepstudy_pooled_fit' not found\n\n\n\n\n3 Sleep deprivation extension\nHere is an example of a pooled model with spline\n\nsleepstudy_pooled_spline_formula &lt;- bf(\n  Reaction ~ 1 + Days + s(Days),\n  family = \"gaussian\",\n  center = FALSE\n)\n\n\nsleepstudy_pooled_spline_priors &lt;- c(\n  prior(\n    normal(250, 100),\n    class = \"b\",\n    coef = \"Intercept\"\n  ),\n  prior(\n    normal(0, 20),\n    class = \"b\",\n    coef = \"Days\"\n  ),\n  prior(\n    normal(0, 100),\n    class = \"sigma\"\n  ),\n  prior(\n    normal(0, 20),\n    class = \"b\",\n    coef = \"sDays_1\"\n  )\n)\n\nsleepstudy_pooled_spline_fit &lt;- brm(\n  formula = sleepstudy_pooled_spline_formula,\n  prior = sleepstudy_pooled_spline_priors,\n  data = sleepstudy,\n  family = \"gaussian\"\n)\n\nError: object 'sleepstudy' not found\n\n\nAdding the loo criterion:\n\nsleepstudy_pooled_spline_fit &lt;- add_criterion(\n  sleepstudy_pooled_spline_fit,\n  criterion = \"loo\"\n)\n\nError: object 'sleepstudy_pooled_spline_fit' not found\n\n\nCompare to the other model\n\nloo_compare(\n  loo(sleepstudy_pooled_fit),\n  loo(sleepstudy_pooled_spline_fit)\n)\n\nError: object 'sleepstudy_pooled_fit' not found\n\n\nIf there are high Pareto-k values\nFirst try moment matching:\n\nsleepstudy_pooled_spline_fit &lt;- add_criterion(\n  sleepstudy_pooled_spline_fit,\n  criterion = \"loo\",\n  moment_match = TRUE,\n  overwrite = TRUE\n)\n\nError: object 'sleepstudy_pooled_spline_fit' not found\n\n\nThen if there are a few remaining (and refitting is not going to take forever), try moment matching and reloo\n\nsleepstudy_pooled_spline_fit &lt;- add_criterion(\n  sleepstudy_pooled_spline_fit,\n  criterion = \"loo\",\n  moment_match = TRUE,\n  reloo = TRUE,\n  overwrite = TRUE\n)\n\nError: object 'sleepstudy_pooled_spline_fit' not found",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 8"
    ]
  },
  {
    "objectID": "template4.html",
    "href": "template4.html",
    "title": "Notebook for Assignment 4",
    "section": "",
    "text": "This assignment is related to Lecture 4 and BDA3 Chapters 3 and 10.\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 3.\nThe reading instructions for BDA3 Chapter 10.\n\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/blob/master/tests/assignment4.yml\", sep=\"\")\nset_assignment(assignment_path)    \n\nAssignment set:\nassignment4: Bayesian Data Analysis: Assignment 4\nThe assignment contain the following (4) tasks:\n- log_importance_weights\n- normalized_importance_weights\n- S_eff\n- posterior_mean\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"remotes\")\n    remotes::install_github(\"avehtari/BDA_course_Aalto\", subdir = \"rpackage\", upgrade=\"never\")\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\n\n\n\n\n\nThe following installs and loads the posterior package, which allows us to use its rvar Random Variable Datatype:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggdist package for advanced plotting functions:\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nggplot2::theme_set(theme_minimal(base_size = 14))\nif(!require(ggdist)){\n    install.packages(\"ggdist\")\n    library(ggdist)\n}\n\nLoading required package: ggdist",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 4"
    ]
  },
  {
    "objectID": "template4.html#setting-up-advanced-packages-posterior-and-ggdist",
    "href": "template4.html#setting-up-advanced-packages-posterior-and-ggdist",
    "title": "Notebook for Assignment 4",
    "section": "",
    "text": "The following installs and loads the posterior package, which allows us to use its rvar Random Variable Datatype:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggdist package for advanced plotting functions:\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nggplot2::theme_set(theme_minimal(base_size = 14))\nif(!require(ggdist)){\n    install.packages(\"ggdist\")\n    library(ggdist)\n}\n\nLoading required package: ggdist",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 4"
    ]
  },
  {
    "objectID": "assignment7.html",
    "href": "assignment7.html",
    "title": "Assignment 7",
    "section": "",
    "text": "The exercises here refer to the lecture 7/BDA chapter 5 content. The main topics for this assignment are the MCSE and importance sampling.\nThe exercises constitute 96% of the Quiz 7 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a rendered html file (to access the qmd file click the “&lt;/&gt; Code” button at the top right hand corner of the template)\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\nLecture 7/Chapter 5 of BDA Quiz (96% of grade)This week's assignment focuses on hierarchical models and modelling with brms.\nAn important building block of hierarchical models is the assumption of exchangeability. Let's review.\n1.1 Consider parameters \\(\\theta_j\\) for j in 1...J. Which of these statements correctly describes exchangeability? \n1.2 What best describes the difference between independence and exchangeability? \n\nConsider the following:  assume a box has n black and white balls but we do not know how many of each color. We pick a ball \\(y_1\\) at random, we do not put it back, and pick another ball \\(y_2\\) at random. Denote the number of black balls by B and white by W.1.3: Are observations \\( y_1 \\) and  \\( y_2 \\) exchangeable?1.4: Are observations \\(y_1\\) and \\(y_2\\) independent?1.5: Can we treat the two observations as if they are independent?1.6: Exchangeability allows us to express dependencies of data and parameters in a convenient form. Suppose we model a sequence of exchangeable random variables \\( \\theta \\) via a governing, or population distribution, where conditional on some unknown parameters \\( \\phi \\), we may assume independence between the elements of  \\( \\theta\\). Assume that \\(\\theta\\) has J elements, write down an equation that conveniently factors the joint probability \\( p(\\theta,\\phi) \\):De Finetti's theorem provides the theoretical basis for the equivalence to the independence assumption when J goes to infinity. In practice J is finite, but the difference may be small when J is relatively large. Check out the examples mentioned in the Chapter notes if you need more convincing. \\( \\phi \\) is in general unknown. so the marginal prior for \\( \\theta \\) must average over uncertainty in \\( \\phi \\): \\( \\int \\prod^J_{j=1} p(\\theta_j | \\phi) p(\\phi)d\\phi \\). 1.7 Based on the marginal prior formulation in the paragraph above, what can you say about the covariances \\( \\text{cov}( \\theta_i, \\theta_j) \\)?1.8 As with the parameters above, we often think of exchangeability as arising for our data model conditional on extra information x, such that the tuple \\((x_i,y_i)\\) are exchangeable whereas \\(y_i\\) might not be. In which modeling context is this useful? Assume that the target data is denoted by \\( y_i \\) \n2.1 Which of these best describes a hierarchical model?2.2: Consider that there are observations \\(y\\) indexed by observation number \\(i\\) and group \\(j\\). Suppose the data are modeled dependent on parameters \\( \\theta_j \\) where \\( j = 1,\\dotsc,J\\) indexes some meaningful grouping such as hospital-j specific health-outcomes, conditional on parameters \\( \\phi \\) which are hyper-parameters of the prior distribution of \\( \\theta_j \\). \\( \\phi \\) are modeled by prior distribution \\( p(\\phi) \\). We think of the distribution \\( p( \\theta_j | \\phi  ) \\) as the population distribution which generates the values for \\( \\theta \\) in the hierarchical model. What are some of the benefits of hierarchical models compared to separate models, which assume no relationship between j (and separate models are estimated), and pooled models, which consider all j jointly, but do not model j specific parameters? Throughout the rest of the course, we will often compare the hierarchical model, to a separate model and the pooled model. Suppose for the questions below that you are modeling data \\( y_{ij} \\) where \\( i \\) refers to an observation within the \\( j^{\\text{th}}\\) group, the observation model for \\( y_{ij} \\)  is normal, and we consider hierarchies at the level of the parameters describing the location of  \\( y_{ij} \\). 2.3 Based on the description of the above, the lecture and BDA chapter 5 content, which of these below would suggest a separate model for \\( y_{ij} \\)? \\(\\pi() \\) stands for some prior distribution and \\( \\eta_j \\) may be a vector of parameters such that  \\(cov(\\eta_s,\\eta_r) = 0 \\) for \\( s \\neq r \\).\n\n2.4 Based on the description of the above, the lecture and BDA chapter 5 content, which of these below would suggest a pooled model for \\( y_{ij} \\)? \\(\\pi() \\) stands for some prior distribution and \\( \\eta_j \\)  may be a vector of parameters such that  \\(cov(\\eta_s,\\eta_r) = 0 \\) for \\( s \\neq r \\).2.5: Based on the description of the above, the lecture and BDA chapter 5 content, which of these below would suggest a hierarchical model for \\( y_{ij} \\)? \\(\\pi() \\) stands for some prior distribution and \\( \\eta_j \\) may be a vector where \\(cov(\\eta_s,\\eta_r) = 0 \\) for \\( s \\neq r \\).2.6: Why are hierarchical models sometimes also referred to as partially pooled models. You may find it helpful to review the first unnumbered equation on page 115 of BDA3?It may help, before translating the model to code, to first describe the relationship between variables as a directed acyclic graph (DAG) (see lecture 7,slide 3).  We interpret the DAG starting from top to bottom as describing the generative mechanism implied by priors and observation model for \\( y_{ij} \\). Top level variables feed into distributions of lower level parameters and the observation model. Distributions are typically not further described in the DAG.  By drawing variables sequentially from top to bottom, you can generate fake observations (push-forward distribution). In the case that the parameters have not yet been updated by the data information, this push-forward distribution is called the prior predictive distribution of  \\( y \\).  You have already created such a prior predictive distribution in Assignment 1, question 7 and we will return to this in the sections below. 2.7: What is the difference between sequential draws from priors and the data model as described above to drawing from the joint posterior in Stan?In the Figure 1 below, assume that all circular nodes indicate that the object inside can be generated according to some distribution, conditional on the parent nodes.\nFigure 1\n2.8: Which of these equations properly describes the posterior for the model shown in the diagram?\n\nOften similar research studies in areas such as medicine or social science will be published under slightly different conditions or replicated with different subjects. It is of interest to summarise and integrate those findings for which hierarchical models have become increasingly popular. \n3.1: Suppose \\(y_i\\) is the point estimate for an effect size of a single study, \\( i \\). Why is it often appropriate to model \\( y_i \\) by a normal distribution with known standard deviation \\( \\sigma_i \\) which is taken as the standard error estimate for \\( y_i \\)?\n3.2 Why are hierarchical models preferable to separate and pooled models for meta-analysis? \n3.3 Suppose the assumption of exchangeability is false because you know the estimates of effects across studies depends on extra information \\( x_i \\), e.g. geolocation, and this has a substantial impact on the estimates. What should you do in this circumstance? \n3.4: Based on the discussion above, which of the below would refer to a hierarchical model for \\( y_i\\)?\nbrms is an R package which makes writing models with Stan easier.Suppose you have oberved the following variables, from different groups: \\(x, z, y\\). \\(i\\) is the observation number and \\(j\\) the group indicator. Assume a model \\(y_{ij} \\sim\\) normal\\((\\mu_{ij}, \\sigma)\\).Translate the following equations for the linear predictor term \\( \\mu_{ij}\\) into brms syntax:4.1 \\(\\mu_{ij} = \\alpha_0\\): 4.2 \\(\\mu_{ij} = \\alpha_0 + \\beta_1 x_i\\)4.3 \\(\\mu_{ij} = \\alpha_0 + \\beta_1 x_i + \\beta_2 z_i\\)4.4 \\(\\mu_{ij} = \\alpha_0 + \\alpha_j + \\beta_1 x_i\\)Note that in within brms, coefficients that do not vary according to some grouping index (e.g. \\( \\mu_{ij} = \\alpha_0 \\)) are called population effects while coefficients that vary according to some grouping are called varying effects (e.g. \\( \\mu_{ij} = \\alpha_j \\)). Some literatures refer to these parameters as fixed and random effects respectively, however in the context of Bayesian inference, this terminology can be misleading, since parameters in a model are treated as random variables. See here for more discussion on this. For the questions below, we will use brms terminology. \nIn this task, you will simulate data from a hierarchical model to gain better insight into it.\nThe following R code simulates data from a hierarchical structure, and then plots the results. Experiment with this function by using it on different values of the arguments, and answer the following questions. This code is also included in the notebook for this assignment.\n\nhierarchical_sim &lt;- function(group_pop_mean,\n                             between_group_sd,\n                             within_group_sd,\n                             n_groups,\n                             n_obs_per_group\n                             ) {  \n  # Generate group means\n  group_means &lt;- rnorm(n = n_groups, mean = group_pop_mean, sd = between_group_sd)\n  # Generate observations\n  ## Create an empty vector for observations\n  y &lt;- numeric()   \n  ## Create a vector for the group identifier   \n  group &lt;- rep(1:n_groups, each = n_obs_per_group)   \n  for (j in 1:n_groups) {\n    ### Generate one group observations     \n    group_y &lt;- rnorm(n = n_obs_per_group, mean = group_means[j], sd = within_group_sd)\n    ### Append the group observations to the vector\n    y &lt;- c(y, group_y)\n  }  \n  # Combine into a data frame   \n  data &lt;- data.frame(group = factor(group), y = y)   \n  # Plot the data\n  ggplot(data, aes(x = y, y = group)) +\n    geom_point() +\n    geom_vline(xintercept = group_pop_mean, linetype = \"dashed\")\n}\n\n5.1 Which of the following generative models does the code correspond to?\n\\(i\\) is the observation number, \\(j\\) is the group indicator.\n\n5.2 What does the vertical dashed line in the plot represent?\n5.3 Which function call would plausibly create Figure 2 below?Figure 2\n\n5.4 Which of these statements correctly describes the behaviour when the number of groups is increased?\n5.5 Which of these statements correctly describes the behaviour when the ratio of the between group and within group variance is changed?\nIn many studies, data will have been collected for the same people repeatedly (e.g. at different time points). A hierarchical model is well suited for such data as we can specify a grouping structure corresponding to the person/subject id. The sleepstudy\ndataset contains observations of reaction times for different people\nafter differing number of days of sleep deprivation.Your task is\nto fit a hierarchical normal linear model in brms. The observation model will be Reaction\\(_{ij} \\sim\\) normal\\((\\mu_{ij}, \\sigma)\\) where i refers to an observation id and j to the subject id.  But depending on the model, the \\(\\mu_{ij}\\) term will be differently parameterised.First fit a model with a population-level intercept, population-level effect of Days and varying intercept per Subject. Note: in order to have the Intercept parameter be more clearly interpretable, use `center = FALSE` when creating the brms formula (see the Parameterization of the population-level intercept secion in the [brms manual](https://rdrr.io/cran/brms/man/brmsformula.html). Centering refers here to data transformations made within the Stan model, that among other things makes sampling more efficient, but change the interpretation of the intercept. Section 5 of this demo provides some more insight into this.Use the following priors (check the code notebook for how to specify):\\(\\alpha_0 \\sim normal(250, 100)\\)\\(\\beta_0 \\sim normal(0, 20)\\)\\(\\alpha_j \\sim normal(0, \\tau)\\)\\(\\tau \\sim normal^+(0, 100)\\)\\(\\sigma \\sim normal^+(0, 100)\\)\n6.1 Which of these formulae correctly defines the linear predictor term in a model with population-level intercept, population-level effect of Days and varying intercepts per Subject?6.2 Which is the correct brms formula for this model?\n6.3 Based on the posterior, the estimate of the population-level intercept is .6.4 The population-level intercept can be interpreted as:\n6.5 Based on the posterior, the estimate of the population-level effect of Days on Reaction is .\n6.6 The population-level effect of Days can be interpreted as:\n6.7 Based on the posterior, the estimate of the standard deviation of the Intercept between Subjects is .\n6.8 The standard deviation of the Subject-specific Intercept can be interpreted as:\nNext fit a model with Subject-specific effects of Days in addition to the other terms.In this model, we can consider a correlation between the by-Subject Intercept and Days effects. This means the priors on \\(\\alpha_j\\) and \\(\\beta_j\\) can be considered as a multivariate normal \\((\\alpha_j, \\beta_j) \\sim N(0, \\Sigma)\\). It is common to decompose this into a prior on \\(\\alpha_j\\) and \\(\\beta_j\\) and a prior on the correlation matrix \\(R\\). Use the priors \\(\\alpha_j \\sim normal(0, \\tau_{\\alpha})\\), \\(\\beta_j \\sim normal(0, \\tau_{\\beta})\\), \\(\\tau_{\\alpha} \\sim normal^+(0, 100)\\), \\(\\tau_{\\beta} \\sim normal^+(0, 20)\\) and \\(R \\sim LKJ(2)\\).\n6.9 Which of these formulae\n    correctly defines the linear predictor in this case?6.10 Which is the correct brms formula for this model?\n6.11 Based on the posterior, the estimate of the standard deviation of Subject-specific effect of Days is .6.13 Based on the posterior, the estimate of correlation between the Subject-specific Intercept and effect of Days is .6.14 After fitting both models, which of the statements describe the results best (here interpret \"plausible\" as what is contained within the 95% posterior interval):\n\n\n\nAs you've learned from the above, hierarchical models are also useful for meta-analyses. The dataset dat.konstantopolous2011 from the metadat package contains results from different studies conducted on the effect of changing the school calendar from a standard one with a long summer break to a modified one with more regular but shorter breaks.Each result of a study is a standardized estimated mean effect on student achievement, where positive values indicate improvement (yi) and the variance of the estimate (vi) for a school.\nThe meta-analysis model can be written as follows: \\(y_{ijk} \\sim normal(\\mu_{ijk}, \\sigma_{ijk})\\). \\(i\\) refers to an observation, \\(j\\) refers to a school, \\(k\\)\n    refers to a district. \\(\\mu_{ijk}\\) thus refers to one observation \\(i\\) at school \\(j\\) in district \\(k\\). \\(\\mu_0\\) is the\n    population-level effect, \\(\\mu_j\\) is the school-specific effect,\n    and \\(\\mu_k\\) is the district-specific effect.\nIn this case, the \\(\\sigma_{ijk}\\) values are known (the standard errors reported from each study) and the \\(\\mu_{ijk}\\) term will differ depending on the model.\nIn this exercise you will fit four different models to the same data set: Pooled, separate, partially pooled within school-specific effects, and partially pooled within schools and district effects.\nFor all models, use brms with the default priors and use the following settings:iter = 2000, warmup = 1000, chains = 4, seed = 2024\nThe dataset has separate columns for school and district, but for the models, we will want a unique identifier for each school. Before fitting any models, add a new column to the dataset called \"district_school\" which is the combination of the district and the school. This is then unique for each school, and will be used in the model formulae.\nPooled model:\nUse brms to fit a pooled model and answer the following questions. Check the code notebook for help starting.\nThe pooled model formula is: \\(\\mu_{ijk} = \\mu_0\\).7.1 The pooled model is written as:\n\n7.2 How many parameters are estimated in the pooled model?\n7.3 What is the Rhat value for the Intercept term?\n7.4 Based on the Rhat value, have the chains converged?\n7.5 What is the posterior mean (labelled Estimate) and lower and upper 95% posterior interval bounds (labelled CI) for the Intercept?Mean: , lower 95% interval bound: , upper 95% interval bound: \n7.6 Based on the posterior of the Intercept, what would you conclude about the effect of the intervention:7.7 Suppose there is a new school in an existing district (School = 9, District = 86). What is the mean prediction for the effect in this school? Use the function`posterior_epred` and the newdata argument.\n7.8 Suppose there is a new school in a new district (School = 1,\n    District = 30). What is the mean prediction for the effect in this\n    school? Use the function`posterior_epred` and the newdata argument.\nSeparate model:\nUse brms to fit a separate model and answer the following questions. Check the code notebook for help starting.\n\n\nThe separate model formula is: \\(\\mu_{ijk}= \\mu_{jk}\\).7.9 The separate model is written as:\n7.10 How many parameters are estimated in the separate model?\n7.11 What is the estimated effect for School 3 in District 71?Mean: , lower 95% interval bound: , upper 95% interval bound: \n7.12 What is the estimated effect of School 7 in District 86?Mean: , lower 95% interval bound: , upper 95% interval bound: 7.13 Based on the posterior for the separate model, what could reasonably be concluded about the effect of the intervention:7.14 Suppose there is a new\n    school in an existing district (District = 86, School = 9). Why can we not easily predict the effect for this school based on the separate model posterior?\nPartially pooled model for schools.\n\nThe partially pooled model formula is: \\(\\mu_{ijk} = \\mu_0 + \\mu_j\\)7.15 And the partially pooled hierarchical model:\n\n\n7.16 How many parameters are estimated in the partially pooled for schools model?\n7.17 Based on the posterior for the partially pooled model, what could reasonably be concluded about the effect of the intervention:\n7.18 What is the estimated effect for School 3 in District 71?Mean: , lower 95% interval bound: , upper 95% interval bound: \n7.19 What is the estimated effect of School 7 in District 86?Mean: , lower 95% interval bound: , upper 95% interval bound: \n\n7.20 Suppose there is a new\n    school in an existing district (District = 86, School = 9). What would\n    the mean prediction for the effect in this school? Use the\n    function`posterior_epred` and the newdata argument with allow_new_levels = TRUE.\n7.21 Suppose there is a new school in a new district (District = 30, School = 1). What would the mean prediction for the effect in this\n    school? Use the function`posterior_epred` and the newdata argument with allow_new_levels = TRUE.\n\n\nPartially pooled model for schools in districts:\n\nIn this data set, as there is a two-level structure, where schools are\n    nested in districts, we can add another level to the hierarchy. The additional hierarchy formula is: \\(\\mu_{ijk} = \\mu_0 + \\mu_j + \\mu_k\\)\n7.22 What is the correct brms formula?7.23 How many parameters are estimated in the partially pooled for schools in districts model?\n\n7.24 Suppose there is a new\n    school in an existing district (District = 86, School = 9). What is\n    the mean prediction for the effect in this school? Use the\n    function`posterior_epred` and the newdata argument with allow_new_levels = TRUE.\n7.25 Suppose there is a new school in a new district (District = 30, School = 1). What is the mean prediction for the effect in this\n    school? Use the function`posterior_epred` and the `newdata` argument with `allow_new_levels = TRUE`.7.26 Which of the following statements are true relating to exchangeability assumptions in the models:\n7.27 After fitting all the models, choose which of the following statements relating to the results are true:",
    "crumbs": [
      "Assignments",
      "Assignment 7"
    ]
  },
  {
    "objectID": "assignment7.html#assignment-questions",
    "href": "assignment7.html#assignment-questions",
    "title": "Assignment 7",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\nLecture 7/Chapter 5 of BDA Quiz (96% of grade)This week's assignment focuses on hierarchical models and modelling with brms.\nAn important building block of hierarchical models is the assumption of exchangeability. Let's review.\n1.1 Consider parameters \\(\\theta_j\\) for j in 1...J. Which of these statements correctly describes exchangeability? \n1.2 What best describes the difference between independence and exchangeability? \n\nConsider the following:  assume a box has n black and white balls but we do not know how many of each color. We pick a ball \\(y_1\\) at random, we do not put it back, and pick another ball \\(y_2\\) at random. Denote the number of black balls by B and white by W.1.3: Are observations \\( y_1 \\) and  \\( y_2 \\) exchangeable?1.4: Are observations \\(y_1\\) and \\(y_2\\) independent?1.5: Can we treat the two observations as if they are independent?1.6: Exchangeability allows us to express dependencies of data and parameters in a convenient form. Suppose we model a sequence of exchangeable random variables \\( \\theta \\) via a governing, or population distribution, where conditional on some unknown parameters \\( \\phi \\), we may assume independence between the elements of  \\( \\theta\\). Assume that \\(\\theta\\) has J elements, write down an equation that conveniently factors the joint probability \\( p(\\theta,\\phi) \\):De Finetti's theorem provides the theoretical basis for the equivalence to the independence assumption when J goes to infinity. In practice J is finite, but the difference may be small when J is relatively large. Check out the examples mentioned in the Chapter notes if you need more convincing. \\( \\phi \\) is in general unknown. so the marginal prior for \\( \\theta \\) must average over uncertainty in \\( \\phi \\): \\( \\int \\prod^J_{j=1} p(\\theta_j | \\phi) p(\\phi)d\\phi \\). 1.7 Based on the marginal prior formulation in the paragraph above, what can you say about the covariances \\( \\text{cov}( \\theta_i, \\theta_j) \\)?1.8 As with the parameters above, we often think of exchangeability as arising for our data model conditional on extra information x, such that the tuple \\((x_i,y_i)\\) are exchangeable whereas \\(y_i\\) might not be. In which modeling context is this useful? Assume that the target data is denoted by \\( y_i \\) \n2.1 Which of these best describes a hierarchical model?2.2: Consider that there are observations \\(y\\) indexed by observation number \\(i\\) and group \\(j\\). Suppose the data are modeled dependent on parameters \\( \\theta_j \\) where \\( j = 1,\\dotsc,J\\) indexes some meaningful grouping such as hospital-j specific health-outcomes, conditional on parameters \\( \\phi \\) which are hyper-parameters of the prior distribution of \\( \\theta_j \\). \\( \\phi \\) are modeled by prior distribution \\( p(\\phi) \\). We think of the distribution \\( p( \\theta_j | \\phi  ) \\) as the population distribution which generates the values for \\( \\theta \\) in the hierarchical model. What are some of the benefits of hierarchical models compared to separate models, which assume no relationship between j (and separate models are estimated), and pooled models, which consider all j jointly, but do not model j specific parameters? Throughout the rest of the course, we will often compare the hierarchical model, to a separate model and the pooled model. Suppose for the questions below that you are modeling data \\( y_{ij} \\) where \\( i \\) refers to an observation within the \\( j^{\\text{th}}\\) group, the observation model for \\( y_{ij} \\)  is normal, and we consider hierarchies at the level of the parameters describing the location of  \\( y_{ij} \\). 2.3 Based on the description of the above, the lecture and BDA chapter 5 content, which of these below would suggest a separate model for \\( y_{ij} \\)? \\(\\pi() \\) stands for some prior distribution and \\( \\eta_j \\) may be a vector of parameters such that  \\(cov(\\eta_s,\\eta_r) = 0 \\) for \\( s \\neq r \\).\n\n2.4 Based on the description of the above, the lecture and BDA chapter 5 content, which of these below would suggest a pooled model for \\( y_{ij} \\)? \\(\\pi() \\) stands for some prior distribution and \\( \\eta_j \\)  may be a vector of parameters such that  \\(cov(\\eta_s,\\eta_r) = 0 \\) for \\( s \\neq r \\).2.5: Based on the description of the above, the lecture and BDA chapter 5 content, which of these below would suggest a hierarchical model for \\( y_{ij} \\)? \\(\\pi() \\) stands for some prior distribution and \\( \\eta_j \\) may be a vector where \\(cov(\\eta_s,\\eta_r) = 0 \\) for \\( s \\neq r \\).2.6: Why are hierarchical models sometimes also referred to as partially pooled models. You may find it helpful to review the first unnumbered equation on page 115 of BDA3?It may help, before translating the model to code, to first describe the relationship between variables as a directed acyclic graph (DAG) (see lecture 7,slide 3).  We interpret the DAG starting from top to bottom as describing the generative mechanism implied by priors and observation model for \\( y_{ij} \\). Top level variables feed into distributions of lower level parameters and the observation model. Distributions are typically not further described in the DAG.  By drawing variables sequentially from top to bottom, you can generate fake observations (push-forward distribution). In the case that the parameters have not yet been updated by the data information, this push-forward distribution is called the prior predictive distribution of  \\( y \\).  You have already created such a prior predictive distribution in Assignment 1, question 7 and we will return to this in the sections below. 2.7: What is the difference between sequential draws from priors and the data model as described above to drawing from the joint posterior in Stan?In the Figure 1 below, assume that all circular nodes indicate that the object inside can be generated according to some distribution, conditional on the parent nodes.\nFigure 1\n2.8: Which of these equations properly describes the posterior for the model shown in the diagram?\n\nOften similar research studies in areas such as medicine or social science will be published under slightly different conditions or replicated with different subjects. It is of interest to summarise and integrate those findings for which hierarchical models have become increasingly popular. \n3.1: Suppose \\(y_i\\) is the point estimate for an effect size of a single study, \\( i \\). Why is it often appropriate to model \\( y_i \\) by a normal distribution with known standard deviation \\( \\sigma_i \\) which is taken as the standard error estimate for \\( y_i \\)?\n3.2 Why are hierarchical models preferable to separate and pooled models for meta-analysis? \n3.3 Suppose the assumption of exchangeability is false because you know the estimates of effects across studies depends on extra information \\( x_i \\), e.g. geolocation, and this has a substantial impact on the estimates. What should you do in this circumstance? \n3.4: Based on the discussion above, which of the below would refer to a hierarchical model for \\( y_i\\)?\nbrms is an R package which makes writing models with Stan easier.Suppose you have oberved the following variables, from different groups: \\(x, z, y\\). \\(i\\) is the observation number and \\(j\\) the group indicator. Assume a model \\(y_{ij} \\sim\\) normal\\((\\mu_{ij}, \\sigma)\\).Translate the following equations for the linear predictor term \\( \\mu_{ij}\\) into brms syntax:4.1 \\(\\mu_{ij} = \\alpha_0\\): 4.2 \\(\\mu_{ij} = \\alpha_0 + \\beta_1 x_i\\)4.3 \\(\\mu_{ij} = \\alpha_0 + \\beta_1 x_i + \\beta_2 z_i\\)4.4 \\(\\mu_{ij} = \\alpha_0 + \\alpha_j + \\beta_1 x_i\\)Note that in within brms, coefficients that do not vary according to some grouping index (e.g. \\( \\mu_{ij} = \\alpha_0 \\)) are called population effects while coefficients that vary according to some grouping are called varying effects (e.g. \\( \\mu_{ij} = \\alpha_j \\)). Some literatures refer to these parameters as fixed and random effects respectively, however in the context of Bayesian inference, this terminology can be misleading, since parameters in a model are treated as random variables. See here for more discussion on this. For the questions below, we will use brms terminology. \nIn this task, you will simulate data from a hierarchical model to gain better insight into it.\nThe following R code simulates data from a hierarchical structure, and then plots the results. Experiment with this function by using it on different values of the arguments, and answer the following questions. This code is also included in the notebook for this assignment.\n\nhierarchical_sim &lt;- function(group_pop_mean,\n                             between_group_sd,\n                             within_group_sd,\n                             n_groups,\n                             n_obs_per_group\n                             ) {  \n  # Generate group means\n  group_means &lt;- rnorm(n = n_groups, mean = group_pop_mean, sd = between_group_sd)\n  # Generate observations\n  ## Create an empty vector for observations\n  y &lt;- numeric()   \n  ## Create a vector for the group identifier   \n  group &lt;- rep(1:n_groups, each = n_obs_per_group)   \n  for (j in 1:n_groups) {\n    ### Generate one group observations     \n    group_y &lt;- rnorm(n = n_obs_per_group, mean = group_means[j], sd = within_group_sd)\n    ### Append the group observations to the vector\n    y &lt;- c(y, group_y)\n  }  \n  # Combine into a data frame   \n  data &lt;- data.frame(group = factor(group), y = y)   \n  # Plot the data\n  ggplot(data, aes(x = y, y = group)) +\n    geom_point() +\n    geom_vline(xintercept = group_pop_mean, linetype = \"dashed\")\n}\n\n5.1 Which of the following generative models does the code correspond to?\n\\(i\\) is the observation number, \\(j\\) is the group indicator.\n\n5.2 What does the vertical dashed line in the plot represent?\n5.3 Which function call would plausibly create Figure 2 below?Figure 2\n\n5.4 Which of these statements correctly describes the behaviour when the number of groups is increased?\n5.5 Which of these statements correctly describes the behaviour when the ratio of the between group and within group variance is changed?\nIn many studies, data will have been collected for the same people repeatedly (e.g. at different time points). A hierarchical model is well suited for such data as we can specify a grouping structure corresponding to the person/subject id. The sleepstudy\ndataset contains observations of reaction times for different people\nafter differing number of days of sleep deprivation.Your task is\nto fit a hierarchical normal linear model in brms. The observation model will be Reaction\\(_{ij} \\sim\\) normal\\((\\mu_{ij}, \\sigma)\\) where i refers to an observation id and j to the subject id.  But depending on the model, the \\(\\mu_{ij}\\) term will be differently parameterised.First fit a model with a population-level intercept, population-level effect of Days and varying intercept per Subject. Note: in order to have the Intercept parameter be more clearly interpretable, use `center = FALSE` when creating the brms formula (see the Parameterization of the population-level intercept secion in the [brms manual](https://rdrr.io/cran/brms/man/brmsformula.html). Centering refers here to data transformations made within the Stan model, that among other things makes sampling more efficient, but change the interpretation of the intercept. Section 5 of this demo provides some more insight into this.Use the following priors (check the code notebook for how to specify):\\(\\alpha_0 \\sim normal(250, 100)\\)\\(\\beta_0 \\sim normal(0, 20)\\)\\(\\alpha_j \\sim normal(0, \\tau)\\)\\(\\tau \\sim normal^+(0, 100)\\)\\(\\sigma \\sim normal^+(0, 100)\\)\n6.1 Which of these formulae correctly defines the linear predictor term in a model with population-level intercept, population-level effect of Days and varying intercepts per Subject?6.2 Which is the correct brms formula for this model?\n6.3 Based on the posterior, the estimate of the population-level intercept is .6.4 The population-level intercept can be interpreted as:\n6.5 Based on the posterior, the estimate of the population-level effect of Days on Reaction is .\n6.6 The population-level effect of Days can be interpreted as:\n6.7 Based on the posterior, the estimate of the standard deviation of the Intercept between Subjects is .\n6.8 The standard deviation of the Subject-specific Intercept can be interpreted as:\nNext fit a model with Subject-specific effects of Days in addition to the other terms.In this model, we can consider a correlation between the by-Subject Intercept and Days effects. This means the priors on \\(\\alpha_j\\) and \\(\\beta_j\\) can be considered as a multivariate normal \\((\\alpha_j, \\beta_j) \\sim N(0, \\Sigma)\\). It is common to decompose this into a prior on \\(\\alpha_j\\) and \\(\\beta_j\\) and a prior on the correlation matrix \\(R\\). Use the priors \\(\\alpha_j \\sim normal(0, \\tau_{\\alpha})\\), \\(\\beta_j \\sim normal(0, \\tau_{\\beta})\\), \\(\\tau_{\\alpha} \\sim normal^+(0, 100)\\), \\(\\tau_{\\beta} \\sim normal^+(0, 20)\\) and \\(R \\sim LKJ(2)\\).\n6.9 Which of these formulae\n    correctly defines the linear predictor in this case?6.10 Which is the correct brms formula for this model?\n6.11 Based on the posterior, the estimate of the standard deviation of Subject-specific effect of Days is .6.13 Based on the posterior, the estimate of correlation between the Subject-specific Intercept and effect of Days is .6.14 After fitting both models, which of the statements describe the results best (here interpret \"plausible\" as what is contained within the 95% posterior interval):\n\n\n\nAs you've learned from the above, hierarchical models are also useful for meta-analyses. The dataset dat.konstantopolous2011 from the metadat package contains results from different studies conducted on the effect of changing the school calendar from a standard one with a long summer break to a modified one with more regular but shorter breaks.Each result of a study is a standardized estimated mean effect on student achievement, where positive values indicate improvement (yi) and the variance of the estimate (vi) for a school.\nThe meta-analysis model can be written as follows: \\(y_{ijk} \\sim normal(\\mu_{ijk}, \\sigma_{ijk})\\). \\(i\\) refers to an observation, \\(j\\) refers to a school, \\(k\\)\n    refers to a district. \\(\\mu_{ijk}\\) thus refers to one observation \\(i\\) at school \\(j\\) in district \\(k\\). \\(\\mu_0\\) is the\n    population-level effect, \\(\\mu_j\\) is the school-specific effect,\n    and \\(\\mu_k\\) is the district-specific effect.\nIn this case, the \\(\\sigma_{ijk}\\) values are known (the standard errors reported from each study) and the \\(\\mu_{ijk}\\) term will differ depending on the model.\nIn this exercise you will fit four different models to the same data set: Pooled, separate, partially pooled within school-specific effects, and partially pooled within schools and district effects.\nFor all models, use brms with the default priors and use the following settings:iter = 2000, warmup = 1000, chains = 4, seed = 2024\nThe dataset has separate columns for school and district, but for the models, we will want a unique identifier for each school. Before fitting any models, add a new column to the dataset called \"district_school\" which is the combination of the district and the school. This is then unique for each school, and will be used in the model formulae.\nPooled model:\nUse brms to fit a pooled model and answer the following questions. Check the code notebook for help starting.\nThe pooled model formula is: \\(\\mu_{ijk} = \\mu_0\\).7.1 The pooled model is written as:\n\n7.2 How many parameters are estimated in the pooled model?\n7.3 What is the Rhat value for the Intercept term?\n7.4 Based on the Rhat value, have the chains converged?\n7.5 What is the posterior mean (labelled Estimate) and lower and upper 95% posterior interval bounds (labelled CI) for the Intercept?Mean: , lower 95% interval bound: , upper 95% interval bound: \n7.6 Based on the posterior of the Intercept, what would you conclude about the effect of the intervention:7.7 Suppose there is a new school in an existing district (School = 9, District = 86). What is the mean prediction for the effect in this school? Use the function`posterior_epred` and the newdata argument.\n7.8 Suppose there is a new school in a new district (School = 1,\n    District = 30). What is the mean prediction for the effect in this\n    school? Use the function`posterior_epred` and the newdata argument.\nSeparate model:\nUse brms to fit a separate model and answer the following questions. Check the code notebook for help starting.\n\n\nThe separate model formula is: \\(\\mu_{ijk}= \\mu_{jk}\\).7.9 The separate model is written as:\n7.10 How many parameters are estimated in the separate model?\n7.11 What is the estimated effect for School 3 in District 71?Mean: , lower 95% interval bound: , upper 95% interval bound: \n7.12 What is the estimated effect of School 7 in District 86?Mean: , lower 95% interval bound: , upper 95% interval bound: 7.13 Based on the posterior for the separate model, what could reasonably be concluded about the effect of the intervention:7.14 Suppose there is a new\n    school in an existing district (District = 86, School = 9). Why can we not easily predict the effect for this school based on the separate model posterior?\nPartially pooled model for schools.\n\nThe partially pooled model formula is: \\(\\mu_{ijk} = \\mu_0 + \\mu_j\\)7.15 And the partially pooled hierarchical model:\n\n\n7.16 How many parameters are estimated in the partially pooled for schools model?\n7.17 Based on the posterior for the partially pooled model, what could reasonably be concluded about the effect of the intervention:\n7.18 What is the estimated effect for School 3 in District 71?Mean: , lower 95% interval bound: , upper 95% interval bound: \n7.19 What is the estimated effect of School 7 in District 86?Mean: , lower 95% interval bound: , upper 95% interval bound: \n\n7.20 Suppose there is a new\n    school in an existing district (District = 86, School = 9). What would\n    the mean prediction for the effect in this school? Use the\n    function`posterior_epred` and the newdata argument with allow_new_levels = TRUE.\n7.21 Suppose there is a new school in a new district (District = 30, School = 1). What would the mean prediction for the effect in this\n    school? Use the function`posterior_epred` and the newdata argument with allow_new_levels = TRUE.\n\n\nPartially pooled model for schools in districts:\n\nIn this data set, as there is a two-level structure, where schools are\n    nested in districts, we can add another level to the hierarchy. The additional hierarchy formula is: \\(\\mu_{ijk} = \\mu_0 + \\mu_j + \\mu_k\\)\n7.22 What is the correct brms formula?7.23 How many parameters are estimated in the partially pooled for schools in districts model?\n\n7.24 Suppose there is a new\n    school in an existing district (District = 86, School = 9). What is\n    the mean prediction for the effect in this school? Use the\n    function`posterior_epred` and the newdata argument with allow_new_levels = TRUE.\n7.25 Suppose there is a new school in a new district (District = 30, School = 1). What is the mean prediction for the effect in this\n    school? Use the function`posterior_epred` and the `newdata` argument with `allow_new_levels = TRUE`.7.26 Which of the following statements are true relating to exchangeability assumptions in the models:\n7.27 After fitting all the models, choose which of the following statements relating to the results are true:",
    "crumbs": [
      "Assignments",
      "Assignment 7"
    ]
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "Assignment 4",
    "section": "",
    "text": "The exercises here refer to the lecture 4/BDA chapters 3 and 10 content. The main topics for this assignment are the MCSE and importance sampling.\nThe exercises constitute 96% of the Quiz 4 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a rendered html file (to access the qmd file click the “&lt;/&gt; Code” button at the top right hand corner of the template)\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\n    \n        \n            \n            \n            \n            \n            \n            \n            \n            \n            As, always, please see the provided code notebook from the website to help you get started on the coding tasks.\n            \n            \n            This task is about understanding and calculating Monte Carlo standard error.\n            \n            1.1 Which of these correctly describes MCSE:\n            \n            \n            \n            We will explore mean estimates and MCSE estimates of two distributions.\n            First is the gamma distribution, parameterised with shape (alpha) and rate (beta).\n            1.2 Look up the gamma distribution in Appendix A in BDA (or wikipedia). What is the mean of the gamma(alpha = 3, beta = 3) distribution?\n        \n        Use the appropriate R function to draw a sample of size 1000 from a gamma(3, 3) distribution. \n        1.3 Which of these commands correctly does this:\n        \n            \n            One way to calculate the Monte Carlo standard error of the mean is to repeatedly take samples of draws from the distribution, calculate the mean of each sample and then the standard deviation of the means. Let's re-calculate the mean with a lower number of draws.\n            \n            1.4 Which of these best describes the relationship between the empirical mean of the sample of size 400 and the analytical mean of the gamma(3, 3) distribution?\n            Simulate 2000 samples, each of 400 draws from the Gamma(3, 3), calculate and save the mean of each sample. Then calculate the standard deviation of the sample of means.Adjust the following R code to do this:\n            \n              # create a vector to store the sample means\n  sample_means &lt;- rep(NA, times = NUMBER_OF_SAMPLES)\n  # loop over the number of samples\n  for (i in 1:NUMBER_OF_SAMPLES) {\n    # generate a sample from the gamma distribution of size 400\n    sample &lt;- ...\n    # calculate the sample mean and save it to the vector\n    sample_means[i] &lt;- ...\n  }\n  # calculate the standard deviation of the sample means\n  sd(...)\n  \n            \n\n            1.5 Enter the MCSE that is calculated from the code (enter with two decimal places): Now, explore the Cauchy(location = 0, scale = 1) distribution. The corresponding functions are named similarly to the gamma functions above.\n            \n            1.6 What is the mean of the Cauchy(0, 1) distribution?\n            \n            Change the simulation to take samples of the Cauchy(0, 1) distribution and calculate the MCSE of the mean. Try this a few times.\n            \n            \n            1.7 What do you notice about the MCSE for the mean of the Cauchy and gamma distributions? \n            \n            The Central Limit Theorem (CLT) gives us the conditions under which it is also possible to estimate the MCSE from a single sample (see lecture slides and for excellent visual intuition, check out \"But what is the Central Limit Theorem\" by 3Blue1Brown ) for means and other functions of the posterior. The function mcse_mean from the posterior package provides this method (more on this is also mentioned in the lecture).\n            \n            1.8 Let’s put the claims of the CLT to test. Assume you’ve taken \\(N\\) draws of a random variable and stored them in a vector \\(\\theta\\). Assume also that the random variable follows a distribution with finite mean and variance, what is the correct formula for the MCSE of the mean?  \\(SD\\) denotes the standard deviation and \\(var\\) the variance of \\(\\theta\\).\n            \n            \n            1.9 Based on what you learned about the Gamma(3, 3) and the Cauchy(0, 1) distributions, which of these statements is correct?\n            \n            \n            The Pareto-k diagnostic can be used to diagnose whether the mean (or other moments) exists. The function posterior::pareto_khat() calculates this for a sample of draws. Calculate the Pareto-k for samples of 400 draws from the gamma(3, 3) and the Cauchy(0, 1) distributions.\n            \n            1.10 Which of these is true:\n            \n        \n        MCSE can be calculated for any estimate, including quantiles and probability and can be used to guide how many digits to report for a given estimate. Suppose you calculate the following summary of a parameter:\n        mean = 0.483834 (MCSE = 0.003)\n        5% quantile = 0.234536 (MCSE = 0.01)\n        95% quantile = 1.34823 (MCSE = 0.2)\n        \n    \n    \n    1.11 Based on recommendations from the lecture how should you report for the mean?\n    \n\n    1.12 Based on recommendations from the lecture how should you report the 5% quantile?\n\n\n\n\n    1.13 Based on recommendations from the lecture how should you report the 95% quantile?\n\n\n    \n    \n        \n            \n                \n                \n            \n        \n        \n            \n            In this exercise, you will use a dose-response relation model that is used in BDA3 Section 3.7 and in the chapter reading notes.The likelihood is the same as in the book, but instead of uniform priors, we will use a bivariate normal distribution as the joint prior distribution of the parameters \\(\\alpha\\) and \\(\\beta\\).\n            In the prior distribution for \\((\\alpha,\\beta)\\), the marginal distributions are \\(\\alpha \\sim N(0,2^2)\\) and \\(\\beta \\sim N(10,10^2)\\), and the correlation between them is \\(\\mathrm{corr}(\\alpha, \\beta)=0.6\\).\n\n            2.1 The mean of the prior distribution for \\((\\alpha, \\beta)\\) is: \n            2.2 The covariance of the prior distribution (two by two matrix) is: \n            \n        \n        \n            \n        \n        For this section, you will estimate the posterior mean by weighting prior draws with the appropriate importance weights. To do this you will need to calculate the unnormalized importance ratios \\(\\tilde{w}\\) (also known as weights) when the importance sampling target distribution \\(q(\\theta)\\) is the posterior distribution, and the proposal distribution \\(g(\\theta)\\) is the prior distribution as defined above. You will then need to use this function to calculate the importance sampling estimate of the posterior mean, given draws from the prior.\n        \n        \n            3.1 What is the general formula for the importance ratios (also called importance weights)?\n            \n            \n            \n            3.2 What is the correct formula for the importance ratios in the case where the prior is the proposal and the posterior is the target?\n            \n                \n                \n            \n            3.3 What is the correct formula for the unnormalized importance ratios in the case where the prior is the proposal and the posterior is the target?\n            \n                \n                \n                    \n                \n            \n        \n        3.4 The unnormalized log importance ratios in the case where the prior is the proposal and the posterior is the target simplify to:\n        \n        \n        \n        3.5 Why is it better to compute the importance rations on the log scale?\n        \n        \n        \n        The function `bioassaylp` from the aaltobda package calculates the unnormalized log posterior density assuming a uniform prior.\n        \n        3.6 What is the relationship between the posterior, likelihood and prior when the prior is uniform? \n        \n        \n            3.7 What is the correct formula or formulas for the self-normalized importance sampling estimate of the mean? \\(w\\) are the unnormalized importance weights, and \\(\\tilde{w}\\) are the self-normalized weights.\n            \n            \n            \n            Use the function rmvnorm to draw 4000 draws from the prior specified in question 2, calculate the importance weights and then the importance sampling estimate of the posterior mean.\n            \n            3.8 The importance sampling estimate of the posterior mean is: \n            \n            alpha: , beta: .\n            \n            3.9 What is the equation for the generic effective sample size (ESS) estimate for importance sampling?\n            \n            \n                \n                3.10 Importance sampling ESS: \n                \n                3.11 What is the MCSE of the estimates? Make sure to use the ESS in the denominator instead of the sample size.\n            \n            \n            \n                alpha: , beta: .\n                \n                3.12 What is the Pareto-k diagnostic of the importance ratios (enter value with one decimal)? .\n                \n                3.13 Based on the value, should you trust the importance sampling estimate of the mean?\n            \n            \n            \n                \n                    \n                \n            \n            \n                \n                    You are given 4000 independent draws from the posterior distributionof the model in the dataset `bioassay_posterior` in the `aaltobda` package.\n                    4.1 The posterior can be summarised by the means and 90% posterior interval.What is the mean, 5% and 95% quantiles of the posterior draws for the parameters?mean of alpha: , 5% quantile of alpha: , 95% quantile of alpha: \n                    mean of beta: , 5% quantile of beta: , 95% quantile of beta: \n                \n                \n                4.2 What is the MCSE for the mean and quantiles (remember that they are independent draws)?For alpha: MCSE for mean: , MCSE for 5% quantile: , MCSE for 95% quantile: \n                \n                For beta: MCSE for mean: , MCSE for 5% quantile: , MCSE for 95% quantile: \n            \n            \n            Compare these posterior summaries to the importance sampling estimate.\n            \n            4.3 How does the importance sampling estimate of the posterior mean compare to the estimate from independent posterior draws?\n            \n            \n            Remember that the LD50 (median lethal dose) is equal to \\( exp( -\\alpha / \\beta) \\). \n            Calculate the posterior probability that the LD50 is less than 0.85ml/g. Also calculate the MCSE for this probability.\n            \n            4.4 Pr(LD50 &lt; 0.85 ml/g) = , MCSE =",
    "crumbs": [
      "Assignments",
      "Assignment 4"
    ]
  },
  {
    "objectID": "assignment4.html#assignment-questions",
    "href": "assignment4.html#assignment-questions",
    "title": "Assignment 4",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\n    \n        \n            \n            \n            \n            \n            \n            \n            \n            \n            As, always, please see the provided code notebook from the website to help you get started on the coding tasks.\n            \n            \n            This task is about understanding and calculating Monte Carlo standard error.\n            \n            1.1 Which of these correctly describes MCSE:\n            \n            \n            \n            We will explore mean estimates and MCSE estimates of two distributions.\n            First is the gamma distribution, parameterised with shape (alpha) and rate (beta).\n            1.2 Look up the gamma distribution in Appendix A in BDA (or wikipedia). What is the mean of the gamma(alpha = 3, beta = 3) distribution?\n        \n        Use the appropriate R function to draw a sample of size 1000 from a gamma(3, 3) distribution. \n        1.3 Which of these commands correctly does this:\n        \n            \n            One way to calculate the Monte Carlo standard error of the mean is to repeatedly take samples of draws from the distribution, calculate the mean of each sample and then the standard deviation of the means. Let's re-calculate the mean with a lower number of draws.\n            \n            1.4 Which of these best describes the relationship between the empirical mean of the sample of size 400 and the analytical mean of the gamma(3, 3) distribution?\n            Simulate 2000 samples, each of 400 draws from the Gamma(3, 3), calculate and save the mean of each sample. Then calculate the standard deviation of the sample of means.Adjust the following R code to do this:\n            \n              # create a vector to store the sample means\n  sample_means &lt;- rep(NA, times = NUMBER_OF_SAMPLES)\n  # loop over the number of samples\n  for (i in 1:NUMBER_OF_SAMPLES) {\n    # generate a sample from the gamma distribution of size 400\n    sample &lt;- ...\n    # calculate the sample mean and save it to the vector\n    sample_means[i] &lt;- ...\n  }\n  # calculate the standard deviation of the sample means\n  sd(...)\n  \n            \n\n            1.5 Enter the MCSE that is calculated from the code (enter with two decimal places): Now, explore the Cauchy(location = 0, scale = 1) distribution. The corresponding functions are named similarly to the gamma functions above.\n            \n            1.6 What is the mean of the Cauchy(0, 1) distribution?\n            \n            Change the simulation to take samples of the Cauchy(0, 1) distribution and calculate the MCSE of the mean. Try this a few times.\n            \n            \n            1.7 What do you notice about the MCSE for the mean of the Cauchy and gamma distributions? \n            \n            The Central Limit Theorem (CLT) gives us the conditions under which it is also possible to estimate the MCSE from a single sample (see lecture slides and for excellent visual intuition, check out \"But what is the Central Limit Theorem\" by 3Blue1Brown ) for means and other functions of the posterior. The function mcse_mean from the posterior package provides this method (more on this is also mentioned in the lecture).\n            \n            1.8 Let’s put the claims of the CLT to test. Assume you’ve taken \\(N\\) draws of a random variable and stored them in a vector \\(\\theta\\). Assume also that the random variable follows a distribution with finite mean and variance, what is the correct formula for the MCSE of the mean?  \\(SD\\) denotes the standard deviation and \\(var\\) the variance of \\(\\theta\\).\n            \n            \n            1.9 Based on what you learned about the Gamma(3, 3) and the Cauchy(0, 1) distributions, which of these statements is correct?\n            \n            \n            The Pareto-k diagnostic can be used to diagnose whether the mean (or other moments) exists. The function posterior::pareto_khat() calculates this for a sample of draws. Calculate the Pareto-k for samples of 400 draws from the gamma(3, 3) and the Cauchy(0, 1) distributions.\n            \n            1.10 Which of these is true:\n            \n        \n        MCSE can be calculated for any estimate, including quantiles and probability and can be used to guide how many digits to report for a given estimate. Suppose you calculate the following summary of a parameter:\n        mean = 0.483834 (MCSE = 0.003)\n        5% quantile = 0.234536 (MCSE = 0.01)\n        95% quantile = 1.34823 (MCSE = 0.2)\n        \n    \n    \n    1.11 Based on recommendations from the lecture how should you report for the mean?\n    \n\n    1.12 Based on recommendations from the lecture how should you report the 5% quantile?\n\n\n\n\n    1.13 Based on recommendations from the lecture how should you report the 95% quantile?\n\n\n    \n    \n        \n            \n                \n                \n            \n        \n        \n            \n            In this exercise, you will use a dose-response relation model that is used in BDA3 Section 3.7 and in the chapter reading notes.The likelihood is the same as in the book, but instead of uniform priors, we will use a bivariate normal distribution as the joint prior distribution of the parameters \\(\\alpha\\) and \\(\\beta\\).\n            In the prior distribution for \\((\\alpha,\\beta)\\), the marginal distributions are \\(\\alpha \\sim N(0,2^2)\\) and \\(\\beta \\sim N(10,10^2)\\), and the correlation between them is \\(\\mathrm{corr}(\\alpha, \\beta)=0.6\\).\n\n            2.1 The mean of the prior distribution for \\((\\alpha, \\beta)\\) is: \n            2.2 The covariance of the prior distribution (two by two matrix) is: \n            \n        \n        \n            \n        \n        For this section, you will estimate the posterior mean by weighting prior draws with the appropriate importance weights. To do this you will need to calculate the unnormalized importance ratios \\(\\tilde{w}\\) (also known as weights) when the importance sampling target distribution \\(q(\\theta)\\) is the posterior distribution, and the proposal distribution \\(g(\\theta)\\) is the prior distribution as defined above. You will then need to use this function to calculate the importance sampling estimate of the posterior mean, given draws from the prior.\n        \n        \n            3.1 What is the general formula for the importance ratios (also called importance weights)?\n            \n            \n            \n            3.2 What is the correct formula for the importance ratios in the case where the prior is the proposal and the posterior is the target?\n            \n                \n                \n            \n            3.3 What is the correct formula for the unnormalized importance ratios in the case where the prior is the proposal and the posterior is the target?\n            \n                \n                \n                    \n                \n            \n        \n        3.4 The unnormalized log importance ratios in the case where the prior is the proposal and the posterior is the target simplify to:\n        \n        \n        \n        3.5 Why is it better to compute the importance rations on the log scale?\n        \n        \n        \n        The function `bioassaylp` from the aaltobda package calculates the unnormalized log posterior density assuming a uniform prior.\n        \n        3.6 What is the relationship between the posterior, likelihood and prior when the prior is uniform? \n        \n        \n            3.7 What is the correct formula or formulas for the self-normalized importance sampling estimate of the mean? \\(w\\) are the unnormalized importance weights, and \\(\\tilde{w}\\) are the self-normalized weights.\n            \n            \n            \n            Use the function rmvnorm to draw 4000 draws from the prior specified in question 2, calculate the importance weights and then the importance sampling estimate of the posterior mean.\n            \n            3.8 The importance sampling estimate of the posterior mean is: \n            \n            alpha: , beta: .\n            \n            3.9 What is the equation for the generic effective sample size (ESS) estimate for importance sampling?\n            \n            \n                \n                3.10 Importance sampling ESS: \n                \n                3.11 What is the MCSE of the estimates? Make sure to use the ESS in the denominator instead of the sample size.\n            \n            \n            \n                alpha: , beta: .\n                \n                3.12 What is the Pareto-k diagnostic of the importance ratios (enter value with one decimal)? .\n                \n                3.13 Based on the value, should you trust the importance sampling estimate of the mean?\n            \n            \n            \n                \n                    \n                \n            \n            \n                \n                    You are given 4000 independent draws from the posterior distributionof the model in the dataset `bioassay_posterior` in the `aaltobda` package.\n                    4.1 The posterior can be summarised by the means and 90% posterior interval.What is the mean, 5% and 95% quantiles of the posterior draws for the parameters?mean of alpha: , 5% quantile of alpha: , 95% quantile of alpha: \n                    mean of beta: , 5% quantile of beta: , 95% quantile of beta: \n                \n                \n                4.2 What is the MCSE for the mean and quantiles (remember that they are independent draws)?For alpha: MCSE for mean: , MCSE for 5% quantile: , MCSE for 95% quantile: \n                \n                For beta: MCSE for mean: , MCSE for 5% quantile: , MCSE for 95% quantile: \n            \n            \n            Compare these posterior summaries to the importance sampling estimate.\n            \n            4.3 How does the importance sampling estimate of the posterior mean compare to the estimate from independent posterior draws?\n            \n            \n            Remember that the LD50 (median lethal dose) is equal to \\( exp( -\\alpha / \\beta) \\). \n            Calculate the posterior probability that the LD50 is less than 0.85ml/g. Also calculate the MCSE for this probability.\n            \n            4.4 Pr(LD50 &lt; 0.85 ml/g) = , MCSE =",
    "crumbs": [
      "Assignments",
      "Assignment 4"
    ]
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "The exercises here refer to the lecture 2/BDA chapters 1-2 content. All questions check your understanding of a simple posterior analysis using a binomial model for the observations and a beta prior.\nThe exercises constitute 96% of the Quiz 2 grade.\nWe prepared a quarto notebook specific to this assignment to help you get started. You still need to fill in your answers on Mycourses! You can inspect this and future templates\n\nas a qmd file,\nas a rendered html file\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\nFor convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\nAlgae\n    status is monitored in 274 sites at Finnish lakes and rivers. The\n    observations for the 2008 algae status at each site are presented in the\n    dataset algae in the aaltobda package ('0': no algae, '1': algae\n    present).\nLet \\( \\theta \\) be the probability of a monitoring site having\n    detectable blue-green algae levels, \\( y \\) the number of observed sites with algae detected, and \\( n \\) be total number sites surveyed.\n    Use a binomial model for the observations and a \\( \\text{Beta}(2,10) \\) prior for binomial model parameter \\( \\theta \\) to formulate a Bayesian model.\n    Here we will not test you on the individual mathematical operations needed in order to derive the posterior distribution for \\( \\theta \\) as it has already been done in the book (and lecture) so make sure to look that up.\nYour task is to perform Bayesian\n    inference for a binomial model and fill in the quiz below based on it. \nFor questions with checkboxes, more than one answer may be\n    correct.\n\nThe algae dataset contains the results of 274 measurements from Finnish lakes, with the following results:\n\n    No Algae: 230 sites\n    Algae: 44 sites\n\nOur goal for the following set of questions is to find the formulation of the posterior using a binomial likeliood and a beta prior on the unknown probability parameter \\( \\theta \\)\n\n\n    1.1 The prior \\(p(\\theta)\\) can be expressed as: \n\n\n    1.2 The likelihood \\( p(y = 44 | \\theta, n = 274) \\) as a function of \\( \\theta \\) can be expressed as: \n\n\n\n\n    1.3 The resulting posterior \\( p(\\theta|y = 44, n = 274) \\) can be expressed as : \n\n\n\n\nThe posterior distribution \\( p(\\theta|y) \\) is analytically available as \\( \\text{Beta}(\\alpha, \\beta) \\), so we can use the properties of that distribution to summarise what we know about \\( \\theta \\).  And in particular, we can make probability statements about ranges of values for \\( \\theta \\). Let's however start with the average value of \\( \\theta \\) you expect after having conditioned on the data. \n\n    2.1 Which of the following is the correct formula for the mean (\\( E[\\cdot] \\)) of a \\( \\text{Beta}(\\alpha, \\beta) \\) distribution: \n\n\n    2.2 Using your answer above, what is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n\n\nPosterior intervals are sometimes called credible intervals and are different from confidence intervals (for more on this, see here). These are computed using the quantile function of the posterior distribution. As the quantiles of a \\( \\text{Beta}(\\alpha, \\beta) \\) distribution do not have a simple analytical form like the expectation, you can use R to compute the posterior intervals.\n\n\n    2.3 What R function would you use here to compute posterior intervals? \n\nUsing your answer above, calculate (report the results in decimals with two decimal digits): \n\n\n\n    2.4 90% posterior interval lower bound: \n\n\n    2.5 90% posterior interval upper bound: \n\nWe are interested in using our posterior distribution to estimate the probability that the proportion of detected algae samples (\\( \\theta \\)) is smaller than the historical detection rate \\( \\theta_0 = 0.2 \\), i.e. \\( p(\\theta \\leq \\theta_0 \\mid y) \\). \n\n    3.1 Which of the following approaches would we take? \n\n\n    3.2 What statistical function computes this probability for us? \n\n\n    3.3 Which R function does this for you? \n\n\n    3.4 Using your answers above, report this probability (report the result in decimals with two decimal digits): \n\n\n\nRedo the analysis using a uniform prior, \\( \\text{Beta}( 1,1 \\)). \n\n    4.1 What is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n    4.2 90% posterior interval lower bound. Report the result in decimals with two decimal digits. \n    4.3 90% posterior interval upper bound. Report the result in decimals with two decimal digits. \n    4.4 Probability \\( p(\\theta \\leq \\theta_0 \\mid y) \\). Report the result in decimals with two decimal digits. \n\nRedo the analysis using as prior \\( \\text{Beta}(0.5,0.5) \\).\n\n\n    4.5 What is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n    4.6 90% posterior interval lower bound. Report the result in decimals with two decimal digits. \n    4.7 90% posterior interval upper bound. Report the result in decimals with two decimal digits. \n    4.8 Probability \\( p(\\theta \\leq \\theta_0 \\mid y) \\). Report the result in decimals with two decimal digits. \n\n\nRedo the analysis using as prior \\( \\text{Beta}(100,2) \\).\n\n\n    4.9 What is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n    4.10 90% posterior interval lower bound. Report the result in decimals with two decimal digits. \n    4.11 90% posterior interval upper bound. Report the result in decimals with two decimal digits. \n    4.12 Probability \\( p(\\theta \\leq \\theta_0 \\mid y) \\). Report the result in decimals with two decimal digits. \n\n4.13 Based on testing different priors, would you consider the posterior results believe and defensible (w.r.t. to this data set)? In order to help your reasoning you can plot the prior and posteriors used with the code template for Assignment 2.",
    "crumbs": [
      "Assignments",
      "Assignment 2"
    ]
  },
  {
    "objectID": "assignment2.html#assignment-questions",
    "href": "assignment2.html#assignment-questions",
    "title": "Assignment 2",
    "section": "",
    "text": "For convenience the assignment questions are copied below. Answer the questions in MyCourses.\n\n\nAlgae\n    status is monitored in 274 sites at Finnish lakes and rivers. The\n    observations for the 2008 algae status at each site are presented in the\n    dataset algae in the aaltobda package ('0': no algae, '1': algae\n    present).\nLet \\( \\theta \\) be the probability of a monitoring site having\n    detectable blue-green algae levels, \\( y \\) the number of observed sites with algae detected, and \\( n \\) be total number sites surveyed.\n    Use a binomial model for the observations and a \\( \\text{Beta}(2,10) \\) prior for binomial model parameter \\( \\theta \\) to formulate a Bayesian model.\n    Here we will not test you on the individual mathematical operations needed in order to derive the posterior distribution for \\( \\theta \\) as it has already been done in the book (and lecture) so make sure to look that up.\nYour task is to perform Bayesian\n    inference for a binomial model and fill in the quiz below based on it. \nFor questions with checkboxes, more than one answer may be\n    correct.\n\nThe algae dataset contains the results of 274 measurements from Finnish lakes, with the following results:\n\n    No Algae: 230 sites\n    Algae: 44 sites\n\nOur goal for the following set of questions is to find the formulation of the posterior using a binomial likeliood and a beta prior on the unknown probability parameter \\( \\theta \\)\n\n\n    1.1 The prior \\(p(\\theta)\\) can be expressed as: \n\n\n    1.2 The likelihood \\( p(y = 44 | \\theta, n = 274) \\) as a function of \\( \\theta \\) can be expressed as: \n\n\n\n\n    1.3 The resulting posterior \\( p(\\theta|y = 44, n = 274) \\) can be expressed as : \n\n\n\n\nThe posterior distribution \\( p(\\theta|y) \\) is analytically available as \\( \\text{Beta}(\\alpha, \\beta) \\), so we can use the properties of that distribution to summarise what we know about \\( \\theta \\).  And in particular, we can make probability statements about ranges of values for \\( \\theta \\). Let's however start with the average value of \\( \\theta \\) you expect after having conditioned on the data. \n\n    2.1 Which of the following is the correct formula for the mean (\\( E[\\cdot] \\)) of a \\( \\text{Beta}(\\alpha, \\beta) \\) distribution: \n\n\n    2.2 Using your answer above, what is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n\n\nPosterior intervals are sometimes called credible intervals and are different from confidence intervals (for more on this, see here). These are computed using the quantile function of the posterior distribution. As the quantiles of a \\( \\text{Beta}(\\alpha, \\beta) \\) distribution do not have a simple analytical form like the expectation, you can use R to compute the posterior intervals.\n\n\n    2.3 What R function would you use here to compute posterior intervals? \n\nUsing your answer above, calculate (report the results in decimals with two decimal digits): \n\n\n\n    2.4 90% posterior interval lower bound: \n\n\n    2.5 90% posterior interval upper bound: \n\nWe are interested in using our posterior distribution to estimate the probability that the proportion of detected algae samples (\\( \\theta \\)) is smaller than the historical detection rate \\( \\theta_0 = 0.2 \\), i.e. \\( p(\\theta \\leq \\theta_0 \\mid y) \\). \n\n    3.1 Which of the following approaches would we take? \n\n\n    3.2 What statistical function computes this probability for us? \n\n\n    3.3 Which R function does this for you? \n\n\n    3.4 Using your answers above, report this probability (report the result in decimals with two decimal digits): \n\n\n\nRedo the analysis using a uniform prior, \\( \\text{Beta}( 1,1 \\)). \n\n    4.1 What is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n    4.2 90% posterior interval lower bound. Report the result in decimals with two decimal digits. \n    4.3 90% posterior interval upper bound. Report the result in decimals with two decimal digits. \n    4.4 Probability \\( p(\\theta \\leq \\theta_0 \\mid y) \\). Report the result in decimals with two decimal digits. \n\nRedo the analysis using as prior \\( \\text{Beta}(0.5,0.5) \\).\n\n\n    4.5 What is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n    4.6 90% posterior interval lower bound. Report the result in decimals with two decimal digits. \n    4.7 90% posterior interval upper bound. Report the result in decimals with two decimal digits. \n    4.8 Probability \\( p(\\theta \\leq \\theta_0 \\mid y) \\). Report the result in decimals with two decimal digits. \n\n\nRedo the analysis using as prior \\( \\text{Beta}(100,2) \\).\n\n\n    4.9 What is the mean of our posterior (i.e.,  \\( E(\\theta|y) \\))? Report the result in decimals with two decimal digits. \n    4.10 90% posterior interval lower bound. Report the result in decimals with two decimal digits. \n    4.11 90% posterior interval upper bound. Report the result in decimals with two decimal digits. \n    4.12 Probability \\( p(\\theta \\leq \\theta_0 \\mid y) \\). Report the result in decimals with two decimal digits. \n\n4.13 Based on testing different priors, would you consider the posterior results believe and defensible (w.r.t. to this data set)? In order to help your reasoning you can plot the prior and posteriors used with the code template for Assignment 2.",
    "crumbs": [
      "Assignments",
      "Assignment 2"
    ]
  },
  {
    "objectID": "template5.html",
    "href": "template5.html",
    "title": "Notebook for Assignment 5",
    "section": "",
    "text": "1 General information\nThis assignment is related to Lecture 5 and Chapters 10 and 11.\nIf you are not using JupyterHub (which has all the needed packages pre-installed), and want to make the assignment on your own computer, you may use a docker container that includes all the necessary software packages, too.\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 10.\nThe reading instructions for BDA3 Chapter 11.\n\n\n\n\n\n\n\n\nGeneral Instructions for Answering the Assignment Questions\n\n\n\n\n\n\nQuestions below are exact copies of the text found in the MyCourses quiz and should serve as a notebook where you can store notes and code.\nWe recommend opening these notebooks in the Aalto JupyterHub, see how to use R and RStudio remotely.\nFor inspiration for code, have a look at the BDA R Demos and the specific Assignment code notebooks\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in MyCourses.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/tests/assignment5.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nAssignment set:\nassignment5: Bayesian Data Analysis: Assignment 5\nThe assignment contain the following task:\n- density_ratio\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\nThe following installs and loads the posterior package which imports the rhat_basic() function:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggplot2 package and the bayesplot package\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nif(!require(bayesplot)){\n    install.packages(\"bayesplot\")\n    library(bayesplot)\n}\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.13.0\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:posterior':\n\n    rhat\n\n\n\n\n\n\n\n2 Generalized linear model: Bioassay model with Metropolis algorithm\nMetropolis algorithm: Replicate the computations for the bioassay example of BDA3 Section 3.7 using the Metropolis algorithm. The Metropolis algorithm is described in BDA3 Chapter 11.2. More information on the bioassay data can be found in Section 3.7 in BDA3, and in Chapter 3 notes.\nBelow you are given a code that implements Metropolis algorithm. It contains two functions - density ratio that computes ratio of joint distributions using log densities and metropolis_bioassay that performs sampling. Reasons behind using log densities are explained on BDA3 page 261 and Lecture video 4.1. Remember that \\(p_1/p_0=\\exp(\\log(p_1)-\\log(p_0))\\). We use the Gaussian prior as in Assignment 4, that is \\[\n\\begin{aligned}\n    \\begin{bmatrix}\n    \\alpha \\\\ \\beta\n    \\end{bmatrix}\n    \\sim\n    \\text{N} \\left( \\mu_0,  \\Sigma_0 \\right), \\qquad\n    \\text{where} \\quad\n     \\mu_0 = \\begin{bmatrix} 0 \\\\ 10 \\end{bmatrix} \\quad \\text{and} \\quad\n     \\Sigma_0 = \\begin{bmatrix} 2^2 & 12 \\\\ 12 & 10^2 \\end{bmatrix}.\n\\end{aligned}\\]\nHowever, this code contains 3 errors. The lines with errors are marked as:\n\n### error x\n\n### error x\n\nYour task is to find these errors, correct them and answer corresponding questions in MyCourses. Note that bioassaylp() from aaltobda package evaluates the log-likelihood for given \\(\\alpha\\) and \\(\\beta\\). As for proposal distribution we used simple normal distributions \\(\\alpha^* \\sim N(\\alpha_{t-1}, \\sigma = \\alpha_\\sigma)\\) and \\(\\beta^* \\sim N(\\beta_{t-1}, \\sigma = \\beta_\\sigma)\\). Efficient proposals are discussed in BDA3 p. 295–297 (not part of the course). In real-life a pre-run could be made with an automatic adaptive control to adapt the proposal distribution.\n\ndata(\"bioassay\")\ndensity_ratio &lt;- function(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n){\n        prior_mean = c(0, 10)\n    prior_sigma = cbind(c(4, 12), c(12, 100))\n    ### error 1\n        bioassaylp(alpha_propose, beta_propose, x, y, n)\n        - bioassaylp(alpha_previous, beta_previous, x, y, n)\n        + dmvnorm(c(alpha_propose, beta_propose), prior_mean, prior_sigma, TRUE)\n        - dmvnorm(c(alpha_previous, beta_previous), prior_mean, prior_sigma, TRUE)\n    ### error 1\n}\n\nmetropolis_bioassay &lt;- function(alpha_initial, beta_initial, alpha_sigma, beta_sigma, no_draws, warmup_len, x, y, n, chain_number){\n    data.frame(\n        alpha=c(alpha_initial, alpha_initial+alpha_sigma, alpha_initial-alpha_sigma),\n        beta=c(beta_initial, beta_initial+beta_sigma, beta_initial-beta_sigma)\n    )\n    alpha_previous = alpha_initial\n    beta_previous = beta_initial\n    alpha_rv = c()\n    beta_rv = c()\n    for(draw in 1:no_draws){\n        alpha_propose = rnorm(1, alpha_previous, alpha_sigma)\n        beta_propose = rnorm(1, beta_previous, beta_sigma)\n        ### error 2\n        if(runif(1) &gt; density_ratio(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n))\n        ### error 2\n          {\n            alpha_previous = alpha_propose\n            beta_previous = beta_propose\n          }\n      ### error 3\n        alpha_rv = c(alpha_rv, alpha_propose)\n        beta_rv = c(beta_rv, beta_propose)\n      ### error 3\n    }\n    data.frame(alpha=tail(alpha_rv,warmup_len), beta=tail(beta_rv, warmup_len), Chain=rep(chain_number, each=no_draws - warmup_len))\n}\n\n\nset.seed(4911)\n\ndf_chain1 = metropolis_bioassay(0, 0, 1, 1, 3000, 1000, bioassay$x, bioassay$y, bioassay$n, 1)\ndf_chain2 = metropolis_bioassay(1, 1, 1, 1, 3000, 1000, bioassay$x, bioassay$y, bioassay$n, 2)\ndf_chain3 = metropolis_bioassay(1, 5, 1, 1, 3000, 1000, bioassay$x, bioassay$y, bioassay$n, 3)\ndf_chain4 = metropolis_bioassay(5, 3, 1, 1, 3000, 1000, bioassay$x, bioassay$y, bioassay$n, 4)\n\ndf_combined_samples &lt;- rbind(df_chain1, df_chain2, df_chain3, df_chain4)\n\nVisualize trace plots with the code below. Have a look at bayesplot trace plot examples and tune your plot if wanted.\n\n# Useful functions: mcmc_trace (from bayesplot)\nmcmc_trace(df_combined_samples, pars=c(\"alpha\", \"beta\")) + scale_colour_manual(values=c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\"))\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\nAfter looking at trace plots, compute Rhat values for both alpha and beta, along with the ess_mean as well as ess_quantile for the 25th quantile. If you’re unsure about the below, this demo provides more details on how to use the posterior and bayesplot package.\n\n# To compute this, first convert to a draws_df object\nnames(df_combined_samples)[names(df_combined_samples) == 'Chain'] &lt;- '.chain'\ndraws &lt;- as_draws_df(df_combined_samples)\n\n# You can get what you need from this summary\nsummarise_draws(draws, Rhat=rhat_basic, ESS= ess_mean, ~ess_quantile(.x, probs = 0.25))\n\n# A tibble: 2 × 4\n  variable  Rhat   ESS ess_q25\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 alpha     2.29  4.99   18.9 \n2 beta      2.28  5.01    9.69\n\n\nPlot the draws for \\(\\alpha\\) and \\(\\beta\\) (scatter plot). You can compare the results to BDA3 Figure 3.3b to verify that your code gives sensible results. Notice though that the results in Figure 3.3b are generated from the posterior with a uniform prior, so even when if your algorithm works perfectly, the results will look slightly different (although fairly similar).\n\n# Useful functions: mcmc_scatter (from bayesplot)",
    "crumbs": [
      "Templates",
      "Notebook for Assignment 5"
    ]
  }
]