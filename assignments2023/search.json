[
  {
    "objectID": "template5.html",
    "href": "template5.html",
    "title": "Assignment 5, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 5 and Chapters 10 and 11.\nThe maximum amount of points from this assignment is 6.\nWe have prepared a *quarto template specific to this assignment (html, qmd, pdf)** to help you get started.\nIf you are not using JupyterHub (which has all the needed packages pre-installed), and want to make the assignment on your own computer, you may use a docker container that includes all the necessary software packages, too.\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 10.\nThe reading instructions for BDA3 Chapter 11.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 5. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment5.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\nThe following installs and loads the posterior package which imports the rhat_basic() function:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggplot2 package and the bayesplot package\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nif(!require(bayesplot)){\n    install.packages(\"bayesplot\")\n    library(bayesplot)\n}\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:posterior':\n\n    rhat\n\n\n\n\n\n\n\n2 Generalized linear model: Bioassay model with Metropolis algorithm\nMetropolis algorithm: Replicate the computations for the bioassay example of BDA3 Section 3.7 using the Metropolis algorithm. The Metropolis algorithm is described in BDA3 Chapter 11.2. More information on the bioassay data can be found in Section 3.7 in BDA3, and in Chapter 3 notes.\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nImplement the Metropolis algorithm as an R function for the bioassay data. Use the Gaussian prior as in Assignment 4, that is \\[\n\\begin{aligned}\n    \\begin{bmatrix}\n    \\alpha \\\\ \\beta\n    \\end{bmatrix}\n    \\sim\n    \\text{N} \\left( \\mu_0,  \\Sigma_0 \\right), \\qquad\n    \\text{where} \\quad\n     \\mu_0 = \\begin{bmatrix} 0 \\\\ 10 \\end{bmatrix} \\quad \\text{and} \\quad\n     \\Sigma_0 = \\begin{bmatrix} 2^2 & 12 \\\\ 12 & 10^2 \\end{bmatrix}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCompute with log-densities. Reasons are explained on BDA3 page 261 and Lecture video 4.1. Remember that \\(p_1/p_0=\\exp(\\log(p_1)-\\log(p_0))\\). For your convenience we have provided functions that will evaluate the log-likelihood for given \\(\\alpha\\) and \\(\\beta\\) (see bioassaylp() in the aaltobda package). Notice that you still need to add the prior yourself and remember the unnormalized log posterior is simply the sum of log-likelihood and log-prior. For evaluating the log of the Gaussian prior you can use the function dmvnorm from package aaltobda.\nUse a simple (normal) proposal distribution. Example proposals are \\(\\alpha^* \\sim N(\\alpha_{t-1}, \\sigma = 1)\\) and \\(\\beta^* \\sim N(\\beta_{t-1}, \\sigma = 5)\\). There is no need to try to find optimal proposal but test some different values for the jump scale (\\(\\sigma\\)). Remember to report the one you used. Efficient proposals are discussed in BDA3 p. 295–297 (not part of the course). In real-life a pre-run could be made with an automatic adaptive control to adapt the proposal distribution.\n\n\n\nWrite your answers/code here!\n\n# Useful functions: runif, rnorm\n# bioassaylp, dmvnorm (from aaltobda)\n\ndata(\"bioassay\")\n# Start by implementing a function called `density_ratio` to\n# compute the density ratio function, $r$ in Eq. (11.1) in BDA3:\ndensity_ratio &lt;- function(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n){\n    # Do computation here, and return as below.\n    # Below are the correct return values for two different calls of this function:\n\n    # alpha_propose = 1.89, alpha_previous = 0.374,\n    # beta_propose = 24.76, beta_previous = 20.04,\n    # x = bioassay$x, y = bioassay$y, n = bioassay$n\n    1.305179\n\n    # alpha_propose = 0.374, alpha_previous = 1.89,\n    # beta_propose = 20.04, beta_previous = 24.76,\n    # x = bioassay$x, y = bioassay$y, n = bioassay$n\n    0.7661784\n    ### {.content-hidden when-profile=\"public\"}\n    prior_mean = c(0, 10)\n    prior_sigma = cbind(c(4, 12), c(12, 100))\n    exp(\n        bioassaylp(alpha_propose, beta_propose, x, y, n)\n        - bioassaylp(alpha_previous, beta_previous, x, y, n)\n        + dmvnorm(c(alpha_propose, beta_propose), prior_mean, prior_sigma, TRUE)\n        - dmvnorm(c(alpha_previous, beta_previous), prior_mean, prior_sigma, TRUE)\n    )\n    ###\n}\n# Then implement a function called `metropolis_bioassay()` which\n# implements the Metropolis algorithm using the `density_ratio()`:\nmetropolis_bioassay &lt;- function(alpha_initial, beta_initial, alpha_sigma, beta_sigma, no_draws, x, y, n){\n    # Do computation here, and return as below.\n    # Below are \"wrong\" values (unlikely to actually occur)\n    # in the \"correct\" format (such that they work with the plotting functions further down).\n    data.frame(\n        alpha=c(alpha_initial, alpha_initial+alpha_sigma, alpha_initial-alpha_sigma),\n        beta=c(beta_initial, beta_initial+beta_sigma, beta_initial-beta_sigma)\n    )\n    ### {.content-hidden when-profile=\"public\"}\n    alpha_previous = alpha_initial\n    beta_previous = beta_initial\n    alpha_rv = c()\n    beta_rv = c()\n    for(draw in 1:no_draws){\n        alpha_propose = rnorm(1, alpha_previous, alpha_sigma)\n        beta_propose = rnorm(1, beta_previous, beta_sigma)\n        if(runif(1) &lt; density_ratio(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n)){\n            alpha_previous = alpha_propose\n            beta_previous = beta_propose\n        }\n        alpha_rv = c(alpha_rv, alpha_previous)\n        beta_rv = c(beta_rv, beta_previous)\n    }\n    data.frame(alpha=alpha_rv, beta=beta_rv)\n    ###\n}\ndf = metropolis_bioassay(0, 0, 1, 1, 1000, bioassay$x, bioassay$y, bioassay$n)\n\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nInclude in the report the following:\n\nDescribe in your own words in one paragraph the basic idea of the Metropolis algorithm (see BDA3 Section 11.2, and Lecture video 5.1).\nThe proposal distribution (related to jumping rule) you used. Describe briefly in words how you chose the final proposal distribution you used for the reported results.\nThe initial points of your Metropolis chains (or the explicit mechanism for generating them).\nReport the chain length or the number of iterations for each chain. Run the simulations long enough for approximate convergence (see BDA Section 11.4, and Lecture 5.2).\nReport the warm-up length (see BDA Section 11.4, and Lecture 5.2).\nThe number of Metropolis chains used. It is important that multiple Metropolis chains are run for evaluating convergence (see BDA Section 11.4, and Lecture 5.2).\nPlot all chains for \\(\\alpha\\) in a single line-plot. Overlapping the chains in this way helps in visually assessing whether chains have converged or not.\nDo the same for \\(\\beta\\).\n\n\n\nWrite your answers/code here!\nHave a look at bayesplot trace plot examples and tune your plot if wanted/needed. Don’t forget to include a title/caption/description.\nThe below example plot only includes a single chain, but your report should include a plot with multiple chains overlayed!\n\n# Useful functions: mcmc_trace (from bayesplot)\nmcmc_trace(df, pars=c(\"alpha\", \"beta\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.c)\n\n\n\nIn complex scenarios, visual assessment is not sufficient and \\(\\widehat{R}\\) is a more robust indicator of convergence of the Markov chains. Use \\(\\widehat{R}\\) for convergence analysis. You can either use Eq. (11.4) in BDA3 or the more recent version described in the article Rank-normalization, folding, and localization: An improved \\(\\widehat{R}\\) for assessing convergence of MCMC. You should specify which \\(\\widehat{R}\\) you used. In R the best choice is to use function rhat_basic() from the package posterior (this function implements the version described in the above mentioned article). Remember to remove the warm-up sample before computing \\(\\widehat{R}\\). Report the \\(\\widehat{R}\\) values for \\(\\alpha\\) and \\(\\beta\\) separately. Report the values for the proposal distribution you finally used.\n\nDescribe briefly in your own words the basic idea of \\(\\widehat{R}\\) and how to to interpret the obtained \\(\\widehat{R}\\) values.\nTell whether you obtained good \\(\\widehat{R}\\) with first try, or whether you needed to run more iterations or how did you modify the proposal distribution.\n\n\n\nWrite your answers/code here!\n\n# Useful functions: rhat_basic (from posterior)\n\n\n\n\n\n\n\nSubtask 2.d)\n\n\n\nPlot the draws for \\(\\alpha\\) and \\(\\beta\\) (scatter plot) and include this plot in your report. You can compare the results to BDA3 Figure 3.3b to verify that your code gives sensible results. Notice though that the results in Figure 3.3b are generated from the posterior with a uniform prior, so even when if your algorithm works perfectly, the results will look slightly different (although fairly similar).\n\n\nWrite your answers/code here!\nHave a look at bayesplot scatter plot examples and tune your plot if wanted/needed. Don’t forget to include a title/caption/description.\n\n# Useful functions: mcmc_scatter (from bayesplot)\nmcmc_scatter(df, pars=c(\"alpha\", \"beta\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the implementation of density_ratio function included ?\n\nNo\nYes\n\nIs the implementation of metropolis_bioassay function included ?\n\nNo\nYes\n\n2 a) Is the brief description of Metropolis-Hastings algorithm included (and it’s not complete nonsense)? Provide also a brief comment on how clear you think that description is (and potentially mention errors if you see them).\n\nNo\nYes\n\n2 b) Is the proposal/jumping distribution reported?\n\nNo\nYes\n\n2 c) Are the starting points or the mechanism how they are generated reported?\n\nNo\nYes\n\n2 d) Is the number of draws per chain reported?\n\nNo\nYes\n\n2 e) Is the warm-up length reported?\n\nNo\nYes\n\n2 f) Is the number of chains reported?\n\nNo\nYes\n\n2 g) and 2 h) Are line plots of the chains included? (Separate plots for alpha and beta)\n\nNo plots are included\nYes, but both plots are in a single figure, or the plots are scatter plots (scatter plots aren’t useful for visual convergence evaluation).\nYes, but only a plot for alpha or beta is included.\nYes, separate line plots for both alpha and beta are included.\n\nIs there a discussion on the convergence of the chains?\n\nNo discussion on convergence.\nYes, but the discussion is not convincing.\nYes, discussed in the report.\n\nIs it mentioned which implementation of Rhat is used? Two possible ways to compute R-hat would be:\n\n\n\n\nIt is OK as long as it is mentioned (or evident from the code) which of the above is used.\n\nNo\nYes\n\nIs the brief description of Rhat included (and it’s not complete nonsense)? Provide also a brief comment on how clear you think that description is (and potentially mention errors if you see them).\n\nNo\nYes\n\nAre the Rhat-values for alpha and beta reported?\n\nNo\nYes, but incorrectly computed\nYes, but computed separately for each chain\nYes, but only for alpha or beta\nYes, single values both for alpha and beta\n\nIs the interpretation of R-hat values correct ()?\n\nNo interpretation or discussion about the R-hat values, or conclusions clearly wrong\nInterpretation somewhat correct\nInterpretation correct\n\nDoes the report contain a scatter plot about the draws? Do the results look reasonable, that is, roughly like in the Figure below ?\n\nNo plot included\nPlot included, but the results do not look like in the figure above\nPlot included, and the results look roughly like in the figure above\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n3 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Templates",
      "Assignment 5, 2023"
    ]
  },
  {
    "objectID": "assignment8.html",
    "href": "assignment8.html",
    "title": "Assignment 8, 2023",
    "section": "",
    "text": "This is for BDA 2023\nThe maximum amount of points from this assignment is 6.\nWe have prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nWe recommend Aalto students use jupyter.cs.aalto.fi, for all others we also provide a docker container.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 6 (posterior predictive checking).\nThe reading instructions for BDA3 Chapter 7 (predictive performance).\nThe ’loo‘ package vignette on the basics of LOO shows an example of how to modify Stan code and use the package with Stan models.\nAlso read about PSIS-LOO in the PSIS-LOO paper.\nCV-FAQ includes a lot of informative answers to frequent questions and misconceptions.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\nInstalling and using CmdStanR:\nSee the Stan demos on how to use Stan in R (or Python). Aalto JupyterHub has working R and CmdStanR/RStan environment and is probably the easiest way to use Stan. * To use CmdStanR in Aalto JupyterHub: library(cmdstanr) set_cmdstan_path('/coursedata/cmdstan')\nThe Aalto Ubuntu desktops also have the necessary libraries installed.\nTo install Stan on your laptop, run ‘install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))’ in R. If you encounter problems, see additional answers in FAQ. For Aalto students, if you don’t succeed in short amount of time, it is probably easier to use Aalto JupyterHub.\nIf you use Aalto JupyterHub, all necessary packages have been pre-installed. In your laptop, install package cmdstanr. Installation instructions on Linux, Mac and Windows can be found at https://mc-stan.org/cmdstanr/. Additional useful packages are loo, bayesplot and posterior (but you don’t need these in this assignment). For Python users, PyStan, CmdStanPy, and ArviZ packages are useful.\nStan manual can be found at https://mc-stan.org/users/documentation/. From this website, you can also find a lot of other useful material about Stan.\nIf you edit files ending .stan in RStudio, you can click “Check” in the editor toolbar to make syntax check. This can significantly speed-up writing a working Stan model.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\nThis is the template for assignment 8. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following loads several needed packages:\n\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /u/77/ave/unix/.cmdstan/cmdstan-2.35.0-rc3\n\n\n- CmdStan version: 2.35.0\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(ggdist) # for stat_dotsinterval\nlibrary(posterior)\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\nlibrary(brms)\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.21.6). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following objects are masked from 'package:ggdist':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\n# Globally specfiy cmdstan backend for brms\noptions(brms.backend=\"cmdstanr\")\n# Tell brms to cache results if possible\noptions(brms.file_refit=\"on_change\")\n\n# Set more readable themes with bigger font for plotting packages\nggplot2::theme_set(theme_minimal(base_size = 14))\nbayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment8.html#exploratory-data-analysis",
    "href": "assignment8.html#exploratory-data-analysis",
    "title": "Assignment 8, 2023",
    "section": "2.1 Exploratory data analysis",
    "text": "2.1 Exploratory data analysis\nIn the first part of this assignment, you will explore the dataset ChickWeight. In particular, you will see what information is recorded in the dataset, and how you can use visualisation to learn more about the dataset. More information can be found on the corresponding page of the R documentation.\n\nhead(ChickWeight, 10)\n\nGrouped Data: weight ~ Time | Chick\n   weight Time Chick Diet\n1      42    0     1    1\n2      51    2     1    1\n3      59    4     1    1\n4      64    6     1    1\n5      76    8     1    1\n6      93   10     1    1\n7     106   12     1    1\n8     125   14     1    1\n9     149   16     1    1\n10    171   18     1    1\n\n\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nCreate a histogram to explore the range of chicken weights. Describe what you see in the plot. What is the qualitative range of the data?\n\n\n\n# Useful functions: ggplot, aes(x=...), geom_histogram\n\n### {.content-hidden when-profile=\"public\"}\nggplot(data = ChickWeight, aes(x=ChickWeight$weight)) +\n  geom_histogram()\n\nWarning: Use of `ChickWeight$weight` is discouraged.\nℹ Use `weight` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nHas it been stated that the data takes on only values which are ?\n\n\n\n\n\n\n\n\n\nSubtask 2.b\n\n\n\nPlot the weight of each chicken over time in a line plot. Add colours based on the diet. Describe what you see in the plot.\n\n\n\n# Useful functions: ggplot, aes(x=...,y=...,group=...,color=...), geom_line\n\n### {.content-hidden when-profile=\"public\"}\nggplot(data = ChickWeight, aes(x=Time, y=weight, group = Chick, color=Diet)) +\n  geom_line()\n\n\n\n\n\n\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment8.html#linear-regression",
    "href": "assignment8.html#linear-regression",
    "title": "Assignment 8, 2023",
    "section": "2.2 Linear regression",
    "text": "2.2 Linear regression\nIn this section, you will build a model that predicts the weight of a chicken over time and depending on the diet. After sampling from the posteriors, you will use posterior predictive checks to see how well the predictions match the observations. Then you will adjust the model by adding more complexity, and check again.\n\n\n\n\n\n\nSubtask 2.c\n\n\n\nUsing brms, implement a pooled linear regression with a normal model and weight as the predicted variable using Diet and Time as predictors. Try to use weakly informative priors.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFor the prior on Time, consider how much the weight of a chicken (in grams) could possibly change each day. For the priors on the effects of different diets, consider how much average weight difference would be possible between diets.\nNote that as Diet is a categorical variable, the priors need to be specified for each category (apart from Diet1 which is taken to be the baseline).\n\n\n\nIn brms, a regression can be specified as below, see also below (#m) or the last template. Fill in the appropriate variables, data, and likelihood family. Specify the priors, then run the model (by removing #| eval: false below).\n\npriors &lt;- c(\n  prior(normal(0, &lt;value&gt;), coef = \"Time\"),\n  prior(normal(0, &lt;value&gt;), coef = \"Diet2\"),\n  prior(normal(0, &lt;value&gt;), coef = \"Diet3\"),\n  prior(normal(0, &lt;value&gt;), coef = \"Diet4\")\n)\n\nf1 &lt;- brms::brm(\n  # This specifies the formula\n  &lt;OUTCOME&gt; ~ 1 + &lt;PREDICTOR&gt; + &lt;PREDICTOR&gt;,\n  # This specifies the dataset\n  data = &lt;data&gt;,\n  # This specifies the observation model family\n  family = &lt;observation_family&gt;,\n  # This passes the priors specified above to brms\n  prior = priors,\n  # This causes brms to cache the results\n  file = \"additional_files/assignment8/f1\"\n)\n\n### {.content-hidden when-profile=\"public\"}\npriors &lt;- c(\n  prior(normal(0, 10), coef = \"Time\"),\n  prior(normal(0, 50), coef = \"Diet2\"),\n  prior(normal(0, 50), coef = \"Diet3\"),\n  prior(normal(0, 50), coef = \"Diet4\")\n)\n\nf1 &lt;- brms::brm(\n  weight ~ 1 + Diet + Time,\n  data = ChickWeight,\n  family = \"gaussian\",\n  prior = priors\n)\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the brms-formula ?\nIs the family ?\nAre the prior standard deviations reasonable, e.g. around ?\n\n\n\nNext, you can use the bayesplot package to check the posterior predictions in relation to the observed data using the pp_check function. The function plots the \\(y\\) values, which are the observed data, and the \\(y_\\text{rep}\\) values, which are replicated data sets from the posterior predictive distribution.\n\n\n\n\n\n\nSubtask 2.d\n\n\n\nPerform the posterior predictive check with the default arguments. What do you observe? Based on the plot, do the posterior predictions encapsulate the main features of the observed data? Point out any major differences between the predictions and the observed data. Answer the following questions:\n\nAre there qualitative differences between the observed data and the predicted data?\nDo the observed data seem quantitatively similar?\n\n\n\n\n# Useful functions: brms::pp_check\n\n### {.content-hidden when-profile=\"public\"}\nbrms::pp_check(f1, plotfun=\"hist\")\n\nError in eval(expr, envir, enclos): object 'f1' not found\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nHas it been recognized that the predicted data include ?\nHas it been recognized that the observed and predicted data ?\n\n\n\nThe default density plot is not always informative, but bayesplot has different settings that can be used to create plots more appropriate for specific data.\n\n\n\n\n\n\nSubtask 2.e\n\n\n\nCreate another plot with grouping to the PPC plot using the arguments type = \"intervals_grouped\" and group = \"Diet\". What do you observe? Point out any major differences between the predictions and the observed data. Based on your visualisations, how could the model be improved?\n\n\n\n# Useful functions: brms::pp_check(..., type = ..., group=...)\n\n### {.content-hidden when-profile=\"public\"}\nbrms::pp_check(..., type = \"intervals_grouped\", group=\"Diet\")\n\nError in eval(expr, envir, enclos): '...' used in an incorrect context\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nIs there at least one reasonable way to improve the model, e.g. ?",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment8.html#log-normal-linear-regression",
    "href": "assignment8.html#log-normal-linear-regression",
    "title": "Assignment 8, 2023",
    "section": "2.3 Log-normal linear regression",
    "text": "2.3 Log-normal linear regression\nBased on the identified issues from the posterior predictive check, the model can be improved. It is advisable to change only one or a few things about a model at once. At this stage, focus on changing the observation model family to better account for the observed data.\nOne option is to use the lognormal observation model, which only allows positive values. In brms you can change the observation model family to this by setting the argument family = \"lognormal\". Note that when using the log-normal observation model, the regression coefficients represent the change in the log weight of a chicken. The priors have been adjusted accordingly in the template.\n\n\n\n\n\n\nSubtask 2.f\n\n\n\nAdjust the model, sample from the posterior and create the same two posterior predictive check plots. Comment on your observations. Does the new model better capture some aspects of the data?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n\n\n\nlog_priors &lt;- c(\n  prior(normal(0, log(3)), coef = \"Time\"),\n  prior(normal(0, log(5)), coef = \"Diet2\"),\n  prior(normal(0, log(5)), coef = \"Diet3\"),\n  prior(normal(0, log(5)), coef = \"Diet4\")\n)\n\n### {.content-hidden when-profile=\"public\"}\nf2 &lt;- brm(\n  weight ~ Diet + Time,\n  data = ChickWeight,\n  family = \"lognormal\",\n  prior = priors\n)\n\nError in eval(expr, envir, enclos): object 'priors' not found\n\n# criticism with ppc density (not grouped)\nbrms::pp_check(f2)\n\nError in eval(expr, envir, enclos): object 'f2' not found\n\n# information for each chicken\nbrms::pp_check(f2, type = \"intervals_grouped\", group = \"Diet\")\n\nError in eval(expr, envir, enclos): object 'f2' not found\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the plots look correct and are they readable?\nHas it been recognized that the fit to data is ?",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment8.html#hierarchical-log-normal-linear-regression",
    "href": "assignment8.html#hierarchical-log-normal-linear-regression",
    "title": "Assignment 8, 2023",
    "section": "2.4 Hierarchical log-normal linear regression",
    "text": "2.4 Hierarchical log-normal linear regression\nThe model can further be improved by directly considering potential differences in growth rate for individual chicken. Some chickens may innately grow faster than others, and this difference can be included by including both population and group level effects in to the model.\nTo include a group effect in brms, the code + (predictor|group) can be added to the model formula. In this case, the predictor is Time and the group is Chick.\n\n\n\n\n\n\nSubtask 2.g\n\n\n\nCreate the same two plots as for the previous models. Comment on what you see. Do the predictions seem to better capture the observed data? Are there remaining discrepancies between the predictions and observed data that could be addressed?\n\n2.4.1 \n\npriors &lt;- c(\n  prior(normal(0, log(3)), coef = \"Time\"),\n  prior(normal(0, log(5)), coef = \"Diet2\"),\n  prior(normal(0, log(5)), coef = \"Diet3\"),\n  prior(normal(0, log(5)), coef = \"Diet4\")\n)\n\nf3 &lt;-  brm(\n  weight ~ Diet + Time + (Time|Chick),\n  data = ChickWeight,\n  family = \"lognormal\",\n  prior = priors\n)\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 8.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 9.7 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 8.3 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 8.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 8.7 seconds.\nTotal execution time: 35.2 seconds.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.35.0.9000 (Stan version 2.35.0)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following objects are masked from 'package:posterior':\n\n    ess_bulk, ess_tail\n\n\n\n\n2.4.2 \n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the plots look correct and are they readable?\nHas it been recognized that the fit to data is ?\n\n\n\n\n\n\n\n\n\nSubtask 2.h\n\n\n\nHave you encountered any convergence issues in the above models? Report and comment.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nHas there been a potentially brief discussion of the standard convergence criteria (Rhat, ESS, divergent transitions) for all models?",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment8.html#model-comparison-using-the-elpd",
    "href": "assignment8.html#model-comparison-using-the-elpd",
    "title": "Assignment 8, 2023",
    "section": "2.5 Model comparison using the ELPD",
    "text": "2.5 Model comparison using the ELPD\nThere are many ways of comparing models1. Commonly, we evaluate point predictions, such as the mean of the predictive distribution2, or accuracy of the whole posterior predictive. Whether we prioritise point or density predictive accuracy may serve different purposes and lead to different outcomes for model choice 3. It is common, however, to report predictive accuracy via log-scores and point-predictive accuracy via root-mean-squared-error based on the empirical average of the predictive distribution. To cross-validate both metrics on left out observations without need to sample from each leave-one-out posterior, we use Pareto-smoothed importance sampling as discussed in the course materials (see Lecture 8).\nWe start comparing models based on the log-score. Use loo::loo() and loo::loo_compare() to quantify the differences in predictive performance.\n\n\n\n\n\n\nSubtask 2.i\n\n\n\nAnswer the following questions using loo/loo_compare:\n\nWhich model has the best predictive performance?\nDoes the uncertainty influence the decision of which model is best?\n\n\n\n\n# Useful functions: loo, loo_compare\n\n### {.content-hidden when-profile=\"public\"}\nloo_f1 &lt;- loo(f1)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f1' not found\n\nloo_f1\n\nError in eval(expr, envir, enclos): object 'loo_f1' not found\n\nloo_f2 &lt;- loo(f2)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f2' not found\n\nloo_f2\n\nError in eval(expr, envir, enclos): object 'loo_f2' not found\n\nloo_f3 &lt;- loo(f3)\n\nWarning: Found 3 observations with a pareto_k &gt; 0.7 in model 'f3'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\nloo_f3\n\n\nComputed from 4000 by 578 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo  -2254.7 27.1\np_loo        78.8  6.7\nlooic      4509.5 54.2\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.2, 1.6]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     575   99.5%   217     \n   (0.7, 1]   (bad)        3    0.5%   &lt;NA&gt;    \n   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\nloo_compare(loo_f1, loo_f2, loo_f3)\n\nError in eval(expr, envir, enclos): object 'loo_f1' not found\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the results look correct and have they been presented in a readable way? They should be roughly .\nHas it been recognized that the best model is and that the uncertainty is ?\n\n\n\n\n\n\n\n\n\nSubtask 2.j\n\n\n\nAssess whether the approximation to the LOO-CV distributions are reliable. Consult the \\(\\hat{k}\\) statistic which informs on the reliability of PSIS computation in PSIS-LOO. Plot the \\(\\hat{k}\\) values for each model against the data point ID and discuss. Are they as expected?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFor hierarchical models, it may be more important to think about how well the individual group is predicted and how many observations there are in a group compared to the number of parameters estimated. Also check out CV-FAQ on high Pareto-\\(\\hat{k}\\) values.\n\n\n\n\n# Useful functions: plot(loo(...), label_points = TRUE)\n### {.content-hidden when-profile=\"public\"}\nplot(loo(f1), label_points = TRUE)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f1' not found\n\nplot(loo(f2), label_points = TRUE)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f2' not found\n\nplot(loo(f3), label_points = TRUE)\n\nWarning: Found 3 observations with a pareto_k &gt; 0.7 in model 'f3'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\n\n\n\n\n\n\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the plots look correct and are they readable?\nHas it been explained why the \\(\\hat{k}\\) values are highest for the ? .\n\n\n\n\n\n\n\n\n\nSubtask 2.k\n\n\n\nPerform a PPC for the hierarchical model for\n\na few of the chickens with the highest \\(\\hat{k}\\) values and\na few of the chickens with the lowest \\(\\hat{k}\\) values\n\nusing the code in the template. What do you observe?\n\n\n\n\n\n\n\n\nCreating a dummy example plot\n\n\n\n\n\nCreating a dummy fit just to be able to generate an example plot below. Generate a similar plot for your hierarchical model.\n\n# The brms-formula (weights ~ ...) below is not one that you should be using in your models!\ndummy_fit &lt;- brms::brm(\n  weight ~ 1 + Time + Chick,\n  data = ChickWeight,\n  file=\"additional_files/assignment8/dummy_fit\"\n)\n# Adjust the chicken_idxs variable to select appropriate chickens\nchicken_idxs = c(1,3,11,43)\n# Create this plot for your hierarchical model for selected chickens\nbrms::pp_check(\n  dummy_fit, type = \"intervals_grouped\", group = \"Chick\",\n  newdata=ChickWeight |&gt; filter(Chick %in% chicken_idxs)\n)\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nHas it been recognized that the chickens with high \\(\\hat{k}\\) values ?",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment8.html#model-comparison-using-the-rmse",
    "href": "assignment8.html#model-comparison-using-the-rmse",
    "title": "Assignment 8, 2023",
    "section": "2.6 Model comparison using the RMSE",
    "text": "2.6 Model comparison using the RMSE\n\n\n\n\n\n\nSubtask 2.l\n\n\n\nUse the function in the template to compare the RMSE and the LOO-RMSE for the three models. Explain the difference between the RMSE and the LOO-RMSE in 1–3 sentences. Is one generally lower than the other? Why?\n\n\n\n\n\n\n\n\nrmse function implementation\n\n\n\n\n\nThe below function takes a brms fit object and computes either the root-mean-square error (RMSE) or the PSIS-LOO-RMSE, i.e. the RMSE using LOO-CV estimated using PSIS-LOO.\n\n# Compute RMSE or LOO-RMSE\nrmse &lt;- function(fit, use_loo=FALSE){\n  mean_y_pred &lt;- if(use_loo){\n    brms::loo_predict(fit)\n  }else{\n    colMeans(brms::posterior_predict(fit))\n  }\n  sqrt(mean(\n    (mean_y_pred - brms::get_y(fit))^2\n  ))\n}\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the results look correct and have they been presented in a readable way? They should be roughly: .\nHas it been recognized that the RMSE is than the LOO-RMSE because ?",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment8.html#footnotes",
    "href": "assignment8.html#footnotes",
    "title": "Assignment 8, 2023",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn principle, when comparing models based on accuracy in predictions or parameter estimation (if true parameter values are available to you, as e.g. in simulation studies), we want to use so called strictly proper scoring rules that will always indicate when a “better” model is better and the score reaches its uniquely defined best value at the “true” model, if it is also well defined. See Gneiting and Raftery, (2007) for an in depth treatment of this topic.↩︎\nNOT predictions based on the mean of the posterior parameters, but first generating the predictive distribution and then computing an average.↩︎\nFor instance, a unimodal and bimodal predictive density may have the same expected value, but very different areas of high posterior density and therefore very different log-scores.↩︎",
    "crumbs": [
      "Assignments",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Assignment 1, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThe exercises of this assignment are meant to test whether or not you have sufficient knowledge to participate in the course. The first question checks that you remember basic terms of probability calculus. The second exercise checks your basic computer skills and guides you to learn some R functions. In the last three ones you will first write the math for solving the problems (you can, for example, write the equations in markdown or include a photo of hand written answers), and then implement the final equations in R (and then you can use markmyassignment to check your results). The last question checks that you have found the course book.\nThe maximum amount of points from this assignment is 3.\nWe prepared a quarto template specific to this assignment to help you get started. You can inspect this and future templates\n\nas a qmd file,\nas a rendered html file\nor as a rendered pdf file\n\nor you can download all template qmd files and some additional files at templates.zip (also available on Aalto JupyterHub under /coursedata).\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 1.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 1. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nlibrary(markmyassignment)\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment1.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\n\n\n\n\n\n2 Basic probability theory notation and terms\nThis can be trivial or you may need to refresh your memory on these concepts (see, e.g. Aalto course First Course in Probability and Statistics). Explain each of the following terms with one sentence:\n\nprobability\nprobability mass (function)\nprobability density (function)\nprobability distribution\ndiscrete probability distribution\ncontinuous probability distribution\ncumulative distribution function (cdf)\nlikelihood\n\n\n\n\n\n\n\nRubric\n\n\n\n\nHow is the answer?\n\nTotally wrong/has not tried\nSomething sensible written\nAll/almost all are correct (&gt;=70% correct)\n\n\n\n\n\n\n3 Basic computer skills\nThis task deals with elementary plotting and computing skills needed during the rest of the course. You can use either R or Python, although R is the recommended language in this course and we will only guarantee support in R. For documentation in R, just type ?{function name here}.\n\n\n\n\n\n\nSubtask 3.a)\n\n\n\nPlot the density function of the Beta-distribution, with mean \\(\\mu = 0.2\\) and variance \\(\\sigma^2=0.01\\). The parameters \\(\\alpha\\) and \\(\\beta\\) of the Beta-distribution are related to the mean and variance according to the following equations \\[\\begin{aligned}\n    \\alpha = \\mu \\left( \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1 \\right), \\quad\n    \\beta = \\frac{\\alpha (1-\\mu) }{\\mu} \\,.\\end{aligned}\\]\n\n\nPlot the PDF here. Explain in text what you do.\n\n# Useful functions: seq(), plot() and dbeta()\n\n\n\n\n\n\n\nSubtask 3.b)\n\n\n\nTake a sample of 1000 random numbers from the above distribution and plot a histogram of the results. Compare visually to the density function.\n\n\nSample and plot the histogram here. Explain in text what you do.\n\n# Useful functions: rbeta() and hist()\n\n\n\n\n\n\n\nSubtask 3.c)\n\n\n\nCompute the sample mean and variance from the drawn sample. Verify that they match (roughly) to the true mean and variance of the distribution.\n\n\nCompute the sample mean and variance here. Explain in text what you do.\n\n# Useful functions: mean() and var()\n\n\n\n\n\n\n\nSubtask 3.d)\n\n\n\nEstimate the central 95% probability interval of the distribution from the drawn sample.\n\n\nCompute the central interval here. Explain in text what you do.\n\n# Useful functions: quantile()\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code for the solutions included?\nDoes the plot in a) look something like this: \nDoes the plot in b) look something like this: \nIs the computed mean in c) close to ?\nIs the variance in c) close to ?\nIs the probability interval in d) roughly ? Remember that since the interval is computed from random sample, there can be small variation, but the answers should be roughly the same!\n\n\n\n\n\n\n\n\n\nFurther formatting recommendations\n\n\n\n\nPlease try to include as much code and output as needed, but as little as possible.\nPlease make sure that the plots are properly labeled and are easily legible and understandable. This means\n\nthey should have x- and y-labels,\nthe text within should be of a size comparable to the size of the surrounding text and\neach plot should have a concise but descriptive caption or title.\n\nPlease make sure to report a sensible number of digits when reporting numbers. You will get more precise instructions later on, but for now think independently about how many digits of your results are important for the assignment.\n\n\n\n\n\n4 Bayes’ theorem 1\nA group of researchers has designed a new inexpensive and painless test for detecting lung cancer. The test is intended to be an initial screening test for the population in general. A positive result (presence of lung cancer) from the test would be followed up immediately with medication, surgery or more extensive and expensive test. The researchers know from their studies the following facts:\n\nTest gives a positive result in \\(98\\%\\) of the time when the test subject has lung cancer.\nTest gives a negative result in \\(96\\%\\) of the time when the test subject does not have lung cancer.\nIn general population approximately one person in 1000 has lung cancer.\n\n\n\n\n\n\n\nSubtask 4.a)\n\n\n\nThe researchers are happy with these preliminary results (about \\(97\\%\\) success rate), and wish to get the test to market as soon as possible. How would you advise them? Base your answer on Bayes’ rule computations.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nRelatively high false negative (cancer doesn’t get detected) or high false positive (unnecessarily administer medication) rates are typically bad and undesirable in tests.\n\n\n\nCompute the quantities needed to justify your recommendation here. Explain in text what you do. You can do the computation with pen and paper or in R. Either way, you have to explain why you compute what you compute.\nIf you use pen and paper, you can include scans or pictures as follows (see also assignment_instructions#fig-workflow):\n\n\n\n\n\n\nFigure 1: Parts of Bayesian workflow\n\n\n\nSee Figure 1 for illustration of parts of Bayesian workflow.\nHere are some probability values that can help you figure out if you copied the right conditional probabilities from the question.\n\nP(Test gives positive | Subject does not have lung cancer) = \\(4\\%\\)\nP(Test gives positive and Subject has lung cancer) = \\(0.098\\%\\) this is also referred to as the joint probability of test being positive and the subject having lung cancer.\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs p(has cancer|test result is positive) computed using Bayes’ formula (or its complement p(does not have cancer|test result is positive))?\nIs the result p(has cancer|test result is positive)= (or p(does not have cancer|test result is positive)=)\nIs the result motivated with something like \n\n\n\n\n\n5 Bayes’ theorem 2\nWe have three boxes, A, B, and C. There are\n\n2 red balls and 5 white balls in the box A,\n4 red balls and 1 white ball in the box B, and\n1 red ball and 3 white balls in the box C.\n\nConsider a random experiment in which one of the boxes is randomly selected and from that box, one ball is randomly picked up. After observing the color of the ball it is replaced in the box it came from. Suppose also that on average box A is selected 40% of the time and box B \\(10\\%\\) of the time (i.e. \\(P(A) = 0.4\\)).\nYou will need to change the numbers to the numbers in the exercise.\n\nboxes_test &lt;- matrix(c(2,2,1,5,5,1), ncol = 2,\n    dimnames = list(c(\"A\", \"B\", \"C\"), c(\"red\", \"white\")))\n\n\n\n\n\n\n\nSubtask 5.a)\n\n\n\nWhat is the probability of picking a red ball? Implement an R function to compute that probability.\n\n\nKeep the below name and format for the function to work with markmyassignment:\n\np_red &lt;- function(boxes) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    0.3928571\n}\n\n\n\n\n\n\n\nSubtask 5.b)\n\n\n\nIf a red ball was picked, from which box did it most probably come from? Implement an R function to compute the probabilities for each box.\n\n\nKeep the below name and format for the function to work with markmyassignment:\n\np_box &lt;- function(boxes) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.29090909,0.07272727,0.63636364)\n}\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code available?\nHow is the answer for probability of picking a red ball?\n\nNo answer\nProbability rules and used, but the result is not \nProbability rules and used, and the result is \n\nHow is the answer for what box is most probable?\n\nNo answer\nBayes rule used to compute probabilities for all boxes given that the picked ball is red, but the answers are not \nBayes rule used to compute probabilities for all boxes given that the picked ball is red, the answers are p and it is not explicity said that the most probable box is box \nBayes rule used to compute probabilities for all boxes given that the picked ball is red, the answers are and it is explicity said that the most probable box is box \n\n\n\n\n\n\n6 Bayes’ theorem 3\nAssume that on average fraternal twins (two fertilized eggs and then could be of different sex) occur once in 150 births and identical twins (single egg divides into two separate embryos, so both have the same sex) once in 400 births (Note! This is not the true value, see Exercise 1.6, page 28, in BDA3). American male singer-actor Elvis Presley (1935 – 1977) had a twin brother who died in birth. Assume that an equal number of boys and girls are born on average.\n\n\n\n\n\n\nSubtask 6.a)\n\n\n\nWhat is the probability that Elvis was an identical twin? Show the steps how you derived the equations to compute that probability and implement a function in R that computes the probability.\n\n\nYou will need to change the numbers to the numbers in the exercise.\n\nfraternal_prob = 1/125\nidentical_prob = 1/300\n\nKeep the below name and format for the function to work with markmyassignment:\n\np_identical_twin &lt;- function(fraternal_prob, identical_prob) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    0.4545455\n}\n\n\n\n\n\n\n\nRubric\n\n\n\n\nHow is the answer for probability of Elvis having had an identical twin brother?\n\nNo answer\nProbability that Elvis had an identical twin brother is computed using Bayes rule, but the result is not roughly \nProbability that Elvis had an identical twin brother is computed using Bayes rule, and the result is roughly \n\n\n\n\n\n\n7 The three steps of Bayesian data analysis\n\n\n\n\n\n\nSubtask 7.a)\n\n\n\nFill in the three steps of Bayesian data analysis (see BDA3 section 1.1):\n\n\n\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nAre the three steps listed as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n8 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Assignments",
      "Assignment 1, 2023"
    ]
  },
  {
    "objectID": "template2.html",
    "href": "template2.html",
    "title": "Assignment 2, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 2 and BDA3 Chapters 1 and 2. You may find an additional discussion about choosing priors in a blog post by Andrew Gelman.\nThe maximum amount of points from this assignment is 3.\nWe prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 1.\nThe reading instructions for BDA3 Chapter 2.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 2. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\nlibrary(markmyassignment)\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment2.yml\", sep=\"\")\nset_assignment(assignment_path)\nThe following installs the aaltobda package:\n#| cache: true\n# Caching should be fine here\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\n\n\n\n\n2 Inference for binomial proportion\nAlgae status is monitored in 274 sites at Finnish lakes and rivers. The observations for the 2008 algae status at each site are presented in the dataset algae in the aaltobda package (‘0’: no algae, ‘1’: algae present).\nLoading the library and the data.\n\nlibrary(aaltobda)\ndata(\"algae\")\n# The data are now stored in the variable `algae`.\n# These are the values for the prior required in the assignment\nprior_alpha = 2\nprior_beta = 10\n\nThe below data is only for the tests, you need to change to the full data algae when reporting your results.\nalgae_test &lt;- c(0, 1, 1, 0, 0, 0)\nLet \\(\\pi\\) be the probability of a monitoring site having detectable blue-green algae levels and \\(y\\) the observations in algae. Use a binomial model for the observations \\(y\\) and a \\(Beta(2,10)\\) prior for binomial model parameter \\(\\pi\\) to formulate a Bayesian model. Here it is not necessary to derive the posterior distribution for \\(\\pi\\) as it has already been done in the book and it suffices to refer to that derivation. Also, it is not necessary to write out the distributions; it is sufficient to use label-parameter format, e.g. \\(Beta(\\alpha,\\beta)\\).\nYour task is to perform Bayesian inference for a binomial model and answer questions based on it:\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nFormulate\n\nthe likelihood \\(p(y|\\pi)\\) as a function of \\(\\pi\\),\nthe prior \\(p(\\pi)\\), and\nthe resulting posterior \\(p(\\pi|y)\\).\n\nReport the posterior in the format \\(Beta(\\alpha,\\beta)\\), where you replace \\(\\alpha\\) and \\(\\beta\\) with the correct numerical values.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWith a conjugate prior, a closed-form posterior has Beta form (see equations in BDA3 and in the slides).\n\n\n\nWrite the likelihood, the prior and the posterior here!\n\n# These are not the actual values for the posterior!\n# You will have to compute those from the data!\nposterior_alpha = 2\nposterior_beta = 10\n\nYou can do string interpolation using R inline code execution in quarto as such:\n\\(\\alpha_\\text{prior}\\) is 2 and \\(\\beta_\\text{prior}\\) is 10. Or string interpolation within math: \\(Beta(2,10)\\)\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nWhat can you say about the value of the unknown \\(\\pi\\) according to the observations and your prior knowledge? Summarize your results with a point estimate (i.e. \\(E(\\pi|y)\\)) and a 90% posterior interval.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nPosterior intervals are also called credible intervals and are different from confidence intervals.\n\n\n\nKeep the below name and format for the functions to work with markmyassignment:\n# Useful function: qbeta()\n\nbeta_point_est &lt;- function(prior_alpha, prior_beta, data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above,\n    # combined with the prior provided above.\n    0.2222222\n}\nbeta_interval &lt;- function(prior_alpha, prior_beta, data, prob=0.9) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above,\n    # combined with the prior provided above.\n    c(0.0846451, 0.3956414)\n}\n\n\n\n\n\n\nSubtask 2.c)\n\n\n\nWhat is the probability that the proportion of monitoring sites with detectable algae levels \\(\\pi\\) is smaller than \\(\\pi_0=0.2\\) that is known from historical records?\n\n\nKeep the below name and format for the function to work with markmyassignment:\n# Useful function: pbeta()\n\nbeta_low &lt;- function(prior_alpha, prior_beta, data, pi_0=0.2) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above,\n    # combined with the correct prior.\n    0.4511238\n}\n\n\n\n\n\n\nSubtask 2.d)\n\n\n\nWhat assumptions are required in order to use this kind of a model with this type of data?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNo need to discuss exchangeability yet, as it is discussed in more detail in BDA3 Chapter 5 and Lecture 7.\n\n\n\nWrite your answer here!\n\n\n\n\n\n\nSubtask 2.e)\n\n\n\nMake prior sensitivity analysis by testing a couple of different reasonable priors and plot the different posteriors. Summarize the results by one or two sentences.\n\n\nPlot the PDFs here. Explain shortly what you do.\n# Useful function: dbeta()\n\n\n\n\n\n\nRubric\n\n\n\n\nIs source code included?\nAre the prior, likelihood and posterior forms in a) reported (derivation of posterior not necessary)?\n\nNo\nSome missing\nYes\n\nIs the reported resulting posterior correct ?\n\nIt is not reported, that the posterior distribution is a distribution.\nIt is reported, that the posterior distribution is , but the numerical values for the parameters are incorrect\nIt is reported, that the posterior distribution is , and the numerical values for the parameters are correct.\n\nIn part b), is there at least one point estimate reported. Sample based estimates are also OK. Points should be given if the method is right, even if the result is wrong due to a wrong posterior distribution being used. With the right posterior, mean, median, and mode are all approximately .\nFor the b) part, is the 90% posterior interval reported? Sample based estimate is also OK. Points should be given if the method is right, even if the result is wrong because the posterior was wrong in the first place. If the posterior was right, the 90% posterior interval is roughly .\nFor the c) part, is the posterior probability Pr(π&lt;0.2|y) reported? Points should be given if the method is right, even if the result is wrong because the posterior was wrong. If the posterior was right, the result should be approximately .\nFor the d) part, does the report discuss\n\nNo\nNo, but other reasonable assumptions are discussed\nYes, but not quite right or some missing\nYes\n\nFor the e) part, is there some comparison and discussion of results obtained with alternative prior parameters?\n\nNo\nYes, but the results and conclusions are clearly wrong\nYes\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\nmark_my_assignment()\n\n\n\n\n\n3 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Templates",
      "Assignment 2, 2023"
    ]
  },
  {
    "objectID": "assignment_instructions.html",
    "href": "assignment_instructions.html",
    "title": "Assignment instructions",
    "section": "",
    "text": "In addition to R-markdown, Quarto can be used to write the assignment reports. This template contains essentially the same information as the old R-markdown template but we illustrate how you can use Quarto for the assignments.\nSome useful resources to get started with Quarto (also an example of a list):\n\nGetting started with Quarto and Rstudio from the official webpage\nA comprehensive user guide from the official webpage\nMarkdown basics\nQuarto FAQ for R-markdown users\nAwesome Quarto - list by Mickaël Canouil\n\nTo create your assignment, you can use the assignment-specific templates (recommended, see e.g. the links at the top of assignment 1) or remove the formatting instructions and use this file as a template. Keep the header (the first lines of this file between two lines of —) as it sets the author name to be anonymous, and you can set the title to match the assignment number.\nAs with R-markdown, you can use the text editor of your choice, but RStudio’s editor is probably the easiest and you can choose the formatting (e.g. section headings, bolding, lists, figures, etc.) from the toolbar. Switching between the source and visual mode allows the quick preview of your formatting.\nNote The report should be anonymous and submitted to peergrade.io as assignmentX.pdf. Aalto JupyterHub has everything installed and you should be able to render the templates to pdf without any further set-up, but if there are problems contact the TAs or get more information on this from the Quarto documentation. Alternatively, if you have problem with creating a PDF file, start by creating an HTML file and the just print the HTML to a PDF. You may also use other software to create the report PDF, but follow the general instructions in this file (see the pdf version of the template file).",
    "crumbs": [
      "General instructions",
      "Assignment instructions"
    ]
  },
  {
    "objectID": "assignment_instructions.html#a",
    "href": "assignment_instructions.html#a",
    "title": "Assignment instructions",
    "section": "5.1 a)",
    "text": "5.1 a)\nFor each subtask include necessary textual explanation, equations, code and figures so that the answer to the question flows naturally. You can think what kind of report would you like to review, and what kind of information would make it easier where there is error (if there are errors).",
    "crumbs": [
      "General instructions",
      "Assignment instructions"
    ]
  },
  {
    "objectID": "assignment7.html",
    "href": "assignment7.html",
    "title": "Assignment 7, 2023",
    "section": "",
    "text": "Warning\n\n\n\nCurrently, rendering on github is broken, such that the rendered template at https://avehtari.github.io/BDA_course_Aalto/assignments/template7.html looks weird. Rendering should however work on Aalto’s JupyterLab, but we will also try to fix rendering on github ASAP.",
    "crumbs": [
      "Assignments",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "assignment7.html#choosing-a-weakly-informative-prior-by-intuition",
    "href": "assignment7.html#choosing-a-weakly-informative-prior-by-intuition",
    "title": "Assignment 7, 2023",
    "section": "2.1 Choosing a weakly informative prior by intuition",
    "text": "2.1 Choosing a weakly informative prior by intuition\nWe will first guide you through two processes for choosing weakly informative priors which you can use in your projects as well (though, if expert knowledge is present, we encourage to use that though instead). Many definitions of weak exist, but for our purposes, we intend to set priors in this assignment which don’t overwhelm the likelihood contributions to the posterior while still exerting some amount of regularisation.\nIn the absence of additional information, we will assume that chick weights at 12 days of age (\\(w\\)) follow a normal distribution: \\[\nw\\sim\\mathcal N (\\mu,\\sigma).\n\\] Our task will be to define weakly informative priors for the mean \\(\\mu\\) given observation model standard deviation, \\(\\sigma\\) (a prior distribution for \\(\\sigma\\) will be set in after section 2).\nHere, \\(\\mu\\) represents the population mean chick weight at 12 days and \\(\\sigma\\) represents the standard-deviation of the chick weights \\(w\\) around that population mean. For this exercise, we will be specifying a normal prior for \\(\\mu\\):\n\\[\n\\mu\\sim\\mathcal N (\\mu_0,\\sigma_0).\n\\]\n\\(\\mu_0\\) represents our prior knowledge of what we believe the population weight to be and \\(\\sigma_0\\) represents our level of certainty in this belief. To specify a weakly-informative prior for \\(\\mu\\) we need to select values of \\(\\mu_0\\) and \\(\\sigma_0\\) that imply the range of plausible values that \\(\\mu\\) could take.\nWe can do this by our own intuitive prior knowledge (if such intuition exists), or by searching for external references.\nDespite the name, weakly informed priors can be quite subjective (see for more theoretical discussion here), such that some justification is always needed. For the subtasks below, you will not be graded on the accuracy or precision of your numbers, but on your justification of them. The numerical choices you make should make sense and be understandable to an external reviewer of your work (even if they may not agree with your choices).\n\n\n\n\n\n\nA word of caution on eliciting the priors below\n\n\n\n\n\nPlease note that in the below, we intend to set a prior on \\(\\mu\\) (the mean chick weight), but the intuition we ilicit is based on the weight of individual chicks. We do so to help create intuition about what the mean could be, however, it would be theoretically more accurate to ilicit priors about mean chick weights.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWe have made changes to the assignment text and some of the rubrics to make it clearer.\n\n\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nBased on your own past experience and estimation skills, what would you guess is a typical weight range of a fully grown chicken in grams? Justify your choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWould it make sense if a chicken weighed 1 million grams? 0.005 grams? What about a chicken that weighed more than you? More than a car? Note that is not important to have a very precise or accurate guess here, the key goal is simply to identify the range of plausible (or at least possible) values.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.1 Fully grown chicken weight range by intuition\n\nDoes the chosen range meet the following common sense criteria?\n\nThe range is always above and below .\n\nIs the justification based on some sort of logic, even if you may disagree?\n\n\n\n\n\n\n\n\n\nSubtask 2.b\n\n\n\nAdjust this range for a 12-day old chick and choose a mean \\(\\mu_0\\) for the weakly informed prior of the parameter \\(\\mu.\\) Justify your adjustment and choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.2 12-day old chick weight range by intuition\n\nThe range is always above and below .\nIs the justification based on some sort of logic, even if you may disagree?\n\n\n\nChoosing the prior standard deviation for \\(\\mu\\) requires a little more caution; overconfident (i.e. narrow) priors can have a strong effect on your results, whereas less confident priors are more easily overcome with observed data. Given that overconfidence is a common human bias, a good intuition-based standard deviation should focus on eliminating the impossible values, rather than including the most likely values.\n\n\n\n\n\n\nSubtask 2.c\n\n\n\nChoose a conservative lower and upper bound for the weight of any 12-day old chick, with the goal to exclude impossible values. Justify your choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDepending on your choice of range above for a “typical” chick, this range excluding the impossible values should be wider.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.3 Prior standard deviation by intuition\n\nDoes the chosen range meet the following common sense criteria?\n\nThe range is always above and below .\n\nIs the justification based on some sort of logic, even if you may disagree?\n\n\n\nA common technique to find a weakly informative prior is to have a standard deviation which is an order of magnitude (a factor of 10) larger than a plausible standard deviation of the data.\n\n\n\n\n\n\nSubtask 2.d\n\n\n\nWhat do you think is a plausible standard deviation \\(\\sigma_\\text{plausible}\\) of the weight of 12 days-old chicks, based on your ranges stated above? Under the above recommendation, what standard deviation \\(\\sigma_0\\) should you use for your prior for the mean weight \\(\\mu\\)?\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.3.1 Prior standard deviation by intuition\n\nDo the two standard deviations meet the following common sense criteria?\n\nBoth values are \n\nGiven the choice of mean from above, the interval \\((\\mu_0 - 3\\sigma_0, \\mu_0 + 3\\sigma_0)\\) includes .\n\n\n\n\n\n\n\n\n\nSubtask 2.e\n\n\n\nWrite down in mathematical form the final prior for the mean weight \\(\\mu\\) you found using this prior definition technique.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.4 Prior by intuition\n\nDoes the final prior exist in mathematical notation?\nDoes the prior reflect the choices made above (i.e. \\(\\mu_0, \\sigma_0\\))?",
    "crumbs": [
      "Assignments",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "assignment7.html#choosing-a-weakly-informative-prior-using-external-references",
    "href": "assignment7.html#choosing-a-weakly-informative-prior-using-external-references",
    "title": "Assignment 7, 2023",
    "section": "2.2 Choosing a weakly informative prior using external references",
    "text": "2.2 Choosing a weakly informative prior using external references\nNext, we’ll use external references to pick the weakly informed prior. This technique is more general and doesn’t assume you would have prior knowledge.\n\n\n\n\n\n\nSubtask 2.f\n\n\n\nConsult a trustworthy source on the weight range of farm chickens, e.g. books, articles, a farmer friend. If the recommended values are for a fully grown chicken, make a reasonable adjustment for a 12-day old chick. What is the weight range of a 12-day old chicken? Cite your source and justify any adjustments you make to the reference range.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.1 Weight range by reference\n\nDoes the reference range meet the following common sense criteria?\n\nThe range is always above and below .\n\nIs there a citation? If an adjustment was made, was it justified by logic, even if you disagree?\n\n\n\n\n\n\n\n\n\nSubtask 2.g\n\n\n\nBased on this reference range, what will you choose for the mean of our weakly informed prior? Justify your choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.2 Weight range by reference\n\nDoes the mean value meet the following common sense criteria?\n\nThe range is always above and below .\n\n\n\n\nNext we choose the standard deviation of the prior. We could use the same technique as before, but we’ll walk you through another common approach. Assume that \\(99.7\\%\\) of all 12-day old chicks fall into the reference range you found. Under our assumption of a normal distribution, this range will encompass values between \\(\\mu_0 \\pm 3\\sigma_0\\).\n\n\n\n\n\n\nSubtask 2.h\n\n\n\nAssuming symmetry, use the mean you chose and either the upper or lower bound \\(b\\) of your reference range to solve the correct version of the following equations to find your associated choice of \\(\\sigma_0\\): (show your work)\n\nFor upper bound \\(b_u\\): \\(Pr(\\mu_0 + 3\\sigma_0 &lt; b_u) \\approx 0.997\\), solving for \\(\\sigma_0\\).\nFor lower bound \\(b_l\\): \\(Pr(\\mu_0 - 3\\sigma_0 &gt; b_l) \\approx 0.997\\), solving for \\(\\sigma_0\\).\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.3 Prior standard deviation by reference\n\nDoes the calculated \\(\\sigma_0\\) value meet the following common sense criteria?\n\nThe value is above and below .\n\nDid they show their work?\n\n\n\n\n\n\n\n\n\nSubtask 2.i\n\n\n\nWrite down in mathematical form the final prior for the mean weight \\(\\mu\\) you found using this prior definition technique.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.4 Prior by reference\n\nDoes the final prior exist in mathematical notation?\nDoes the prior reflect the choices made above (i.e. \\(\\mu_0, \\sigma_0\\))?",
    "crumbs": [
      "Assignments",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "assignment7.html#non-normal-priors",
    "href": "assignment7.html#non-normal-priors",
    "title": "Assignment 7, 2023",
    "section": "2.3 Non-normal priors",
    "text": "2.3 Non-normal priors\nThe previous steps all assumed we could use a prior which is normally distributed, but this may not always be the correct assumption to make.\n\n\n\n\n\n\nSubtask 2.j\n\n\n\nUnder what mathematical/statistical circumstances would a normal distributed prior not make sense? List at least one circumstance. Are there values that the normal distribution can take on which would not make sense for some types of variables?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nConsider the nature of any variable you are trying to define a prior over.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.3.1 Non-normal priors\n\nExample cases include variables that or variables that",
    "crumbs": [
      "Assignments",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "assignment7.html#modeling-diet-effects-on-chicken-weight",
    "href": "assignment7.html#modeling-diet-effects-on-chicken-weight",
    "title": "Assignment 7, 2023",
    "section": "2.4 Modeling diet effects on chicken weight",
    "text": "2.4 Modeling diet effects on chicken weight\nIn addition to chick weights, the data also contains a categorical variable indicating which diet the chick received. In the data file, each column contains the measurements for a single chick at a given point of time.\nIn addition to the existing diets, we are interested in the quality of another box of feed (the fifth diet), which a farmer happened to find yesterday at a dark corner of his warehouse. To read in the data and select chicks with age of 12 days, and to have a peek at the first 6 rows, just use:\n\n\n\n\n\n\nData inside, don’t peek before you have set your priors!\n\n\n\n\n\n\n\n\n\n\n\nHave you set your priors?\n\n\n\n\n\n\ndata(\"ChickWeight\")\n\nChick12 &lt;- ChickWeight |&gt; filter(Time == 12)\n\nhead(Chick12)\n\nGrouped Data: weight ~ Time | Chick\n  weight Time Chick Diet\n1    106   12     1    1\n2    122   12     2    1\n3    115   12     3    1\n4    102   12     4    1\n5    141   12     5    1\n6    141   12     6    1\n\n\n\n\n\n\n\n\nIn the following analysis, we will model the weight of a chick at the age of 12 days. We will use the following three Gaussian models:\n\na separate model, in which each diet is modeled individually\na pooled model, in which all measurements are combined and there is no distinction between diets\na hierarchical model, which has a hierarchical structure as described in BDA3 Section 11.6\n\nAs in the model described in the book, use the same weight standard deviation \\(\\sigma\\) for all the groups in the hierarchical model. In the separate model, however, use separate weight standard deviation \\(\\sigma_d\\) for each diet \\(d\\). You should use weakly informative priors for all your models.\nThe provided Stan code below is given as an example of a separate model. Note that the author has left a comment expressing uncertainty about their prior choices. This separate model can be summarized mathematically as \\[\n\\begin{aligned}\n    \\mu_{d} &\\sim \\pi(\\mu_d)&&\\text{(diet-wise mean weight),}\\\\\n    \\sigma_d &\\sim \\pi(\\sigma_d)&&\\text{(diet-wise standard deviation of diet-wise chicken weights)},\\\\\n    w_{i,d} &\\sim N(\\mu_d,\\sigma_d)&&\\text{(diet-wise chicken weights)}\\\\\n\\end{aligned}\n\\tag{1}\\]\nwith priors\n\\[\n\\begin{aligned}\n    \\mu_{d} &\\sim N(0,10)&&\\text{(adjust this) and}\\\\\n    \\sigma_d &\\sim\\mathrm{exponential}(.02)&&\\text{(you can keep this).}\n\\end{aligned}\n\\tag{2}\\]\nFor the separate and the pooled models, use one of the weakly informative priors you have derived in 2.1) or 2.2) for the diet-wise mean weights \\[\\mu_d\\sim \\pi(\\mu_d)=N(\\mu_0,\\sigma_0).\\] For the hierarchical model, remember that the parameters in the priors for the diet-wise mean weights itself have to be parameters with their own prior distributions, in our case \\[\n\\begin{aligned}\n\\mu_d &\\sim N(\\mu,\\tau)&&\\text{(diet-wise mean weights)},\\\\\n\\mu &\\sim \\pi(\\mu)&&\\text{(mean of prior for diet-wise mean weights) and}\\\\\n\\tau &\\sim \\pi(\\tau)&&\\text{(standard deviation of prior for diet-wise mean weights).}\n\\end{aligned}\n\\]\nUse the prior you have used for the diet-wise mean weights \\(\\mu_d\\) in the separate and pooled models for the prior on the mean of the prior for the diet-wise mean weights \\[\\mu \\sim \\pi(\\mu) = N(\\mu_0,\\sigma_0)\\] in the hierarchical model and use \\[\\tau \\sim \\pi(\\tau) = \\mathrm{exponential}(.02)\\] for the prior on the standard deviation of the prior for the diet-wise mean weights.\n\n\n\n\n\n\n\nSample from the posterior\n\n\n\n\n\nTo sample from the posterior using Stan, use:\n\nstan_data &lt;- list(\n  N_observations = nrow(Chick12),\n  N_diets = length(unique(Chick12$Diet)),\n  diet_idx = Chick12$Diet,\n  weight = Chick12$weight\n)\n\nmodel_separate &lt;- cmdstan_model(stan_file = \"additional_files/assignment7/chickens_separate.stan\")\n\n# Sampling from the posterior distribution happens here:\nfit_separate &lt;- model_separate$sample(data = stan_data, refresh=0,\n                                      show_messages=FALSE,\n                                      show_exceptions=FALSE)\n\nWarning: No chains finished successfully. Unable to retrieve the fit.\n\n\nFit objects returned by the sample() method, by default print a summary of the posterior draws. These are NOT the results you would expect to turn in your report. You will need to change the priors in the code for the separate model.\n\nfit_separate\n\nError: Fitting failed. Unable to print.\n\n\nQuick model convergence check (as in assignment 6):\n\nfit_separate$cmdstan_diagnose()\n\nError: No CmdStan runs finished successfully. Unable to run bin/diagnose.\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.k\n\n\n\nDescribe the models with mathematical notation (as is done for the separate model above). Also describe in words the difference between the model and the other models.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nAre the models described using mathematical notation and the difference to other models described in words?\n\nNo equations and no description\nDescription but no equations\nEquations but no description\nEquations and description\n\n\n\n\n\n\n\n\n\n\nSubtask 2.l\n\n\n\nImplement the models in Stan and include the code in the report. Use weakly informative priors for all of your models.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWhen sampling from the posterior of the hierarchical model, you will very likely get a warning about divergent transitions. This tells you that the sampler is having difficulties in sampling the joint posterior and this may lead to biased inference. We will return to this in the next task.\n\n\n\nFor the figures below, we use the earlier draws for the separate model with bad priors. When you have implemented the pooled and hierarchical models, edit the code below to include draws from your model posterior into the figures.\n\n\n\n\n\n\nData preparation and sampling from the posterior\n\n\n\n\n\n\nfit_pooled &lt;- fit_separate\nfit_hierarchical &lt;- fit_separate\n\nBelow, we collect the corresponding posterior draws from the three models into a shared data frame using the extract_variable function. This makes plotting the posterior in a single plot easier.\n\n# Expect the same number of posterior draws from each model.\nndraws &lt;- nrow(fit_hierarchical$sampler_diagnostics(format = \"matrix\"))\n\nError: No chains finished successfully. Unable to retrieve the sampler diagnostics.\n\n# Collect posterior draws and the model used to a data frame.\nmean_diet_4_separate = extract_variable(fit_separate, \"mean_diet[4]\")\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\nmean_diet_4_pooled = extract_variable(fit_pooled, \"mean_diet[4]\")\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\nmean_diet_4_hierarchical = extract_variable(fit_hierarchical, \"mean_diet[4]\")\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\nposterior_mean_diet_4 &lt;- data.frame(\n  model_name = rep(c(\"Separate\", \"Pooled\", \"Hierarchical\"),\n              each = ndraws),\n  mean_diet_4 = c(\n   mean_diet_4_separate, mean_diet_4_pooled, mean_diet_4_hierarchical\n  ))\n\nError in eval(expr, envir, enclos): object 'mean_diet_4_separate' not found\n\npredicted_weight_diet_4 &lt;- data.frame(\n  model_name = rep(c(\"Separate\", \"Pooled\", \"Hierarchical\"),\n              each = ndraws),\n  predicted_weight = c(\n   extract_variable(fit_separate, \"weight_pred\"),\n   extract_variable(fit_pooled, \"weight_pred\"),\n   extract_variable(fit_hierarchical, \"weight_pred\")\n  ))\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\n# Collect posterior draws and the model used to a long data frame.\nposterior_mean_diet_5 &lt;- data.frame(\n  model_name = rep(c(\"Separate\", \"Pooled\", \"Hierarchical\"),\n    each = ndraws\n  ),\n  mean_diet_5 = c(\n    extract_variable(fit_separate, \"mean_five\"),\n    extract_variable(fit_pooled, \"mean_five\"),\n    extract_variable(fit_hierarchical, \"mean_five\")\n  )\n)\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\n# Mean observed weight per diet, these help to compare the posteriors to data.\ndiet_means &lt;- sapply(\n  1:4, function(diet) mean(Chick12[Chick12$Diet == diet, \"weight\"])\n)\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.4.1 All models\n\nIs there a related Stan implementation?\n\nNo Stan model implemented\nStan model implemented, but it seems clearly wrong or broken\nSeemingly valid Stan model implemented\n\n\n\n\n\n\n\n\n\n\nSubtask 2.m\n\n\n\nUse the provided code in the template to plot the posterior distribution of the mean of the weight measurements of the fourth diet and comment on the possible differences you observe between the models.\n\n\n\nggplot(posterior_mean_diet_4, aes(x = mean_diet_4, y = model_name)) +\n  stat_dotsinterval(quantiles = 100, scale = .9) +\n  vline_at(diet_means[4], size = 1, linetype = \"dashed\") +\n  # Annotate the vline from above.\n  annotate(\"text\", label = \"Observation mean\", x = diet_means[4] - 5, y = .7,\n           hjust = \"right\", size = 6) +\n  # Add title and axis labels. One line to make everything so much more clear!\n  labs(\n    title = \"Mean of diet 4\",\n    x = \"Weight (g)\",\n    y = \"Model\"\n  )\n\nError in eval(expr, envir, enclos): object 'posterior_mean_diet_4' not found\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs there a comparison plotted for the posteriors of the mean of diet 4? Does it look something like the model solution plot?\n\nNo comparison plotted\nComparison plotted but it clearly differs from the example\nComparison plotted and it approximately matches the example\n\nSeparate model: Is the result for the separate model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the separate model is recognised as .\n\nPooled model: Is the result for the pooled model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the pooled model is recognised as .\n\nHierarchical model: Is the result for the hierarchical model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the hierarchical model is recognised as .\n\n\n\n\n\n\n\n\n\n\nSubtask 2.n\n\n\n\nUse the provided code in the template to plot the predictive distribution for another weight measurement from a chick having the fourth diet and comment on the possible differences you observe between the models.\n\n\n\nggplot(predicted_weight_diet_4, aes(x = predicted_weight, y = model_name)) +\n  stat_dotsinterval(quantiles = 100, scale = .9) +\n  vline_at(diet_means[4], size = 1, linetype = \"dashed\") +\n  # Annotate the vline from above.\n  annotate(\"text\", label = \"Observation mean\", x = diet_means[4] - 5, y = .7,\n           hjust = \"right\", size = 6) +\n  # Add title and axis labels. One line to make everything so much more clear!\n  labs(\n    title = \"Weigth of a chick with diet 4\",\n    x = \"Weight (g)\",\n    y = \"Model\"\n  )\n\nError in eval(expr, envir, enclos): object 'predicted_weight_diet_4' not found\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs there a comparison plotted for the predictive distributions of the weight of a chick with diet 4? Does it look something like the model solution plot?\n\nNo comparison plotted\nComparison plotted but it clearly differs from the example\nComparison plotted and it approximately matches the example\n\nSeparate model: Is the result for the separate model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the separate model is recognised as .\n\nPooled model: Is the result for the pooled model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the pooled model is recognised as .\n\nHierarchical model: Is the result for the hierarchical model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the hierarchical model is recognised as .\n\n\n\n\n\n\n\n\n\n\nSubtask 2.o\n\n\n\nUse the provided code in the template to plot the posterior distribution of the mean of the weight measurements of a new fifth diet and comment on the possible differences you observe between the models.\n\n\n\nggplot(posterior_mean_diet_5, aes(x = mean_diet_5, y = model_name)) +\n  # Draw the mean of each diet from the data as a dashed vertical line.\n  vline_at(diet_means, size = .5, linetype = \"dashed\") +\n  # dotsinterval gives mean, 50%, and 90% intervals + dotsplot with each dot\n  # representing 1% of data (quantiles = 100).\n  stat_dotsinterval(quantiles = 100, scale = .9) +\n  # Annotate the vline from above.\n  annotate(geom = \"text\", label = \"Means of observed diets\", y = .7, x = 100,\n           hjust = \"right\", size = 5, family = \"sans\") +\n  # Add title and axis labels. One line to make everything so much more clear!\n  labs(title = \"Mean of a new diet\",\n       x = \"Weight (g)\",\n       y = \"Model\")\n\nError in eval(expr, envir, enclos): object 'posterior_mean_diet_5' not found\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs there a comparison plotted for the posterior distributions of the mean weight with a new diet? Does it look something like the model solution plot?\n\nNo comparison plotted\nComparison plotted but it clearly differs from the example\nComparison plotted and it approximately matches the example\n\nSeparate model: Is the result for the separate model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the separate model is recognised as .\nIn addition to the previous option, it is recognised that .\n\nPooled model: Is the result for the pooled model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the pooled model is recognised as .\nIn addition to the previous option, it is mentioned that .\n\nHierarchical model: Is the result for the hierarchical model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the hierarchical model is recognised as .\n\n\n\n\n\n\n\n\n\n\nSubtask 2.p\n\n\n\nFor each model, report the posterior expectation for the mean weight of diet 4 with a 90% credible interval.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSee the example Stan codes in the demo Bayesian data analysis - CmdStanR demos: Comparison of \\(k\\) groups with hierarchical models for the comparison of \\(k\\) groups with and without the hierarchical structure.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nFor the separate model, is the posterior 90% credible interval for the mean of the fourth diet close to: (small/medium deviation is fine).\n\nNo or incorrect answer\nAnswer is only partially correct\nAnswers look correct\n\nFor the pooled model, is the posterior 90% credible interval for the mean of the fourth diet close to: (small/medium deviation is fine).\n\nNo answer\nAnswer is only partially correct\nAnswer looks correct\n\nFor the hierarchical model, is the posterior 90% credible interval for the mean of the fourth diet close to: (small/medium deviation is fine).\n\nNo answer\nAnswer is only partially correct.\nAnswers look correct.",
    "crumbs": [
      "Assignments",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "Assignment 2, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 2 and BDA3 Chapters 1 and 2. You may find an additional discussion about choosing priors in a blog post by Andrew Gelman.\nThe maximum amount of points from this assignment is 3.\nWe prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 1.\nThe reading instructions for BDA3 Chapter 2.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 2. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\nlibrary(markmyassignment)\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment2.yml\", sep=\"\")\nset_assignment(assignment_path)\nThe following installs the aaltobda package:\n#| cache: true\n# Caching should be fine here\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\n\n\n\n\n2 Inference for binomial proportion\nAlgae status is monitored in 274 sites at Finnish lakes and rivers. The observations for the 2008 algae status at each site are presented in the dataset algae in the aaltobda package (‘0’: no algae, ‘1’: algae present).\nLoading the library and the data.\n\nlibrary(aaltobda)\ndata(\"algae\")\n# The data are now stored in the variable `algae`.\n# These are the values for the prior required in the assignment\nprior_alpha = 2\nprior_beta = 10\n\nThe below data is only for the tests, you need to change to the full data algae when reporting your results.\nalgae_test &lt;- c(0, 1, 1, 0, 0, 0)\nLet \\(\\pi\\) be the probability of a monitoring site having detectable blue-green algae levels and \\(y\\) the observations in algae. Use a binomial model for the observations \\(y\\) and a \\(Beta(2,10)\\) prior for binomial model parameter \\(\\pi\\) to formulate a Bayesian model. Here it is not necessary to derive the posterior distribution for \\(\\pi\\) as it has already been done in the book and it suffices to refer to that derivation. Also, it is not necessary to write out the distributions; it is sufficient to use label-parameter format, e.g. \\(Beta(\\alpha,\\beta)\\).\nYour task is to perform Bayesian inference for a binomial model and answer questions based on it:\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nFormulate\n\nthe likelihood \\(p(y|\\pi)\\) as a function of \\(\\pi\\),\nthe prior \\(p(\\pi)\\), and\nthe resulting posterior \\(p(\\pi|y)\\).\n\nReport the posterior in the format \\(Beta(\\alpha,\\beta)\\), where you replace \\(\\alpha\\) and \\(\\beta\\) with the correct numerical values.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWith a conjugate prior, a closed-form posterior has Beta form (see equations in BDA3 and in the slides).\n\n\n\nWrite the likelihood, the prior and the posterior here!\n\n# These are not the actual values for the posterior!\n# You will have to compute those from the data!\nposterior_alpha = 2\nposterior_beta = 10\n\nYou can do string interpolation using R inline code execution in quarto as such:\n\\(\\alpha_\\text{prior}\\) is 2 and \\(\\beta_\\text{prior}\\) is 10. Or string interpolation within math: \\(Beta(2,10)\\)\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nWhat can you say about the value of the unknown \\(\\pi\\) according to the observations and your prior knowledge? Summarize your results with a point estimate (i.e. \\(E(\\pi|y)\\)) and a 90% posterior interval.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nPosterior intervals are also called credible intervals and are different from confidence intervals.\n\n\n\nKeep the below name and format for the functions to work with markmyassignment:\n# Useful function: qbeta()\n\nbeta_point_est &lt;- function(prior_alpha, prior_beta, data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above,\n    # combined with the prior provided above.\n    0.2222222\n}\nbeta_interval &lt;- function(prior_alpha, prior_beta, data, prob=0.9) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above,\n    # combined with the prior provided above.\n    c(0.0846451, 0.3956414)\n}\n\n\n\n\n\n\nSubtask 2.c)\n\n\n\nWhat is the probability that the proportion of monitoring sites with detectable algae levels \\(\\pi\\) is smaller than \\(\\pi_0=0.2\\) that is known from historical records?\n\n\nKeep the below name and format for the function to work with markmyassignment:\n# Useful function: pbeta()\n\nbeta_low &lt;- function(prior_alpha, prior_beta, data, pi_0=0.2) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above,\n    # combined with the correct prior.\n    0.4511238\n}\n\n\n\n\n\n\nSubtask 2.d)\n\n\n\nWhat assumptions are required in order to use this kind of a model with this type of data?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNo need to discuss exchangeability yet, as it is discussed in more detail in BDA3 Chapter 5 and Lecture 7.\n\n\n\nWrite your answer here!\n\n\n\n\n\n\nSubtask 2.e)\n\n\n\nMake prior sensitivity analysis by testing a couple of different reasonable priors and plot the different posteriors. Summarize the results by one or two sentences.\n\n\nPlot the PDFs here. Explain shortly what you do.\n# Useful function: dbeta()\n\n\n\n\n\n\nRubric\n\n\n\n\nIs source code included?\nAre the prior, likelihood and posterior forms in a) reported (derivation of posterior not necessary)?\n\nNo\nSome missing\nYes\n\nIs the reported resulting posterior correct ?\n\nIt is not reported, that the posterior distribution is a distribution.\nIt is reported, that the posterior distribution is , but the numerical values for the parameters are incorrect\nIt is reported, that the posterior distribution is , and the numerical values for the parameters are correct.\n\nIn part b), is there at least one point estimate reported. Sample based estimates are also OK. Points should be given if the method is right, even if the result is wrong due to a wrong posterior distribution being used. With the right posterior, mean, median, and mode are all approximately .\nFor the b) part, is the 90% posterior interval reported? Sample based estimate is also OK. Points should be given if the method is right, even if the result is wrong because the posterior was wrong in the first place. If the posterior was right, the 90% posterior interval is roughly .\nFor the c) part, is the posterior probability Pr(π&lt;0.2|y) reported? Points should be given if the method is right, even if the result is wrong because the posterior was wrong. If the posterior was right, the result should be approximately .\nFor the d) part, does the report discuss\n\nNo\nNo, but other reasonable assumptions are discussed\nYes, but not quite right or some missing\nYes\n\nFor the e) part, is there some comparison and discussion of results obtained with alternative prior parameters?\n\nNo\nYes, but the results and conclusions are clearly wrong\nYes\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\nmark_my_assignment()\n\n\n\n\n\n3 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Assignments",
      "Assignment 2, 2023"
    ]
  },
  {
    "objectID": "template1.html",
    "href": "template1.html",
    "title": "Assignment 1, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThe exercises of this assignment are meant to test whether or not you have sufficient knowledge to participate in the course. The first question checks that you remember basic terms of probability calculus. The second exercise checks your basic computer skills and guides you to learn some R functions. In the last three ones you will first write the math for solving the problems (you can, for example, write the equations in markdown or include a photo of hand written answers), and then implement the final equations in R (and then you can use markmyassignment to check your results). The last question checks that you have found the course book.\nThe maximum amount of points from this assignment is 3.\nWe prepared a quarto template specific to this assignment to help you get started. You can inspect this and future templates\n\nas a qmd file,\nas a rendered html file\nor as a rendered pdf file\n\nor you can download all template qmd files and some additional files at templates.zip (also available on Aalto JupyterHub under /coursedata).\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 1.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 1. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nlibrary(markmyassignment)\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment1.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\n\n\n\n\n\n2 Basic probability theory notation and terms\nThis can be trivial or you may need to refresh your memory on these concepts (see, e.g. Aalto course First Course in Probability and Statistics). Explain each of the following terms with one sentence:\n\nprobability\nprobability mass (function)\nprobability density (function)\nprobability distribution\ndiscrete probability distribution\ncontinuous probability distribution\ncumulative distribution function (cdf)\nlikelihood\n\n\n\n\n\n\n\nRubric\n\n\n\n\nHow is the answer?\n\nTotally wrong/has not tried\nSomething sensible written\nAll/almost all are correct (&gt;=70% correct)\n\n\n\n\n\n\n3 Basic computer skills\nThis task deals with elementary plotting and computing skills needed during the rest of the course. You can use either R or Python, although R is the recommended language in this course and we will only guarantee support in R. For documentation in R, just type ?{function name here}.\n\n\n\n\n\n\nSubtask 3.a)\n\n\n\nPlot the density function of the Beta-distribution, with mean \\(\\mu = 0.2\\) and variance \\(\\sigma^2=0.01\\). The parameters \\(\\alpha\\) and \\(\\beta\\) of the Beta-distribution are related to the mean and variance according to the following equations \\[\\begin{aligned}\n    \\alpha = \\mu \\left( \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1 \\right), \\quad\n    \\beta = \\frac{\\alpha (1-\\mu) }{\\mu} \\,.\\end{aligned}\\]\n\n\nPlot the PDF here. Explain in text what you do.\n\n# Useful functions: seq(), plot() and dbeta()\n\n\n\n\n\n\n\nSubtask 3.b)\n\n\n\nTake a sample of 1000 random numbers from the above distribution and plot a histogram of the results. Compare visually to the density function.\n\n\nSample and plot the histogram here. Explain in text what you do.\n\n# Useful functions: rbeta() and hist()\n\n\n\n\n\n\n\nSubtask 3.c)\n\n\n\nCompute the sample mean and variance from the drawn sample. Verify that they match (roughly) to the true mean and variance of the distribution.\n\n\nCompute the sample mean and variance here. Explain in text what you do.\n\n# Useful functions: mean() and var()\n\n\n\n\n\n\n\nSubtask 3.d)\n\n\n\nEstimate the central 95% probability interval of the distribution from the drawn sample.\n\n\nCompute the central interval here. Explain in text what you do.\n\n# Useful functions: quantile()\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code for the solutions included?\nDoes the plot in a) look something like this:\nDoes the plot in b) look something like this:\nIs the computed mean in c) close to ?\nIs the variance in c) close to ?\nIs the probability interval in d) roughly ? Remember that since the interval is computed from random sample, there can be small variation, but the answers should be roughly the same!\n\n\n\n\n\n\n\n\n\nFurther formatting recommendations\n\n\n\n\nPlease try to include as much code and output as needed, but as little as possible.\nPlease make sure that the plots are properly labeled and are easily legible and understandable. This means\n\nthey should have x- and y-labels,\nthe text within should be of a size comparable to the size of the surrounding text and\neach plot should have a concise but descriptive caption or title.\n\nPlease make sure to report a sensible number of digits when reporting numbers. You will get more precise instructions later on, but for now think independently about how many digits of your results are important for the assignment.\n\n\n\n\n\n4 Bayes’ theorem 1\nA group of researchers has designed a new inexpensive and painless test for detecting lung cancer. The test is intended to be an initial screening test for the population in general. A positive result (presence of lung cancer) from the test would be followed up immediately with medication, surgery or more extensive and expensive test. The researchers know from their studies the following facts:\n\nTest gives a positive result in \\(98\\%\\) of the time when the test subject has lung cancer.\nTest gives a negative result in \\(96\\%\\) of the time when the test subject does not have lung cancer.\nIn general population approximately one person in 1000 has lung cancer.\n\n\n\n\n\n\n\nSubtask 4.a)\n\n\n\nThe researchers are happy with these preliminary results (about \\(97\\%\\) success rate), and wish to get the test to market as soon as possible. How would you advise them? Base your answer on Bayes’ rule computations.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nRelatively high false negative (cancer doesn’t get detected) or high false positive (unnecessarily administer medication) rates are typically bad and undesirable in tests.\n\n\n\nCompute the quantities needed to justify your recommendation here. Explain in text what you do. You can do the computation with pen and paper or in R. Either way, you have to explain why you compute what you compute.\nIf you use pen and paper, you can include scans or pictures as follows (see also assignment_instructions#fig-workflow):\n\n\n\n\n\n\nFigure 1: Parts of Bayesian workflow\n\n\n\nSee Figure 1 for illustration of parts of Bayesian workflow.\nHere are some probability values that can help you figure out if you copied the right conditional probabilities from the question.\n\nP(Test gives positive | Subject does not have lung cancer) = \\(4\\%\\)\nP(Test gives positive and Subject has lung cancer) = \\(0.098\\%\\) this is also referred to as the joint probability of test being positive and the subject having lung cancer.\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs p(has cancer|test result is positive) computed using Bayes’ formula (or its complement p(does not have cancer|test result is positive))?\nIs the result p(has cancer|test result is positive)= (or p(does not have cancer|test result is positive)=)\nIs the result motivated with something like \n\n\n\n\n\n5 Bayes’ theorem 2\nWe have three boxes, A, B, and C. There are\n\n2 red balls and 5 white balls in the box A,\n4 red balls and 1 white ball in the box B, and\n1 red ball and 3 white balls in the box C.\n\nConsider a random experiment in which one of the boxes is randomly selected and from that box, one ball is randomly picked up. After observing the color of the ball it is replaced in the box it came from. Suppose also that on average box A is selected 40% of the time and box B \\(10\\%\\) of the time (i.e. \\(P(A) = 0.4\\)).\nYou will need to change the numbers to the numbers in the exercise.\n\nboxes_test &lt;- matrix(c(2,2,1,5,5,1), ncol = 2,\n    dimnames = list(c(\"A\", \"B\", \"C\"), c(\"red\", \"white\")))\n\n\n\n\n\n\n\nSubtask 5.a)\n\n\n\nWhat is the probability of picking a red ball? Implement an R function to compute that probability.\n\n\nKeep the below name and format for the function to work with markmyassignment:\n\np_red &lt;- function(boxes) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    0.3928571\n}\n\n\n\n\n\n\n\nSubtask 5.b)\n\n\n\nIf a red ball was picked, from which box did it most probably come from? Implement an R function to compute the probabilities for each box.\n\n\nKeep the below name and format for the function to work with markmyassignment:\n\np_box &lt;- function(boxes) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.29090909,0.07272727,0.63636364)\n}\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code available?\nHow is the answer for probability of picking a red ball?\n\nNo answer\nProbability rules\nProbability rules\n\nHow is the answer for what box is most probable?\n\nNo answer\nBayes rule used to compute probabilities for all boxes given that the picked ball is red, but the answers are not\nBayes rule used to compute probabilities for all boxes given that the picked ball is red, the answers are p\nBayes rule used to compute probabilities for all boxes given that the picked ball is red, the answers are\n\n\n\n\n\n\n6 Bayes’ theorem 3\nAssume that on average fraternal twins (two fertilized eggs and then could be of different sex) occur once in 150 births and identical twins (single egg divides into two separate embryos, so both have the same sex) once in 400 births (Note! This is not the true value, see Exercise 1.6, page 28, in BDA3). American male singer-actor Elvis Presley (1935 – 1977) had a twin brother who died in birth. Assume that an equal number of boys and girls are born on average.\n\n\n\n\n\n\nSubtask 6.a)\n\n\n\nWhat is the probability that Elvis was an identical twin? Show the steps how you derived the equations to compute that probability and implement a function in R that computes the probability.\n\n\nYou will need to change the numbers to the numbers in the exercise.\n\nfraternal_prob = 1/125\nidentical_prob = 1/300\n\nKeep the below name and format for the function to work with markmyassignment:\n\np_identical_twin &lt;- function(fraternal_prob, identical_prob) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    0.4545455\n}\n\n\n\n\n\n\n\nRubric\n\n\n\n\nHow is the answer for probability of Elvis having had an identical twin brother?\n\nNo answer\nProbability that Elvis had an identical twin brother is computed using Bayes rule, but the result is not roughly\nProbability that Elvis had an identical twin brother is computed using Bayes rule, and the result is roughly\n\n\n\n\n\n\n7 The three steps of Bayesian data analysis\n\n\n\n\n\n\nSubtask 7.a)\n\n\n\nFill in the three steps of Bayesian data analysis (see BDA3 section 1.1):\n\n\n\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nAre the three steps listed as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n8 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Templates",
      "Assignment 1, 2023"
    ]
  },
  {
    "objectID": "assignment9.html",
    "href": "assignment9.html",
    "title": "Assignment 9, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThe maximum amount of points from this assignment is 3.\nWe have prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nWe recommend Aalto students use jupyter.cs.aalto.fi, for all others we also provide a docker container.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 9 (decision analysis).\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\nInstalling and using CmdStanR:\nSee the Stan demos on how to use Stan in R (or Python). Aalto JupyterHub has working R and CmdStanR/RStan environment and is probably the easiest way to use Stan. * To use CmdStanR in Aalto JupyterHub: library(cmdstanr) set_cmdstan_path('/coursedata/cmdstan')\nThe Aalto Ubuntu desktops also have the necessary libraries installed.\nTo install Stan on your laptop, run ‘install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))’ in R. If you encounter problems, see additional answers in FAQ. For Aalto students, if you don’t succeed in short amount of time, it is probably easier to use Aalto JupyterHub.\nIf you use Aalto JupyterHub, all necessary packages have been pre-installed. In your laptop, install package cmdstanr. Installation instructions on Linux, Mac and Windows can be found at https://mc-stan.org/cmdstanr/. Additional useful packages are loo, bayesplot and posterior (but you don’t need these in this assignment). For Python users, PyStan, CmdStanPy, and ArviZ packages are useful.\nStan manual can be found at https://mc-stan.org/users/documentation/. From this website, you can also find a lot of other useful material about Stan.\nIf you edit files ending .stan in RStudio, you can click “Check” in the editor toolbar to make syntax check. This can significantly speed-up writing a working Stan model.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\nThis is the template for assignment 9. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following loads several needed packages:\n\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /u/77/ave/unix/.cmdstan/cmdstan-2.35.0-rc3\n\n\n- CmdStan version: 2.35.0\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(ggdist) # for stat_dotsinterval\nlibrary(posterior)\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\nlibrary(brms)\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.21.6). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following objects are masked from 'package:ggdist':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\n# Globally specfiy cmdstan backend for brms\noptions(brms.backend=\"cmdstanr\")\n# Tell brms to cache results if possible\noptions(brms.file_refit=\"on_change\")\n\n# Set more readable themes with bigger font for plotting packages\nggplot2::theme_set(theme_minimal(base_size = 14))\nbayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))\n\n\n\n\nThis exercise is an example of a decision analysis (DA). In a broad context, this means optimizing over different decisions that lead to different outcomes that all have different utilities. In a Bayesian context, this means using posterior distributions to make decisions.\n\n\n2 Escaping from the chicken coop\nYou are an adult chicken living in an organic chicken commune, where life is great, if a bit boring. You have settled in comfortably, but you want something more for your offspring. Your traveling corvid friends tell you of places where chickens eat corn all day, get ferried around in mobile chicken coops to see the world or get mental stimulation by being trained humanely to perform tricks. The chicken elders have gained access to the computers of your human caretakers and have found the results of a complicated statistical analysis of the growth curves of your relatives. Because you are a chicken, you don’t care about convergence diagnostics or priors.\nYour task is to maximizes the chance of escape for your offspring.\n\n\n\n\n\n\nSubtask 2.c\n\n\n\nCompute and visualize the expected chicken weight for days 1–40 per diet, according to the model provided in the template. Do the predictions look reasonable? Why/why not?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nTo sample a “new chicken” from the posterior, use posterior_predict with options newdata=..., allow_new_levels=TRUE, sample_new_levels=\"gaussian\", where you pass a dataframe as newdata which has a “new” chicken ID Chick and appropriate values for Time and Diet.\n\n\n\n\n\n\n\n\n\nA simple GP model\n\n\n\n\n\nThe below fits a GP model to the chicken growth curves. It may take a few minutes to fit, but you can also download the fit .rds-file and work with that fit object.\n\nfit &lt;- brm(\n  weight ~ gp(Time) + (0+Time|Diet) + (0+Time|Chick),\n  data = ChickWeight,\n  family = \"lognormal\",\n  file=\"additional_files/assignment9/gp_chicken_fit\",\n  cores = parallel::detectCores(),\n  # For the template only, remove the below from your code!\n  iter = 500\n)\n\nStart sampling\n\n\nRunning MCMC with 4 chains, at most 12 in parallel...\n\nChain 1 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 2 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 3 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 4 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 4 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 3 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 2 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 1 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 3 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 4 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 1 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 3 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 4 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 2 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 1 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 2 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 4 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 3 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 1 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 4 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 1 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 2 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 3 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 4 Iteration: 500 / 500 [100%]  (Sampling) \nChain 4 finished in 17.0 seconds.\nChain 1 Iteration: 500 / 500 [100%]  (Sampling) \nChain 1 finished in 17.8 seconds.\nChain 3 Iteration: 500 / 500 [100%]  (Sampling) \nChain 3 finished in 18.2 seconds.\nChain 2 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 2 Iteration: 500 / 500 [100%]  (Sampling) \nChain 2 finished in 21.5 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 18.6 seconds.\nTotal execution time: 21.6 seconds.\n\n\nWarning: 84 of 1000 (8.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 746 of 1000 (75.0%) transitions hit the maximum treedepth limit of 10.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.35.0.9000 (Stan version 2.35.0)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following objects are masked from 'package:posterior':\n\n    ess_bulk, ess_tail\n\nbrms::pp_check(fit, type = \"intervals_grouped\", group = \"Diet\")\n\nUsing all posterior draws for ppc type 'intervals_grouped' by default.\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Useful r functions:\n#   rep(..., each=...), cbind, colMeans,\n#   posterior_predict(..., newdata=..., allow_new_levels=TRUE, sample_new_levels=\"gaussian\")\n#   ggplot, geom_line, aes(..., group=..., color=...)\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look right and is it readable? It should be quite close to the reference plot below:\nHas it been recognized that the prediction time ?\n\n\n\nYour chicken elders have been meticulously collecting data on what kind of characteristics have allowed previous chickens to escape. They have found out that both the age and the weight influence the (daily) probability of escape for a chicken:\n\nIf the chicken is too young, it is not yet mature enough to venture out into the world.\nIf the chicken is too old, it will not try to escape anymore.\nIf the chicken is small and has just the right size, it can try to squeze through a tiny crack in the fence.\nIf the chicken is big enough, it is strong enough to try to fly over the fence.\nNo matter the size, there is always a small residual probability that the chicken can escape.\n\nEvery day, chickens will try to escape if they are of the right age. Their daily escape probability \\(e(\\text{day}, \\text{weight})\\) is implemented in the daily_probability_of_escape(day, weight) function. The probability that a chicken with daily weights \\(w = (w_1,\\dots,w_N)\\) has not escaped after \\(i+1\\) days can be computed as follows: \\[\n  f_{i+1} = f_i \\, (1 - e(i, w_i))\n\\] The chickenwise_probability_of_escape(weights) computes the probability that a chicken has escaped after length(weights) days.\n\n\n\n\n\n\nChickenwise probability of escape function\n\n\n\n\n\n\nbump &lt;- function(x, loc=0, scale=1){\n  xi = (x - loc) / scale\n  ifelse(abs(xi) &lt; 1, exp(-1/(1-xi^2)), 0.)\n}\ndaily_probability_of_escape &lt;- function(day, weight){\n  # Expects a day and a weight and computes the daily probability of escape\n  bump(day, 30, 10) * (1e-2 + bump(weight, 200, 150)+bump(weight, 700, 150))\n}\nchickenwise_probability_of_escape &lt;- function(weights){\n  # Expects a vector of daily weights from day 1 to N and computes the probability of\n  # escape at the end of the time series\n  prob_of_failure = 1\n  for(day in 1:length(weights)){\n    prob_of_failure = prob_of_failure * (1-daily_probability_of_escape(day, weights[day]))\n  }\n  return(1 - prob_of_failure)\n}\n\n\n\n\n\ndays = 1:40\nweights = 1:900\nheatmap_matrix = outer(days,weights,daily_probability_of_escape)\nimage(days, weights, heatmap_matrix, xlab=\"day\", ylab=\"weight\", main=\"Daily probability of escape\")\n\n\n\n\n\n\n\nFigure 1: Daily probability of escape for a given day and weight\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.a\n\n\n\nCompute and visualize the distribution of the chickenwise probabilities of escape per diet, according to the model provided in the template.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can reuse the predictions you created in the previous subtask. Work with the draws to compute the chickenwise probability of escape first, and then take the expectation!\n\n\n\n\n# Useful r functions: chickenwise_probability_of_escape (see above)\n# rep(..., each=...), apply,\n# ggplot, stat_dotsinterval\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look right and is it readable? It should be quite close to the reference plot below:\n\n\n\n\n\n\n\n\n\nSubtask 2.b\n\n\n\nCompute the expected probability of escape for each diet. Why would it be wrong to compute the expected probability of escape by applying the chickenwise_probability_of_escape function in the template to the daily expected chicken weights per diet computed in subtask 2.a? How does the correctly calculated value compare to the incorrectly calculated value? Why is one higher than the other?\n\n\n\n# Useful r functions: chickenwise_probability_of_escape (see above)\n# apply, aggregate,\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the results look correct and have they been presented in a readable way? They should be roughly the first column below for the correct calculation and the second column below for the wrong calculation: [\n\ndiet chickenwise_loss meanwise_loss 1 0.55 0.83 2 0.57 0.67 3 0.50 0.10 4 0.52 0.15 ]{.content-hidden when-profile=“public”} * Has it been explained that the expected probability of escape depends on ? * Has it been explained that\n is lower because ?\n[AND/OR\nfor some diets the “incorrect” computation (meanwise_loss) is lower because the mean growth curve (used in the incorrect meanwise_loss) “by chance” passes through the region of low probability of escape, even though due to high within-population variation most chickens’ growth curve won’t pass through that region of low probability of escape?\n(Due to a slightly misleading public rubric, either of the above answers would be sufficient)]{.content-hidden when-profile=“public”}\n\n\n\n\n3 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Assignments",
      "Assignment 9, 2023"
    ]
  },
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "Assignment 3, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 3 and BDA3 Chapters 2 and 3. Use Frank Harrell’s recommendations on how to state results in Bayesian two group comparisons (and note that there is no point null hypothesis testing in this assignment).\nThe maximum amount of points from this assignment is 9.\nWe have prepared two quarto templates specific to this assignment to help you get started:\n\nA recommended template (html, qmd, pdf) which uses some additional packages, which however requires a bit more set-up work to run and\na simple template (html, qmd, pdf) which doesn’t use those additional packages and is therefore easier to get to run.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 1.\nThe reading instructions for BDA3 Chapter 2.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 3. You can download qmd-files (full, simple) or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment3.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\n\n\n\n\n\n\n\n\n\nSetting up advanced packages (posterior and ggdist)\n\n\n\n\n\nThe following installs and loads the posterior package, which allows us to use its rvar Random Variable Datatype:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggdist package for advanced plotting functions:\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nggplot2::theme_set(theme_minimal(base_size = 14))\nif(!require(ggdist)){\n    install.packages(\"ggdist\")\n    library(ggdist)\n}\n\nLoading required package: ggdist\n\n\n\n\n\n\n\n2 Inference for normal mean and deviation (3 points)\nA factory has a production line for manufacturing car windshields. A sample of windshields has been taken for testing hardness. The observed hardness values \\(\\mathbf{y}_1\\) can be found in the dataset windshieldy1 in the aaltobda package.\nWe may assume that the observations follow a normal distribution with an unknown standard deviation \\(\\sigma\\). We wish to obtain information about the unknown average hardness \\(\\mu\\). For simplicity we assume standard uninformative prior discussed in the book, that is, \\(p(\\mu, \\sigma) \\propto \\sigma^{-1}\\). It is not necessary to derive the posterior distribution in the report, as it has already been done in the book (see section 3.2).\nLoading the library and the data.\n\ndata(\"windshieldy1\")\n# The data are now stored in the variable `windshieldy1`.\n# The below displays the data:\nwindshieldy1\n\n[1] 13.357 14.928 14.896 15.297 14.820 12.067 14.824 13.865 17.447\n\n\nThe below data is only for the tests, you need to change to the full data windshieldy1 when reporting your results.\n\nwindshieldy_test &lt;- c(13.357, 14.928, 14.896, 14.820)\n\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nFormulate\n\nthe likelihood,\nthe prior, and\nthe resulting posterior.\n\n\n\nWrite your answers here!\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nWhat can you say about the unknown \\(\\mu\\)?\n\nCompute and report the point estimate \\(E(\\mu|y)\\),\ncompute and report a posterior 95%-interval,\nplot the density, and\nwrite interpretation of the result in text.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nPosterior intervals are also called credible intervals and are different from confidence intervals.\n\n\n\nWrite your answers and code here!\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful functions: mean(), length(), sqrt(), sum()\n# and qtnew(), dtnew() (from aaltobda)\n\nmu_point_est &lt;- function(data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    14.5\n    ### {.content-hidden when-profile=\"public\"}\n    mean(data)\n    ###\n}\nmu_interval &lt;- function(data, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(13.3, 15.7)\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-location)^2)\n    )/n)\n    ql = (1-prob)/2\n    qu = prob + (1-prob)/2\n    qtnew(c(ql, qu), df, location, scale)\n    ###\n}\n\nYou can plot the density as below if you implement mu_pdf to compute the PDF of the posterior \\(p(\\mu|y)\\) of the average hardness \\(\\mu\\).\n\nmu_pdf &lt;- function(data, x){\n    # Compute necessary parameters here.\n    # These are the correct parameters for `windshieldy_test`\n    # with the provided uninformative prior.\n    df = 3\n    location = 14.5\n    scale = 0.3817557\n    # Use the computed parameters as below to compute the PDF:\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-location)^2)\n    )/n)\n    ###\n    dtnew(x, df, location, scale)\n}\n\nx_interval = mu_interval(windshieldy1, .999)\nlower_x = x_interval[1]\nupper_x = x_interval[2]\nx = seq(lower_x, upper_x, length.out=1000)\nplot(\n    x, mu_pdf(windshieldy1, x), type=\"l\",\n    xlab=TeX(r'(average hardness $\\mu$)'),\n    ylab=TeX(r'(PDF of the posterior $p(\\mu|y)$)')\n)\n\n\n\n\n\n\n\nFigure 1: PDF of the posterior \\(p(\\mu|y)\\) of the average hardness \\(\\mu\\)\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.c)\n\n\n\nWhat can you say about the hardness of the next windshield coming from the production line before actually measuring the hardness?\n\nCompute and report the point estimate \\(E(\\tilde{y}|y)\\),\ncompute and report a posterior predictive 95%-interval,\nplot the density, and\nwrite interpretation of the result in text.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nPredictive intervals are different from posterior intervals.\nWith a conjugate prior a closed form posterior is Student’s \\(t\\) form (see equations in the book).\n\n\n\nWrite your answers and code here!\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful functions: mean(), length(), sqrt(), sum()\n# and qtnew(), dtnew() (from aaltobda)\n\nmu_pred_point_est &lt;- function(data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    14.5\n    ### {.content-hidden when-profile=\"public\"}\n    mean(data)\n    ###\n}\nmu_pred_interval &lt;- function(data, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(11.8, 17.2)\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-location)^2)\n    )*(1+1/n))\n    ql = (1-prob)/2\n    qu = prob + (1-prob)/2\n    qtnew(c(ql, qu), df, location, scale)\n    ###\n}\n\nYou can plot the density as below if you implement mu_pred_pdf to compute the PDF of the posterior predictive \\(p(\\tilde{y}|y)\\) of a new hardness observation \\(\\tilde{y}\\).\n\nmu_pred_pdf &lt;- function(data, x){\n    # Compute necessary parameters here.\n    # These are the correct parameters for `windshieldy_test`\n    # with the provided uninformative prior.\n    df = 3\n    location = 14.5\n    scale = 0.8536316\n    # Use the computed parameters as below to compute the PDF:\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-mean(data))^2)\n    )*(1+1/n))\n    ###\n    dtnew(x, df, location, scale)\n}\n\nx_interval = mu_pred_interval(windshieldy1, .999)\nlower_x = x_interval[1]\nupper_x = x_interval[2]\nx = seq(lower_x, upper_x, length.out=1000)\nplot(\n    x, mu_pred_pdf(windshieldy1, x), type=\"l\",\n    xlab=TeX(r'(new hardness observation $\\tilde{y}$)'),\n    ylab=TeX(r'(PDF of the posterior predictive $p(\\tilde{y}|y)$)')\n)\n\n\n\n\n\n\n\nFigure 2: PDF of the posterior predictive \\(p(\\tilde{y}|y)\\) of a new hardness observation \\(\\tilde{y}\\)\n\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code included?\n\nNo\nYes\n\nAre the likelihood, prior and the posterior for computing the average hardness value reported? It is ok to refer to the book instead of deriving the distributions.\n\nNo\nYes, but some are missing\nYes\n\nIn part a), were the point estimates and posterior interval provided? (The posterior mean should be close to and 95% posterior interval should be around )\n\nNo\nYes, but seem incorrect or only one estimate was reported\nYes, and the reported values seem plausible\n\nIn part b), was the density plotted?\n\nNo\nYes, but seem incorrect\nYes, and the plot seems plausible\n\nFor b)-part, was a formula or a simulation method presented for computing the posterior predictive distribution? It is ok to refer to the book.\n\nNo\nYes, but seems incorrect\nYes\n\nFor c)-part, were the point estimate and predictive interval provided? (95% predictive interval should be around and the mean the same as in a)-part).\n\nNo\nYes, but seems incorrect\nYes, and the reported values seem plausible\n\nFor c)-part, was the density plotted?\n\nNo\nYes, but seems incorrect\nYes, and the plot seem plausible\n\n\n\n\n\n\n3 Inference for the difference between proportions (3 points)\nAn experiment was performed to estimate the effect of beta-blockers on mortality of cardiac patients. A group of patients was randomly assigned to treatment and control groups: out of 674 patients receiving the control, 39 died, and out of 680 receiving the treatment, 22 died. Assume that the outcomes are independent and binomially distributed, with probabilities of death of \\(p_0\\) and \\(p_1\\) under the control and treatment, respectively. Set up a noninformative or weakly informative prior distribution on \\((p_0,p_1)\\).\n\n\n\n\n\n\nSubtask 3.a)\n\n\n\nFormulate\n\nthe likelihood,\nthe prior, and\nthe resulting posterior.\n\n\n\nWrite your answers here!\n\n\n\n\n\n\nSubtask 3.b)\n\n\n\nSummarize the posterior distribution for the odds ratio, \\[\n\\mathrm{OR} = (p_1/(1-p_1))/(p_0/(1-p_0)).\n\\]\n\nCompute and report the point estimate \\(E(\\mathrm{OR}|y_0,y_1)\\),\ncompute and report a posterior 95%-interval,\nplot the histogram, and\nwrite interpretation of the result in text.\n\nUse Frank Harrell’s recommendations how to state results in Bayesian two group comparison.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWith a conjugate prior, a closed-form posterior is the Beta form for each group separately (see equations in the book). You can use rbeta() to sample from the posterior distributions of \\(p_0\\) and \\(p_1\\), and use this sample and odds ratio equation to get a sample from the distribution of the odds ratio.\n\n\n\nWrite your answers and code here!\nThe below data is only for the tests:\n\nset.seed(4711)\nndraws = 1000\np0 = rbeta(ndraws, 5, 95)\np1 = rbeta(ndraws, 10, 90)\n### {.content-hidden when-profile=\"public\"}\nset.seed(4711)\np0 = rbeta(ndraws, 40, 675)\np1 = rbeta(ndraws, 23, 681)\n###\n\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful function: mean(), quantile()\n\nposterior_odds_ratio_point_est &lt;- function(p0, p1) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    2.650172\n    ### {.content-hidden when-profile=\"public\"}\n    odds_ratios = p1/(1-p1)/(p0/(1-p0))\n    mean(odds_ratios)\n    ###\n}\nposterior_odds_ratio_interval &lt;- function(p0, p1, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.6796942,7.3015964)\n    ### {.content-hidden when-profile=\"public\"}\n    odds_ratios = p1/(1-p1)/(p0/(1-p0))\n    ql = (1-prob)/2\n    qu = prob + (1-prob)/2\n    quantile(odds_ratios, c(ql, qu))\n    ###\n}\n\n\n\n\n\n\n\nadvanced tools (posterior’s rvar, ggdist’s stat_dotsinterval)\n\n\n\n\n\nThe posterior package’s random variable datatype rvar is a “sample-based representation of random variables” which makes handling of random samples (of draws) such as the ones contained in the above variables p0 and p1 easier. By default, it prints as the mean and standard deviation of the draws, such that rvar(p0) prints as 0.056 ± 0.0086 and rvar(p1) prints as 0.033 ± 0.0066.\nThe datatype is “designed to […] be able to be used inside data.frame()s and tibble()s, and to be used with distribution visualizations in the ggdist package.” The code below sets up an R data.frame() with the draws in p0 and p1 wrapped in an rvar, and uses that data frame to visualize the draws using ggdist, an R package building on ggplot2 and “designed for both frequentist and Bayesian uncertainty visualization”.\nThe below plot, Figure 3 uses ggdist’s stat_dotsinterval(), which by default visualizes\n\nan rvar’s median and central 66% and 95% intervals using a black dot and lines of varying thicknesses as when using ggdist’s stat_pointinterval() and\nan rvar’s draws using grey dots as when using ggdist’s stat_dots():\n\n\nr0 = rvar(p0)\nr1 = rvar(p1)\nggplot(data.frame(\n    rv_name=c(\"control\", \"treatment\"), rv=c(r0, r1)\n)) +\n    aes(xdist=rv, y=rv_name) +\n    labs(x=\"probabilities of death\", y=\"patient group\") +\n    stat_dotsinterval()\n\n\n\n\n\n\n\nFigure 3: Probabilities of death for the two patient groups.\n\n\n\n\n\nrvars make it easy to compute functions of random variables, such as\n\ndifferences, e.g. \\(p_0 - p_1\\): r0 - r1 computes an rvar which prints as 0.023 ± 0.011, indicating the sample mean and the sample standard deviation of the difference of the probabilities of death,\nproducts, e.g. \\(p_0 \\, p_1\\): r0 * r1 computes an rvar which prints as 0.0018 ± 0.00048 which in this case has no great interpretation, or\nthe odds ratios needed in task 3.b).\n\nBelow, in Figure 4, we compute the odds ratios using the rvars and visualize its median, central intervals and draws, as above in Figure 3:\n\nrodds_ratio = (r1/(1-r1))/(r0/(1-r0))\nggplot(data.frame(\n    rv=c(rodds_ratio)\n)) +\n    aes(xdist=rv) +\n    labs(x=\"odds ratio\", y=\"relative amount of draws\") +\n    stat_dotsinterval()\n\n\n\n\n\n\n\nFigure 4: Odds ratios of the two patient groups.\n\n\n\n\n\nYou can use Figure 4 to visually check whether the answers you computed for 3.b) make sense.\n\n\n\n\n\n\n\n\n\nSubtask 3.c)\n\n\n\nUse at least two different priors, and discuss the sensitivity of your inference to your choice of prior density with a couple of sentences.\n\n\nWrite your answers and code here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code included?\n\nNo\nYes\n\nAre the likelihood, prior and the posterior for the death probabilities reported? It is ok to refer to the book instead of deriving the distributions.\n\nNo\nYes, but some are missing\nYes\n\nIn part a), was the simulation algorithm for computing the posterior of the odds ratio presented or implemented?\n\nNo\nYes, but seems incorrect\nYes\n\nIn part a), was the odds ratio summarized with a point estimate and a posterior interval? (The mean should be close to and 95% posterior interval approximately )\n\nNo\nYes, but results seem incorrect\nYes, and the results seem plausible\n\nIn part b), was some discussion about testing alternative priors provided? (For example, one could have repeated the computations in a)-part with a couple of alternative priors and reported these results or some related general conclusions briefly)\n\nNot at all\nSome analysis was provided but it was lacking or did not make sense\nSome alternative priors were tested and some sensible discussion provided\n\n\n\n\n\n\n4 Inference for the difference between normal means (3 points)\nConsider a case where the same factory has two production lines for manufacturing car windshields. Independent samples from the two production lines were tested for hardness. The hardness measurements for the two samples \\(\\mathbf{y}_1\\) and \\(\\mathbf{y}_2\\) be found in the datasets windshieldy1 and windshieldy2 in the aaltobda package.\nWe assume that the samples have unknown standard deviations \\(\\sigma_1\\) and \\(\\sigma_2\\). Use uninformative or weakly informative priors and answer the following questions:\nLoading the library and the data.\n\ndata(\"windshieldy2\")\n# The new data are now stored in the variable `windshieldy2`.\n# The below displays the first few rows of the new data:\nhead(windshieldy2)\n\n[1] 15.980 14.206 16.011 17.250 15.993 15.722\n\n\n\n\n\n\n\n\nSubtask 4.a)\n\n\n\nFormulate\n\nthe likelihood,\nthe prior, and\nthe resulting posterior.\n\n\n\nWrite your answers here!\n\n\n\n\n\n\nSubtask 4.b)\n\n\n\nWhat can you say about \\(\\mu_d = \\mu_1 - \\mu_2\\)?\n\nCompute and report the point estimate \\(E(\\mu_d|y_1, y_2)\\),\ncompute and report a posterior 95%-interval,\nplot the histogram, and\nwrite interpretation of the result in text.\n\nUse Frank Harrell’s recommendations how to state results in Bayesian two group comparison.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWith a conjugate prior, a closed-form posterior is Student’s \\(t\\) form for each group separately (see equations in the book). You can use the rtnew() function to sample from the posterior distributions of \\(\\mu_1\\) and \\(\\mu_2\\), and use this sample to get a sample from the distribution of the difference \\(\\mu_d = \\mu_1 - \\mu_2\\).\n\n\n\nWrite your answers and code here!\n\n# Useful functions: mean(), length(), sqrt(), sum(),\n# rtnew() (from aaltobda), quantile() and hist().\n\n\n\n\n\n\n\nSubtask 4.c)\n\n\n\nGiven this specific model, what is the probability that the means are exactly the same (\\(\\mu_1 = \\mu_2\\))? Explain your reasoning.\n\n\nWrite your answers here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs source code included?\n\nNo\nYes\n\nAre the likelihood, prior and the posterior for the windshield hardness values reported? (It is also ok to refer to the book or related formulas from exercise 1)\n\nNo\nYes, but some are missing\nYes\n\nIn part a), was the simulation algorithm for computing the difference in the means presented or implemented?\n\nNo\nYes, but seems to be incorrect\nYes\n\nIn part a), was the posterior for the difference between the means summarized with point and interval estimates? (The mean should be close to and 95% posterior interval or something close to it)\n\nNo answer\nYes, but results seem incorrect or only one estimate was given\nYes, and results seem reasonable\n\nWere some analysis or discussion provided for assessing whether the means could be the same?\n\nNo analysis or explanation is given\nYes, but the analysis or explanation seems incorrect\nYes, and the analysis or explanation seems plausible\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n5 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Assignments",
      "Assignment 3, 2023"
    ]
  },
  {
    "objectID": "template9.html",
    "href": "template9.html",
    "title": "Assignment 9, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThe maximum amount of points from this assignment is 3.\nWe have prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nWe recommend Aalto students use jupyter.cs.aalto.fi, for all others we also provide a docker container.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 9 (decision analysis).\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\nInstalling and using CmdStanR:\nSee the Stan demos on how to use Stan in R (or Python). Aalto JupyterHub has working R and CmdStanR/RStan environment and is probably the easiest way to use Stan. * To use CmdStanR in Aalto JupyterHub: library(cmdstanr) set_cmdstan_path('/coursedata/cmdstan')\nThe Aalto Ubuntu desktops also have the necessary libraries installed.\nTo install Stan on your laptop, run ‘install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))’ in R. If you encounter problems, see additional answers in FAQ. For Aalto students, if you don’t succeed in short amount of time, it is probably easier to use Aalto JupyterHub.\nIf you use Aalto JupyterHub, all necessary packages have been pre-installed. In your laptop, install package cmdstanr. Installation instructions on Linux, Mac and Windows can be found at https://mc-stan.org/cmdstanr/. Additional useful packages are loo, bayesplot and posterior (but you don’t need these in this assignment). For Python users, PyStan, CmdStanPy, and ArviZ packages are useful.\nStan manual can be found at https://mc-stan.org/users/documentation/. From this website, you can also find a lot of other useful material about Stan.\nIf you edit files ending .stan in RStudio, you can click “Check” in the editor toolbar to make syntax check. This can significantly speed-up writing a working Stan model.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\nThis is the template for assignment 9. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following loads several needed packages:\n\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /u/77/ave/unix/.cmdstan/cmdstan-2.35.0-rc3\n\n\n- CmdStan version: 2.35.0\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(ggdist) # for stat_dotsinterval\nlibrary(posterior)\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\nlibrary(brms)\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.21.6). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following objects are masked from 'package:ggdist':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\n# Globally specfiy cmdstan backend for brms\noptions(brms.backend=\"cmdstanr\")\n# Tell brms to cache results if possible\noptions(brms.file_refit=\"on_change\")\n\n# Set more readable themes with bigger font for plotting packages\nggplot2::theme_set(theme_minimal(base_size = 14))\nbayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))\n\n\n\n\nThis exercise is an example of a decision analysis (DA). In a broad context, this means optimizing over different decisions that lead to different outcomes that all have different utilities. In a Bayesian context, this means using posterior distributions to make decisions.\n\n\n2 Escaping from the chicken coop\nYou are an adult chicken living in an organic chicken commune, where life is great, if a bit boring. You have settled in comfortably, but you want something more for your offspring. Your traveling corvid friends tell you of places where chickens eat corn all day, get ferried around in mobile chicken coops to see the world or get mental stimulation by being trained humanely to perform tricks. The chicken elders have gained access to the computers of your human caretakers and have found the results of a complicated statistical analysis of the growth curves of your relatives. Because you are a chicken, you don’t care about convergence diagnostics or priors.\nYour task is to maximizes the chance of escape for your offspring.\n\n\n\n\n\n\nSubtask 2.c\n\n\n\nCompute and visualize the expected chicken weight for days 1–40 per diet, according to the model provided in the template. Do the predictions look reasonable? Why/why not?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nTo sample a “new chicken” from the posterior, use posterior_predict with options newdata=..., allow_new_levels=TRUE, sample_new_levels=\"gaussian\", where you pass a dataframe as newdata which has a “new” chicken ID Chick and appropriate values for Time and Diet.\n\n\n\n\n\n\n\n\n\nA simple GP model\n\n\n\n\n\nThe below fits a GP model to the chicken growth curves. It may take a few minutes to fit, but you can also download the fit .rds-file and work with that fit object.\n\nfit &lt;- brm(\n  weight ~ gp(Time) + (0+Time|Diet) + (0+Time|Chick),\n  data = ChickWeight,\n  family = \"lognormal\",\n  file=\"additional_files/assignment9/gp_chicken_fit\",\n  cores = parallel::detectCores(),\n  # For the template only, remove the below from your code!\n  iter = 500\n)\n\nStart sampling\n\n\nRunning MCMC with 4 chains, at most 12 in parallel...\n\nChain 1 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 2 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 3 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 4 Iteration:   1 / 500 [  0%]  (Warmup) \nChain 2 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 4 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 3 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 1 Iteration: 100 / 500 [ 20%]  (Warmup) \nChain 2 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 4 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 3 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 2 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 4 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 3 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 1 Iteration: 200 / 500 [ 40%]  (Warmup) \nChain 2 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 1 Iteration: 251 / 500 [ 50%]  (Sampling) \nChain 3 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 4 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 2 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 3 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 2 Iteration: 500 / 500 [100%]  (Sampling) \nChain 2 finished in 16.4 seconds.\nChain 4 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 3 Iteration: 500 / 500 [100%]  (Sampling) \nChain 1 Iteration: 350 / 500 [ 70%]  (Sampling) \nChain 3 finished in 16.8 seconds.\nChain 4 Iteration: 500 / 500 [100%]  (Sampling) \nChain 4 finished in 18.2 seconds.\nChain 1 Iteration: 450 / 500 [ 90%]  (Sampling) \nChain 1 Iteration: 500 / 500 [100%]  (Sampling) \nChain 1 finished in 21.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 18.3 seconds.\nTotal execution time: 21.9 seconds.\n\n\nWarning: 47 of 1000 (5.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 819 of 1000 (82.0%) transitions hit the maximum treedepth limit of 10.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.35.0.9000 (Stan version 2.35.0)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following objects are masked from 'package:posterior':\n\n    ess_bulk, ess_tail\n\nbrms::pp_check(fit, type = \"intervals_grouped\", group = \"Diet\")\n\nUsing all posterior draws for ppc type 'intervals_grouped' by default.\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Useful r functions:\n#   rep(..., each=...), cbind, colMeans,\n#   posterior_predict(..., newdata=..., allow_new_levels=TRUE, sample_new_levels=\"gaussian\")\n#   ggplot, geom_line, aes(..., group=..., color=...)\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look right and is it readable? It should be quite close to the reference plot below:\nHas it been recognized that the prediction time ?\n\n\n\nYour chicken elders have been meticulously collecting data on what kind of characteristics have allowed previous chickens to escape. They have found out that both the age and the weight influence the (daily) probability of escape for a chicken:\n\nIf the chicken is too young, it is not yet mature enough to venture out into the world.\nIf the chicken is too old, it will not try to escape anymore.\nIf the chicken is small and has just the right size, it can try to squeze through a tiny crack in the fence.\nIf the chicken is big enough, it is strong enough to try to fly over the fence.\nNo matter the size, there is always a small residual probability that the chicken can escape.\n\nEvery day, chickens will try to escape if they are of the right age. Their daily escape probability \\(e(\\text{day}, \\text{weight})\\) is implemented in the daily_probability_of_escape(day, weight) function. The probability that a chicken with daily weights \\(w = (w_1,\\dots,w_N)\\) has not escaped after \\(i+1\\) days can be computed as follows: \\[\n  f_{i+1} = f_i \\, (1 - e(i, w_i))\n\\] The chickenwise_probability_of_escape(weights) computes the probability that a chicken has escaped after length(weights) days.\n\n\n\n\n\n\nChickenwise probability of escape function\n\n\n\n\n\n\nbump &lt;- function(x, loc=0, scale=1){\n  xi = (x - loc) / scale\n  ifelse(abs(xi) &lt; 1, exp(-1/(1-xi^2)), 0.)\n}\ndaily_probability_of_escape &lt;- function(day, weight){\n  # Expects a day and a weight and computes the daily probability of escape\n  bump(day, 30, 10) * (1e-2 + bump(weight, 200, 150)+bump(weight, 700, 150))\n}\nchickenwise_probability_of_escape &lt;- function(weights){\n  # Expects a vector of daily weights from day 1 to N and computes the probability of\n  # escape at the end of the time series\n  prob_of_failure = 1\n  for(day in 1:length(weights)){\n    prob_of_failure = prob_of_failure * (1-daily_probability_of_escape(day, weights[day]))\n  }\n  return(1 - prob_of_failure)\n}\n\n\n\n\n\ndays = 1:40\nweights = 1:900\nheatmap_matrix = outer(days,weights,daily_probability_of_escape)\nimage(days, weights, heatmap_matrix, xlab=\"day\", ylab=\"weight\", main=\"Daily probability of escape\")\n\n\n\n\n\n\n\nFigure 1: Daily probability of escape for a given day and weight\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.a\n\n\n\nCompute and visualize the distribution of the chickenwise probabilities of escape per diet, according to the model provided in the template.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can reuse the predictions you created in the previous subtask. Work with the draws to compute the chickenwise probability of escape first, and then take the expectation!\n\n\n\n\n# Useful r functions: chickenwise_probability_of_escape (see above)\n# rep(..., each=...), apply,\n# ggplot, stat_dotsinterval\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look right and is it readable? It should be quite close to the reference plot below:\n\n\n\n\n\n\n\n\n\nSubtask 2.b\n\n\n\nCompute the expected probability of escape for each diet. Why would it be wrong to compute the expected probability of escape by applying the chickenwise_probability_of_escape function in the template to the daily expected chicken weights per diet computed in subtask 2.a? How does the correctly calculated value compare to the incorrectly calculated value? Why is one higher than the other?\n\n\n\n# Useful r functions: chickenwise_probability_of_escape (see above)\n# apply, aggregate,\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the results look correct and have they been presented in a readable way? They should be roughly the first column below for the correct calculation and the second column below for the wrong calculation: [\n\ndiet chickenwise_loss meanwise_loss 1 0.55 0.83 2 0.57 0.67 3 0.50 0.10 4 0.52 0.15 ]{.content-hidden when-profile=“public”} * Has it been explained that the expected probability of escape depends on ? * Has it been explained that\n?\n[AND/OR\nfor some diets the “incorrect” computation (meanwise_loss) is lower because the mean growth curve (used in the incorrect meanwise_loss) “by chance” passes through the region of low probability of escape, even though due to high within-population variation most chickens’ growth curve won’t pass through that region of low probability of escape?\n(Due to a slightly misleading public rubric, either of the above answers would be sufficient)]{.content-hidden when-profile=“public”}\n\n\n\n\n3 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Templates",
      "Assignment 9, 2023"
    ]
  },
  {
    "objectID": "template7.html",
    "href": "template7.html",
    "title": "Assignment 7, 2023",
    "section": "",
    "text": "Warning\n\n\n\nCurrently, rendering on github is broken, such that the rendered template at https://avehtari.github.io/BDA_course_Aalto/assignments/template7.html looks weird. Rendering should however work on Aalto’s JupyterLab, but we will also try to fix rendering on github ASAP.",
    "crumbs": [
      "Templates",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "template7.html#choosing-a-weakly-informative-prior-by-intuition",
    "href": "template7.html#choosing-a-weakly-informative-prior-by-intuition",
    "title": "Assignment 7, 2023",
    "section": "2.1 Choosing a weakly informative prior by intuition",
    "text": "2.1 Choosing a weakly informative prior by intuition\nWe will first guide you through two processes for choosing weakly informative priors which you can use in your projects as well (though, if expert knowledge is present, we encourage to use that though instead). Many definitions of weak exist, but for our purposes, we intend to set priors in this assignment which don’t overwhelm the likelihood contributions to the posterior while still exerting some amount of regularisation.\nIn the absence of additional information, we will assume that chick weights at 12 days of age (\\(w\\)) follow a normal distribution: \\[\nw\\sim\\mathcal N (\\mu,\\sigma).\n\\] Our task will be to define weakly informative priors for the mean \\(\\mu\\) given observation model standard deviation, \\(\\sigma\\) (a prior distribution for \\(\\sigma\\) will be set in after section 2).\nHere, \\(\\mu\\) represents the population mean chick weight at 12 days and \\(\\sigma\\) represents the standard-deviation of the chick weights \\(w\\) around that population mean. For this exercise, we will be specifying a normal prior for \\(\\mu\\):\n\\[\n\\mu\\sim\\mathcal N (\\mu_0,\\sigma_0).\n\\]\n\\(\\mu_0\\) represents our prior knowledge of what we believe the population weight to be and \\(\\sigma_0\\) represents our level of certainty in this belief. To specify a weakly-informative prior for \\(\\mu\\) we need to select values of \\(\\mu_0\\) and \\(\\sigma_0\\) that imply the range of plausible values that \\(\\mu\\) could take.\nWe can do this by our own intuitive prior knowledge (if such intuition exists), or by searching for external references.\nDespite the name, weakly informed priors can be quite subjective (see for more theoretical discussion here), such that some justification is always needed. For the subtasks below, you will not be graded on the accuracy or precision of your numbers, but on your justification of them. The numerical choices you make should make sense and be understandable to an external reviewer of your work (even if they may not agree with your choices).\n\n\n\n\n\n\nA word of caution on eliciting the priors below\n\n\n\n\n\nPlease note that in the below, we intend to set a prior on \\(\\mu\\) (the mean chick weight), but the intuition we ilicit is based on the weight of individual chicks. We do so to help create intuition about what the mean could be, however, it would be theoretically more accurate to ilicit priors about mean chick weights.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWe have made changes to the assignment text and some of the rubrics to make it clearer.\n\n\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nBased on your own past experience and estimation skills, what would you guess is a typical weight range of a fully grown chicken in grams? Justify your choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWould it make sense if a chicken weighed 1 million grams? 0.005 grams? What about a chicken that weighed more than you? More than a car? Note that is not important to have a very precise or accurate guess here, the key goal is simply to identify the range of plausible (or at least possible) values.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.1 Fully grown chicken weight range by intuition\n\nDoes the chosen range meet the following common sense criteria?\n\nThe range is always above .\n\nIs the justification based on some sort of logic, even if you may disagree?\n\n\n\n\n\n\n\n\n\nSubtask 2.b\n\n\n\nAdjust this range for a 12-day old chick and choose a mean \\(\\mu_0\\) for the weakly informed prior of the parameter \\(\\mu.\\) Justify your adjustment and choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.2 12-day old chick weight range by intuition\n\nThe range is always above .\nIs the justification based on some sort of logic, even if you may disagree?\n\n\n\nChoosing the prior standard deviation for \\(\\mu\\) requires a little more caution; overconfident (i.e. narrow) priors can have a strong effect on your results, whereas less confident priors are more easily overcome with observed data. Given that overconfidence is a common human bias, a good intuition-based standard deviation should focus on eliminating the impossible values, rather than including the most likely values.\n\n\n\n\n\n\nSubtask 2.c\n\n\n\nChoose a conservative lower and upper bound for the weight of any 12-day old chick, with the goal to exclude impossible values. Justify your choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDepending on your choice of range above for a “typical” chick, this range excluding the impossible values should be wider.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.3 Prior standard deviation by intuition\n\nDoes the chosen range meet the following common sense criteria?\n\nThe range is always above .\n\nIs the justification based on some sort of logic, even if you may disagree?\n\n\n\nA common technique to find a weakly informative prior is to have a standard deviation which is an order of magnitude (a factor of 10) larger than a plausible standard deviation of the data.\n\n\n\n\n\n\nSubtask 2.d\n\n\n\nWhat do you think is a plausible standard deviation \\(\\sigma_\\text{plausible}\\) of the weight of 12 days-old chicks, based on your ranges stated above? Under the above recommendation, what standard deviation \\(\\sigma_0\\) should you use for your prior for the mean weight \\(\\mu\\)?\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.3.1 Prior standard deviation by intuition\n\nDo the two standard deviations meet the following common sense criteria?\n\nBoth values are\n\nGiven the choice of mean from above, the interval \\((\\mu_0 - 3\\sigma_0, \\mu_0 + 3\\sigma_0)\\) includes .\n\n\n\n\n\n\n\n\n\nSubtask 2.e\n\n\n\nWrite down in mathematical form the final prior for the mean weight \\(\\mu\\) you found using this prior definition technique.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.1.4 Prior by intuition\n\nDoes the final prior exist in mathematical notation?\nDoes the prior reflect the choices made above (i.e. \\(\\mu_0, \\sigma_0\\))?",
    "crumbs": [
      "Templates",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "template7.html#choosing-a-weakly-informative-prior-using-external-references",
    "href": "template7.html#choosing-a-weakly-informative-prior-using-external-references",
    "title": "Assignment 7, 2023",
    "section": "2.2 Choosing a weakly informative prior using external references",
    "text": "2.2 Choosing a weakly informative prior using external references\nNext, we’ll use external references to pick the weakly informed prior. This technique is more general and doesn’t assume you would have prior knowledge.\n\n\n\n\n\n\nSubtask 2.f\n\n\n\nConsult a trustworthy source on the weight range of farm chickens, e.g. books, articles, a farmer friend. If the recommended values are for a fully grown chicken, make a reasonable adjustment for a 12-day old chick. What is the weight range of a 12-day old chicken? Cite your source and justify any adjustments you make to the reference range.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.1 Weight range by reference\n\nDoes the reference range meet the following common sense criteria?\n\nThe range is always above .\n\nIs there a citation? If an adjustment was made, was it justified by logic, even if you disagree?\n\n\n\n\n\n\n\n\n\nSubtask 2.g\n\n\n\nBased on this reference range, what will you choose for the mean of our weakly informed prior? Justify your choice with 1-3 sentences.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.2 Weight range by reference\n\nDoes the mean value meet the following common sense criteria?\n\nThe range is always above .\n\n\n\n\nNext we choose the standard deviation of the prior. We could use the same technique as before, but we’ll walk you through another common approach. Assume that \\(99.7\\%\\) of all 12-day old chicks fall into the reference range you found. Under our assumption of a normal distribution, this range will encompass values between \\(\\mu_0 \\pm 3\\sigma_0\\).\n\n\n\n\n\n\nSubtask 2.h\n\n\n\nAssuming symmetry, use the mean you chose and either the upper or lower bound \\(b\\) of your reference range to solve the correct version of the following equations to find your associated choice of \\(\\sigma_0\\): (show your work)\n\nFor upper bound \\(b_u\\): \\(Pr(\\mu_0 + 3\\sigma_0 &lt; b_u) \\approx 0.997\\), solving for \\(\\sigma_0\\).\nFor lower bound \\(b_l\\): \\(Pr(\\mu_0 - 3\\sigma_0 &gt; b_l) \\approx 0.997\\), solving for \\(\\sigma_0\\).\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.3 Prior standard deviation by reference\n\nDoes the calculated \\(\\sigma_0\\) value meet the following common sense criteria?\n\nThe value is above .\n\nDid they show their work?\n\n\n\n\n\n\n\n\n\nSubtask 2.i\n\n\n\nWrite down in mathematical form the final prior for the mean weight \\(\\mu\\) you found using this prior definition technique.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.2.4 Prior by reference\n\nDoes the final prior exist in mathematical notation?\nDoes the prior reflect the choices made above (i.e. \\(\\mu_0, \\sigma_0\\))?",
    "crumbs": [
      "Templates",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "template7.html#non-normal-priors",
    "href": "template7.html#non-normal-priors",
    "title": "Assignment 7, 2023",
    "section": "2.3 Non-normal priors",
    "text": "2.3 Non-normal priors\nThe previous steps all assumed we could use a prior which is normally distributed, but this may not always be the correct assumption to make.\n\n\n\n\n\n\nSubtask 2.j\n\n\n\nUnder what mathematical/statistical circumstances would a normal distributed prior not make sense? List at least one circumstance. Are there values that the normal distribution can take on which would not make sense for some types of variables?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nConsider the nature of any variable you are trying to define a prior over.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.3.1 Non-normal priors\n\nExample cases include variables that",
    "crumbs": [
      "Templates",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "template7.html#modeling-diet-effects-on-chicken-weight",
    "href": "template7.html#modeling-diet-effects-on-chicken-weight",
    "title": "Assignment 7, 2023",
    "section": "2.4 Modeling diet effects on chicken weight",
    "text": "2.4 Modeling diet effects on chicken weight\nIn addition to chick weights, the data also contains a categorical variable indicating which diet the chick received. In the data file, each column contains the measurements for a single chick at a given point of time.\nIn addition to the existing diets, we are interested in the quality of another box of feed (the fifth diet), which a farmer happened to find yesterday at a dark corner of his warehouse. To read in the data and select chicks with age of 12 days, and to have a peek at the first 6 rows, just use:\n\n\n\n\n\n\nData inside, don’t peek before you have set your priors!\n\n\n\n\n\n\n\n\n\n\n\nHave you set your priors?\n\n\n\n\n\n\ndata(\"ChickWeight\")\n\nChick12 &lt;- ChickWeight |&gt; filter(Time == 12)\n\nhead(Chick12)\n\nGrouped Data: weight ~ Time | Chick\n  weight Time Chick Diet\n1    106   12     1    1\n2    122   12     2    1\n3    115   12     3    1\n4    102   12     4    1\n5    141   12     5    1\n6    141   12     6    1\n\n\n\n\n\n\n\n\nIn the following analysis, we will model the weight of a chick at the age of 12 days. We will use the following three Gaussian models:\n\na separate model, in which each diet is modeled individually\na pooled model, in which all measurements are combined and there is no distinction between diets\na hierarchical model, which has a hierarchical structure as described in BDA3 Section 11.6\n\nAs in the model described in the book, use the same weight standard deviation \\(\\sigma\\) for all the groups in the hierarchical model. In the separate model, however, use separate weight standard deviation \\(\\sigma_d\\) for each diet \\(d\\). You should use weakly informative priors for all your models.\nThe provided Stan code below is given as an example of a separate model. Note that the author has left a comment expressing uncertainty about their prior choices. This separate model can be summarized mathematically as \\[\n\\begin{aligned}\n    \\mu_{d} &\\sim \\pi(\\mu_d)&&\\text{(diet-wise mean weight),}\\\\\n    \\sigma_d &\\sim \\pi(\\sigma_d)&&\\text{(diet-wise standard deviation of diet-wise chicken weights)},\\\\\n    w_{i,d} &\\sim N(\\mu_d,\\sigma_d)&&\\text{(diet-wise chicken weights)}\\\\\n\\end{aligned}\n\\tag{1}\\]\nwith priors\n\\[\n\\begin{aligned}\n    \\mu_{d} &\\sim N(0,10)&&\\text{(adjust this) and}\\\\\n    \\sigma_d &\\sim\\mathrm{exponential}(.02)&&\\text{(you can keep this).}\n\\end{aligned}\n\\tag{2}\\]\nFor the separate and the pooled models, use one of the weakly informative priors you have derived in 2.1) or 2.2) for the diet-wise mean weights \\[\\mu_d\\sim \\pi(\\mu_d)=N(\\mu_0,\\sigma_0).\\] For the hierarchical model, remember that the parameters in the priors for the diet-wise mean weights itself have to be parameters with their own prior distributions, in our case \\[\n\\begin{aligned}\n\\mu_d &\\sim N(\\mu,\\tau)&&\\text{(diet-wise mean weights)},\\\\\n\\mu &\\sim \\pi(\\mu)&&\\text{(mean of prior for diet-wise mean weights) and}\\\\\n\\tau &\\sim \\pi(\\tau)&&\\text{(standard deviation of prior for diet-wise mean weights).}\n\\end{aligned}\n\\]\nUse the prior you have used for the diet-wise mean weights \\(\\mu_d\\) in the separate and pooled models for the prior on the mean of the prior for the diet-wise mean weights \\[\\mu \\sim \\pi(\\mu) = N(\\mu_0,\\sigma_0)\\] in the hierarchical model and use \\[\\tau \\sim \\pi(\\tau) = \\mathrm{exponential}(.02)\\] for the prior on the standard deviation of the prior for the diet-wise mean weights.\n\n\n\n\n\n\n\nSample from the posterior\n\n\n\n\n\nTo sample from the posterior using Stan, use:\n\nstan_data &lt;- list(\n  N_observations = nrow(Chick12),\n  N_diets = length(unique(Chick12$Diet)),\n  diet_idx = Chick12$Diet,\n  weight = Chick12$weight\n)\n\nmodel_separate &lt;- cmdstan_model(stan_file = \"additional_files/assignment7/chickens_separate.stan\")\n\n# Sampling from the posterior distribution happens here:\nfit_separate &lt;- model_separate$sample(data = stan_data, refresh=0,\n                                      show_messages=FALSE,\n                                      show_exceptions=FALSE)\n\nWarning: No chains finished successfully. Unable to retrieve the fit.\n\n\nFit objects returned by the sample() method, by default print a summary of the posterior draws. These are NOT the results you would expect to turn in your report. You will need to change the priors in the code for the separate model.\n\nfit_separate\n\nError: Fitting failed. Unable to print.\n\n\nQuick model convergence check (as in assignment 6):\n\nfit_separate$cmdstan_diagnose()\n\nError: No CmdStan runs finished successfully. Unable to run bin/diagnose.\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.k\n\n\n\nDescribe the models with mathematical notation (as is done for the separate model above). Also describe in words the difference between the model and the other models.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nAre the models described using mathematical notation and the difference to other models described in words?\n\nNo equations and no description\nDescription but no equations\nEquations but no description\nEquations and description\n\n\n\n\n\n\n\n\n\n\nSubtask 2.l\n\n\n\nImplement the models in Stan and include the code in the report. Use weakly informative priors for all of your models.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWhen sampling from the posterior of the hierarchical model, you will very likely get a warning about divergent transitions. This tells you that the sampler is having difficulties in sampling the joint posterior and this may lead to biased inference. We will return to this in the next task.\n\n\n\nFor the figures below, we use the earlier draws for the separate model with bad priors. When you have implemented the pooled and hierarchical models, edit the code below to include draws from your model posterior into the figures.\n\n\n\n\n\n\nData preparation and sampling from the posterior\n\n\n\n\n\n\nfit_pooled &lt;- fit_separate\nfit_hierarchical &lt;- fit_separate\n\nBelow, we collect the corresponding posterior draws from the three models into a shared data frame using the extract_variable function. This makes plotting the posterior in a single plot easier.\n\n# Expect the same number of posterior draws from each model.\nndraws &lt;- nrow(fit_hierarchical$sampler_diagnostics(format = \"matrix\"))\n\nError: No chains finished successfully. Unable to retrieve the sampler diagnostics.\n\n# Collect posterior draws and the model used to a data frame.\nmean_diet_4_separate = extract_variable(fit_separate, \"mean_diet[4]\")\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\nmean_diet_4_pooled = extract_variable(fit_pooled, \"mean_diet[4]\")\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\nmean_diet_4_hierarchical = extract_variable(fit_hierarchical, \"mean_diet[4]\")\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\nposterior_mean_diet_4 &lt;- data.frame(\n  model_name = rep(c(\"Separate\", \"Pooled\", \"Hierarchical\"),\n              each = ndraws),\n  mean_diet_4 = c(\n   mean_diet_4_separate, mean_diet_4_pooled, mean_diet_4_hierarchical\n  ))\n\nError in eval(expr, envir, enclos): object 'mean_diet_4_separate' not found\n\npredicted_weight_diet_4 &lt;- data.frame(\n  model_name = rep(c(\"Separate\", \"Pooled\", \"Hierarchical\"),\n              each = ndraws),\n  predicted_weight = c(\n   extract_variable(fit_separate, \"weight_pred\"),\n   extract_variable(fit_pooled, \"weight_pred\"),\n   extract_variable(fit_hierarchical, \"weight_pred\")\n  ))\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\n# Collect posterior draws and the model used to a long data frame.\nposterior_mean_diet_5 &lt;- data.frame(\n  model_name = rep(c(\"Separate\", \"Pooled\", \"Hierarchical\"),\n    each = ndraws\n  ),\n  mean_diet_5 = c(\n    extract_variable(fit_separate, \"mean_five\"),\n    extract_variable(fit_pooled, \"mean_five\"),\n    extract_variable(fit_hierarchical, \"mean_five\")\n  )\n)\n\nError: No chains finished successfully. Unable to retrieve the draws.\n\n# Mean observed weight per diet, these help to compare the posteriors to data.\ndiet_means &lt;- sapply(\n  1:4, function(diet) mean(Chick12[Chick12$Diet == diet, \"weight\"])\n)\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n2.4.1 All models\n\nIs there a related Stan implementation?\n\nNo Stan model implemented\nStan model implemented, but it seems clearly wrong or broken\nSeemingly valid Stan model implemented\n\n\n\n\n\n\n\n\n\n\nSubtask 2.m\n\n\n\nUse the provided code in the template to plot the posterior distribution of the mean of the weight measurements of the fourth diet and comment on the possible differences you observe between the models.\n\n\n\nggplot(posterior_mean_diet_4, aes(x = mean_diet_4, y = model_name)) +\n  stat_dotsinterval(quantiles = 100, scale = .9) +\n  vline_at(diet_means[4], size = 1, linetype = \"dashed\") +\n  # Annotate the vline from above.\n  annotate(\"text\", label = \"Observation mean\", x = diet_means[4] - 5, y = .7,\n           hjust = \"right\", size = 6) +\n  # Add title and axis labels. One line to make everything so much more clear!\n  labs(\n    title = \"Mean of diet 4\",\n    x = \"Weight (g)\",\n    y = \"Model\"\n  )\n\nError in eval(expr, envir, enclos): object 'posterior_mean_diet_4' not found\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs there a comparison plotted for the posteriors of the mean of diet 4? Does it look something like the model solution plot?\n\nNo comparison plotted\nComparison plotted but it clearly differs from the example\nComparison plotted and it approximately matches the example\n\nSeparate model: Is the result for the separate model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the separate model is recognised as .\n\nPooled model: Is the result for the pooled model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the pooled model is recognised as .\n\nHierarchical model: Is the result for the hierarchical model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the hierarchical model is recognised as .\n\n\n\n\n\n\n\n\n\n\nSubtask 2.n\n\n\n\nUse the provided code in the template to plot the predictive distribution for another weight measurement from a chick having the fourth diet and comment on the possible differences you observe between the models.\n\n\n\nggplot(predicted_weight_diet_4, aes(x = predicted_weight, y = model_name)) +\n  stat_dotsinterval(quantiles = 100, scale = .9) +\n  vline_at(diet_means[4], size = 1, linetype = \"dashed\") +\n  # Annotate the vline from above.\n  annotate(\"text\", label = \"Observation mean\", x = diet_means[4] - 5, y = .7,\n           hjust = \"right\", size = 6) +\n  # Add title and axis labels. One line to make everything so much more clear!\n  labs(\n    title = \"Weigth of a chick with diet 4\",\n    x = \"Weight (g)\",\n    y = \"Model\"\n  )\n\nError in eval(expr, envir, enclos): object 'predicted_weight_diet_4' not found\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs there a comparison plotted for the predictive distributions of the weight of a chick with diet 4? Does it look something like the model solution plot?\n\nNo comparison plotted\nComparison plotted but it clearly differs from the example\nComparison plotted and it approximately matches the example\n\nSeparate model: Is the result for the separate model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the separate model is recognised as .\n\nPooled model: Is the result for the pooled model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the pooled model is recognised as .\n\nHierarchical model: Is the result for the hierarchical model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the hierarchical model is recognised as .\n\n\n\n\n\n\n\n\n\n\nSubtask 2.o\n\n\n\nUse the provided code in the template to plot the posterior distribution of the mean of the weight measurements of a new fifth diet and comment on the possible differences you observe between the models.\n\n\n\nggplot(posterior_mean_diet_5, aes(x = mean_diet_5, y = model_name)) +\n  # Draw the mean of each diet from the data as a dashed vertical line.\n  vline_at(diet_means, size = .5, linetype = \"dashed\") +\n  # dotsinterval gives mean, 50%, and 90% intervals + dotsplot with each dot\n  # representing 1% of data (quantiles = 100).\n  stat_dotsinterval(quantiles = 100, scale = .9) +\n  # Annotate the vline from above.\n  annotate(geom = \"text\", label = \"Means of observed diets\", y = .7, x = 100,\n           hjust = \"right\", size = 5, family = \"sans\") +\n  # Add title and axis labels. One line to make everything so much more clear!\n  labs(title = \"Mean of a new diet\",\n       x = \"Weight (g)\",\n       y = \"Model\")\n\nError in eval(expr, envir, enclos): object 'posterior_mean_diet_5' not found\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs there a comparison plotted for the posterior distributions of the mean weight with a new diet? Does it look something like the model solution plot?\n\nNo comparison plotted\nComparison plotted but it clearly differs from the example\nComparison plotted and it approximately matches the example\n\nSeparate model: Is the result for the separate model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the separate model is recognised as .\nIn addition to the previous option, it is recognised that .\n\nPooled model: Is the result for the pooled model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the pooled model is recognised as .\nIn addition to the previous option, it is mentioned that .\n\nHierarchical model: Is the result for the hierarchical model discussed?\n\nThe result is not discussed.\nThere is some discussion, but it is not mentioned that .\nThe result is discussed and the hierarchical model is recognised as .\n\n\n\n\n\n\n\n\n\n\nSubtask 2.p\n\n\n\nFor each model, report the posterior expectation for the mean weight of diet 4 with a 90% credible interval.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSee the example Stan codes in the demo Bayesian data analysis - CmdStanR demos: Comparison of \\(k\\) groups with hierarchical models for the comparison of \\(k\\) groups with and without the hierarchical structure.\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nFor the separate model, is the posterior 90% credible interval for the mean of the fourth diet close to: (small/medium deviation is fine).\n\nNo or incorrect answer\nAnswer is only partially correct\nAnswers look correct\n\nFor the pooled model, is the posterior 90% credible interval for the mean of the fourth diet close to: (small/medium deviation is fine).\n\nNo answer\nAnswer is only partially correct\nAnswer looks correct\n\nFor the hierarchical model, is the posterior 90% credible interval for the mean of the fourth diet close to: (small/medium deviation is fine).\n\nNo answer\nAnswer is only partially correct.\nAnswers look correct.",
    "crumbs": [
      "Templates",
      "Assignment 7, 2023"
    ]
  },
  {
    "objectID": "assignment6.html",
    "href": "assignment6.html",
    "title": "Assignment 6, 2023",
    "section": "",
    "text": "1 General information\nThe maximum amount of points from this assignment is 6.\nThis is for BDA 2023\nWe have prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nWe recommend Aalto students use jupyter.cs.aalto.fi, for all others we also provide a docker container.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 10.\nThe reading instructions for BDA3 Chapter 11.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\nInstalling and using CmdStanR:\nSee the Stan demos on how to use Stan in R (or Python). Aalto JupyterHub has working R and CmdStanR/RStan environment and is probably the easiest way to use Stan. * To use CmdStanR in Aalto JupyterHub: library(cmdstanr) set_cmdstan_path('/coursedata/cmdstan')\nThe Aalto Ubuntu desktops also have the necessary libraries installed.\nTo install Stan on your laptop, run ‘install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))’ in R. If you encounter problems, see additional answers in FAQ. For Aalto students, if you don’t succeed in short amount of time, it is probably easier to use Aalto JupyterHub.\nIf you use Aalto JupyterHub, all necessary packages have been pre-installed. In your laptop, install package cmdstanr. Installation instructions on Linux, Mac and Windows can be found at https://mc-stan.org/cmdstanr/. Additional useful packages are loo, bayesplot and posterior (but you don’t need these in this assignment). For Python users, PyStan, CmdStanPy, and ArviZ packages are useful.\nStan manual can be found at https://mc-stan.org/users/documentation/. From this website, you can also find a lot of other useful material about Stan.\nIf you edit files ending .stan in RStudio, you can click “Check” in the editor toolbar to make syntax check. This can significantly speed-up writing a working Stan model.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\nThis is the template for assignment 6. You can download the broken stan-file and the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nJupyterHub has all the needed packages pre-installed.\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\nThe following installs and loads the posterior package which imports the rhat_basic() function:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggplot2 package, the bayesplot package and the dplyr package\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nif(!require(bayesplot)){\n    install.packages(\"bayesplot\")\n    library(bayesplot)\n}\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:posterior':\n\n    rhat\n\nif(!require(dplyr)){\n    install.packages(\"dplyr\")\n    library(dplyr)\n}\n\nLoading required package: dplyr\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nif(!require(tidyr)){\n    install.packages(\"tidyr\")\n    library(tidyr)\n}\n\nLoading required package: tidyr\n\n# Some additional set-up to make plots legible\nggplot2::theme_set(theme_minimal(base_size = 14))\nbayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))\n# register_knitr_engine()\n\nThe following installs and loads the cmdstanr package and tries to install cmdstan.\n\nif(!require(cmdstanr)){\n    install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n    library(cmdstanr)\n}\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /u/77/ave/unix/.cmdstan/cmdstan-2.35.0-rc3\n\n\n- CmdStan version: 2.35.0\n\ncmdstan_installed &lt;- function(){\n  res &lt;- try(out &lt;- cmdstanr::cmdstan_path(), silent = TRUE)\n  !inherits(res, \"try-error\")\n}\nif(!cmdstan_installed()){\n    install_cmdstan()\n}\n\n\n\n\n\n\n2 Stan warm-up: linear model of BDA retention with Stan (2 points)\nFrom 2018 to 2022, we have been keeping track of assignment submissions for the BDA course given the number of submissions for the 1st assignment. We will fit a simple linear model to answer two questions of interest:\n\nWhat is the trend of student retention as measured by assignment submissions?\nGiven the submission rates for assignments 1–8, how many students will complete the final 9th assignment (and potentially pass the course)?\n\nThe author has given you the broken Stan code below, which they intend to encode the following linear model: \\[\n\\begin{aligned}\np(\\alpha,\\beta,\\sigma) &= \\mathrm{const.}\n      & \\text{(improper flat prior)}&\\text{ and}\\\\\np(y|x,\\alpha,\\beta,\\sigma) &= p_\\mathrm{normal}(y|\\alpha + \\beta x, \\sigma)\n      & \\text{(normal likelihood)} &\\text{.}\n\\end{aligned}\n\\] In both the statistical model above and in the Stan model below, \\(x \\in \\mathbb{R}^N\\) and \\(y \\in \\mathbb{R}^N\\) are vectors of the covariates / predictors (the assignment number) and vectors of the observation (proportions of students who have handed in the respective assignment). \\(\\alpha \\in \\mathbb{R}\\) is the unknown scalar intercept, \\(\\beta \\in \\mathbb{R}\\) is the unknown scalar slope and \\(\\sigma \\in \\mathbb{R}_{&gt;0}\\) is the unknown scalar observation standard deviation. The statistical model further implies \\[\np(y_\\mathrm{pred.}|x_\\mathrm{pred.},\\alpha,\\beta,\\sigma) = p_\\mathrm{normal}(y_\\mathrm{pred.}|\\alpha + \\beta x_\\mathrm{pred.}, \\sigma)\n\\] as the predictive distribution for a new observation \\(y_\\mathrm{pred.}\\) at a given new covariate value \\(x_\\mathrm{pred.}\\).\nYou can download the broken stan file from github.\n1data {\n    // number of data points\n    int&lt;lower=0&gt; N;\n    // covariate / predictor\n    vector[N] x;\n    // observations\n    vector[N] y;\n    // number of covariate values to make predictions at\n    int&lt;lower=0&gt; no_predictions;\n    // covariate values to make predictions at\n    vector[no_predictions] x_predictions;\n}\n2parameters {\n    // intercept\n    real alpha;\n    // slope\n    real beta;\n    // the standard deviation should be constrained to be positive\n    real&lt;upper=0&gt; sigma;\n}\n3transformed parameters {\n    // deterministic transformation of parameters and data\n    vector[N] mu = alpha + beta * x // linear model\n}\n4model {\n    // observation model / likelihood\n    y ~ normal(mu, sigma);\n}\n5generated quantities {\n    // compute the means for the covariate values at which to make predictions\n    vector[no_predictions] mu_pred = alpha + beta * x_predictions;\n    // sample from the predictive distribution, a normal(mu_pred, sigma).\n    array[no_predictions] real y_pred = normal_rng(mu, sigma);\n}\n\n1\n\nThis is Stan’s data block: “The data block is for the declaration of variables that are read in as data. […] Each variable’s value is validated against its declaration as it is read. For example, if a variable sigma is declared as real&lt;lower=0&gt;, then trying to assign it a negative value will raise an error. As a result, data type errors will be caught as early as possible. Similarly, attempts to provide data of the wrong size for a compound data structure will also raise an error.” For more information, follow the link.\n\n2\n\nThis is Stan’s parameters block: “The variables declared in the parameters program block correspond directly to the variables being sampled by Stan’s samplers (HMC and NUTS). From a user’s perspective, the parameters in the program block are the parameters being sampled by Stan.” For more information, follow the link.\n\n3\n\nThis is Stan’s transformed parameters block: “The transformed parameters program block consists of optional variable declarations followed by statements. After the statements are executed, the constraints on the transformed parameters are validated. Any variable declared as a transformed parameter is part of the output produced for draws.” For more information, follow the link.\n\n4\n\nThis is Stan’s model block: “The model program block consists of optional variable declarations followed by statements. The variables in the model block are local variables and are not written as part of the output. […] The statements in the model block typically define the model. This is the block in which probability (sampling notation) statements are allowed.” For more information, follow the link.\n\n5\n\nThis is Stan’s generated quantities block: “The generated quantities program block is rather different than the other blocks. Nothing in the generated quantities block affects the sampled parameter values. The block is executed only after a sample has been generated.” For more information, follow the link.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nA normal linear model is actually not the best model to use for this type of data, but we will use it here to illustrate the first step in building up to more appropriate, complicated models.\n\n\n\n\n\n\n\n\n\nSubtask 2.a\n\n\n\n\nFind the three mistakes in the code and fix them. Report the original mistakes and your fixes clearly in your report. Include the full corrected Stan code in your report. Verify that sampling was successful.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou may find some of the mistakes in the code using Stan syntax checker. If you copy the Stan code to a file ending .stan and open it in RStudio (you can also choose from RStudio menu File\\(\\rightarrow\\)New File\\(\\rightarrow\\)Stan file to create a new Stan file), the editor will show you some syntax errors. More syntax errors might be detected by clicking `Check’ in the bar just above the Stan file in the RStudio editor. Note that some of the errors in the presented Stan code may not be syntax errors.\n\n\n\nWrite your answers/code here!\n\nThe author runs the corrected Stan file using the following R code and plots the returned MCMC sample. Read through the code below to understand what is being plotted.\n\n\n\n\n\n\nData preparation and sampling from the posterior\n\n\n\n\n\nData assembly happens here:\n\n# These are our observations y: the proportion of students handing in each assignment (1-8),\n# sorted by year (row-wise) and assignment (column-wise).\n# While the code suggest a matrix structure,\n# the result will actually be a vector of length N = no_years * no_assignments\npropstudents&lt;-c(c(176, 174, 158, 135, 138, 129, 126, 123)/176,\n                c(242, 212, 184, 177, 174, 172, 163, 156)/242,\n                c(332, 310, 278, 258, 243, 242, 226, 224)/332,\n                c(301, 269, 231, 232, 217, 208, 193, 191)/301,\n                c(245, 240, 228, 217, 206, 199, 191, 182)/245)\n# These are our predictors x: for each observation, the corresponding assignment number.\nassignment &lt;- rep(1:8, 5)\n# These are in some sense our test data: the proportion of students handing in the last assignment (9),\n# sorted by year.\n# Usually, we would not want to split our data like that and instead\n# use e.g. Leave-One-Out Cross-Validation (LOO-CV, see e.g. http://mc-stan.org/loo/index.html)\n# to evaluate model performance.\npropstudents9 = c(121/176, 153/242, 218/332, 190/301, 175/245)\n# The total number of assignments\nno_assignments = 9\n# The assignment numbers for which we want to generate predictions\nx_predictions = 1:no_assignments\n# (Cmd)Stan(R) expects the data to be passed in the below format:\nmodel_data = list(N=length(assignment),\n                 x=assignment,\n                 y=propstudents,\n                 no_predictions=no_assignments,\n                 x_predictions=x_predictions)\n\nSampling from the posterior distribution happens here:\n\n# This reads the file at the specified path and tries to compile it.\n# If it fails, an error is thrown.\nretention_model = cmdstan_model(\"./additional_files/assignment6_linear_model.stan\")\n\nError in initialize(...): Assertion on 'stan_file' failed: File does not exist: './additional_files/assignment6_linear_model.stan'.\n\n# This \"out &lt;- capture.output(...)\" construction suppresses output from cmdstanr\n# See also https://github.com/stan-dev/cmdstanr/issues/646\nout &lt;- capture.output(\n    # Sampling from the posterior distribution happens here:\n    fit &lt;- retention_model$sample(data=model_data, refresh=0, show_messages=FALSE)\n)\n\nError in eval(expr, envir, enclos): object 'retention_model' not found\n\n\nDraws postprocessing happens here:\n\n# This extracts the draws from the sampling result as a data.frame.\ndraws_df = fit$draws(format=\"draws_df\")\n\nError in eval(expr, envir, enclos): object 'fit' not found\n\n# This does some data/draws wrangling to compute the 5, 50 and 95 percentiles of\n# the mean at the specified covariate values (x_predictions).\n# It can be instructive to play around with each of the data processing steps\n# to find out what each step does, e.g. by removing parts from the back like \"|&gt;  gather(pct,y,-x)\"\n# and printing the resulting data.frame.\nmu_quantiles_df = draws_df |&gt;\n      subset_draws(variable = c(\"mu_pred\")) |&gt;\n      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |&gt;\n      mutate(x = 1:9) |&gt;\n      pivot_longer(c(q5, q50, q95), names_to = c(\"pct\"))\n\nError in UseMethod(\"subset_draws\"): no applicable method for 'subset_draws' applied to an object of class \"function\"\n\n# Same as above, but for the predictions.\ny_quantiles_df = draws_df |&gt;\n      subset_draws(variable = c(\"y_pred\")) |&gt;\n      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |&gt;\n      mutate(x = 1:9) |&gt;\n      pivot_longer(c(q5, q50, q95), names_to = c(\"pct\"))\n\nError in UseMethod(\"subset_draws\"): no applicable method for 'subset_draws' applied to an object of class \"function\"\n\n\n\n\n\nPlotting happens here:\n\nggplot() +\n  # scatter plot of the training data:\n  geom_point(\n    aes(x, y, color=assignment),\n    data=data.frame(x=assignment, y=propstudents, assignment=\"1-8\")\n) +\n  # scatter plot of the test data:\n  geom_point(\n    aes(x, y, color=assignment),\n    data=data.frame(x=no_assignments, y=propstudents9, assignment=\"9\")\n) +\n  # you have to tell us what this plots:\n  geom_line(aes(x,y=value,linetype=pct), data=mu_quantiles_df, color='grey', linewidth=1.5) +\n  # you have to tell us what this plots:\n  geom_line(aes(x,y=value,linetype=pct), data=y_quantiles_df, color='red') +\n  # adding xticks for each assignment:\n  scale_x_continuous(breaks=1:no_assignments) +\n  # adding labels to the plot:\n  labs(y=\"assignment submission %\", x=\"assignment number\") +\n  # specifying that line types repeat:\n  scale_linetype_manual(values=c(2,1,2)) +\n  # Specify colours of the observations:\n  scale_colour_manual(values = c(\"1-8\"=\"black\", \"9\"=\"blue\")) +\n  # remove the legend for the linetypes:\n  guides(linetype=\"none\")\n\nError in eval(expr, envir, enclos): object 'mu_quantiles_df' not found\n\n\n\n\n\n\n\n\nQuick check for sampling convergence\n\n\n\n\n\nIf your model is correctly implemented, sampling from the posterior distribution should have been successful. You can check whether Stan thinks that sampling succeeded by inspecting the output of the below command, which you should be able to interpret with a little help from the CmdStan User’s Guide.\n\nfit$cmdstan_diagnose()\n\nError in eval(expr, envir, enclos): object 'fit' not found\n\n\n\n\n\nBased on the above plot, answer the following questions:\n\n\n\n\n\n\nSubtask 2.b\n\n\n\n\nWhat is the solid red line plotting? What are the dashed red lines? How and why are these different from the corresponding grey lines?\nWhat is the general trend of student retention as measured by assignment submissions?\nGiven a model fitted to the submission data for assignments 1-8, does it do a good job predicting the proportion of students who submit the final 9th assignment?\nName one different modeling choice you could make to improve the prediction.\n\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code included?\n\nNo\nYes\n\nIs the full resulting modified Stan model code presented in the report?\n\nNo\nYes, but partially\nYes, with a few mistakes\nYes, and it is correct\n\nHas the sampling success been verified/summarized (e.g. by inspecting and summarizing the output of CmdStan’s diagnose method).\n\nNo\nYes, but partially\nYes, and it is correctly verified\n\nFix #1: Is there a fix for line .\n\nIt has not been discussed, that this line should be fixed.\nIt has been discussed, that this line should be fixed, but there is no fix presented for it or the fix is clearly wrong.\nThere is a fix presented for this line, that clearly solves the problem.\n\nFix #2: Is there a fix for line .\n\nIt has not been discussed, that this line should be fixed.\nIt has been discussed, that this line should be fixed, but there is no fix presented for it or the fix is clearly wrong.\nThere is a fix presented for this line, that clearly solves the problem.\n\nFix #3: Is there a fix for line .\n\nIt has not been discussed, that this line should be fixed.\nIt has been discussed, that this line should be fixed, but there is no fix presented for it or the fix is clearly wrong.\nThere is a fix presented for this line, that clearly solves the problem.\n\nHave the red lines been correctly described ()?\nHave the grey lines been correctly described ()?\nHas the difference between the red and grey lines been explained ()?\nHas the student retention trend been described ()\nHas the predictive performance for the held out data been discussed and assessed satisfactorily ()?\n\nNo\nSomewhat\nYes\n\nHas at least one way to improve the model been mentioned (E.g. or )?\n\n\n\n\n\n3 Generalized linear model: Bioassay with Stan (4 points)\nReplicate the computations for the bioassay example of section 3.7 (BDA3) using Stan.\n\n\n\n\n\n\nSubtask 3.a\n\n\n\nWrite down the model for the bioassay data in Stan syntax. For instructions in reporting your implementation, you can refer to parts 2c.3 - 2c.6 in Assignment 5. Use the Gaussian prior as in Assignment 4 and 5, that is \\[\n\\begin{aligned}\n    \\begin{bmatrix}\n    \\alpha \\\\ \\beta\n    \\end{bmatrix}\n    \\sim\n    \\text{N} \\left( \\mu_0,  \\Sigma_0 \\right), \\qquad\n    \\text{where} \\quad\n     \\mu_0 = \\begin{bmatrix} 0 \\\\ 10 \\end{bmatrix} \\quad \\text{and} \\quad\n     \\Sigma_0 = \\begin{bmatrix} 2^2 & 12 \\\\ 12 & 10^2 \\end{bmatrix}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou will need Stan functions multi_normal and binomial_logit for implementing the prior and observation model, respectively. In Stan code, it is easiest to declare a variable (say theta) which is a two-element vector so that the first value denotes \\(\\alpha\\) and latter one \\(\\beta\\). This is because the multi_normal function that you need for implementing the prior requires a vector as an input.\n\n\n\nWrite your answers/code here!\n\ndata(\"bioassay\")\n\n\n\n\n\n\n\nSubtask 3.b\n\n\n\nUse \\(\\widehat{R}\\) for convergence analysis. You can either use Eq. (11.4) in BDA3 or the later version that can be found in a recent article. You should specify which \\(\\widehat{R}\\) you used. In R the best choice is to use function rhat_basic() or rhat() from the posterior package (see ?posterior::rhat_basic). To check \\(\\widehat{R}\\) and other diagnostics, you can also call fit$summary(), where fit is the fit object returned by Stan’s sampling function. Report the \\(\\widehat{R}\\) values both for \\(\\alpha\\) and \\(\\beta\\) and discuss the convergence of the chains. Briefly explain in your own words how to interpret the obtained \\(\\widehat{R}\\) values.\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nSubtask 3.c\n\n\n\nPlot the draws for \\(\\alpha\\) and \\(\\beta\\) (scatter plot) and include this plot in your report. You can compare the results to Figure 3.3b in BDA3 to verify that your code gives sensible results. Notice though that the results in Figure 3.3b are generated from posterior with a uniform prior, so even when your algorithm works perfectly, the results will look slightly different (although fairly similar).\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nSubtask 3.d\n\n\n\nTo develop the course and provide feedback to Stan developers, we collect information on which Stan setup you used and whether you had any problems in setting it up or using it. Please report,\n\nOperating system (Linux, Mac, Windows) or jupyter.cs.aalto.fi?\nProgramming environment used: R or Python?\nInterface used: RStan, CmdStanR, PyStan, or CmdStanPy?\nDid you have installation or compilation problems? Did you try first installing locally, but switched to jupyter.cs.aalto.fi?\nIn addition of these you can write what other things you found out difficult (or even frustrating) when making this assignment with Stan.\n\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the Stan model code included?\n\nNo\nYes\n\nDoes the implemented Stan-model seem to be working?\n\nNo implementation\nModel implemented but results not visualized/reported\nModel implemented, but the results seem weird\nModel seems to work correctly\n\nAre the R_hat-values reported (potential scale reduction factor, Eq. (11.4) in the BDA3)?\n\nNo\nYes, but only for alpha or beta\nYes, single values both for alpha and beta\n\nIs the interpretation of R_hat values correct ()?\n\nNo interpretation or discussion about the R_hat-values, or conclusions clearly wrong\nSomewhat correct\nInterpretation correct\n\nDoes the report contain a scatter plot about the draws? Do the results look reasonable, that is, roughly like in the Figure below ?\n\nNo plot included\nPlot included, but the results do not look like in the figure above\nPlot included, and the results look roughly like in the figure above\n\nDoes the report contain description of Stan setup used and whether there were any problems in setting it up or using it?\n\nNo\nYes\n\nEven if the Stan model code is correct, there might be ways to give improve the layout or write the model in more elegant ways. This optional feedback box can be used to give additional suggestions for better Stan code.\n\n\n\n\n\n4 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Assignments",
      "Assignment 6, 2023"
    ]
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "Assignment 5, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 5 and Chapters 10 and 11.\nThe maximum amount of points from this assignment is 6.\nWe have prepared a *quarto template specific to this assignment (html, qmd, pdf)** to help you get started.\nIf you are not using JupyterHub (which has all the needed packages pre-installed), and want to make the assignment on your own computer, you may use a docker container that includes all the necessary software packages, too.\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 10.\nThe reading instructions for BDA3 Chapter 11.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 5. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment5.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\nThe following installs and loads the posterior package which imports the rhat_basic() function:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggplot2 package and the bayesplot package\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nif(!require(bayesplot)){\n    install.packages(\"bayesplot\")\n    library(bayesplot)\n}\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:posterior':\n\n    rhat\n\n\n\n\n\n\n\n2 Generalized linear model: Bioassay model with Metropolis algorithm\nMetropolis algorithm: Replicate the computations for the bioassay example of BDA3 Section 3.7 using the Metropolis algorithm. The Metropolis algorithm is described in BDA3 Chapter 11.2. More information on the bioassay data can be found in Section 3.7 in BDA3, and in Chapter 3 notes.\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nImplement the Metropolis algorithm as an R function for the bioassay data. Use the Gaussian prior as in Assignment 4, that is \\[\n\\begin{aligned}\n    \\begin{bmatrix}\n    \\alpha \\\\ \\beta\n    \\end{bmatrix}\n    \\sim\n    \\text{N} \\left( \\mu_0,  \\Sigma_0 \\right), \\qquad\n    \\text{where} \\quad\n     \\mu_0 = \\begin{bmatrix} 0 \\\\ 10 \\end{bmatrix} \\quad \\text{and} \\quad\n     \\Sigma_0 = \\begin{bmatrix} 2^2 & 12 \\\\ 12 & 10^2 \\end{bmatrix}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCompute with log-densities. Reasons are explained on BDA3 page 261 and Lecture video 4.1. Remember that \\(p_1/p_0=\\exp(\\log(p_1)-\\log(p_0))\\). For your convenience we have provided functions that will evaluate the log-likelihood for given \\(\\alpha\\) and \\(\\beta\\) (see bioassaylp() in the aaltobda package). Notice that you still need to add the prior yourself and remember the unnormalized log posterior is simply the sum of log-likelihood and log-prior. For evaluating the log of the Gaussian prior you can use the function dmvnorm from package aaltobda.\nUse a simple (normal) proposal distribution. Example proposals are \\(\\alpha^* \\sim N(\\alpha_{t-1}, \\sigma = 1)\\) and \\(\\beta^* \\sim N(\\beta_{t-1}, \\sigma = 5)\\). There is no need to try to find optimal proposal but test some different values for the jump scale (\\(\\sigma\\)). Remember to report the one you used. Efficient proposals are discussed in BDA3 p. 295–297 (not part of the course). In real-life a pre-run could be made with an automatic adaptive control to adapt the proposal distribution.\n\n\n\nWrite your answers/code here!\n\n# Useful functions: runif, rnorm\n# bioassaylp, dmvnorm (from aaltobda)\n\ndata(\"bioassay\")\n# Start by implementing a function called `density_ratio` to\n# compute the density ratio function, $r$ in Eq. (11.1) in BDA3:\ndensity_ratio &lt;- function(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n){\n    # Do computation here, and return as below.\n    # Below are the correct return values for two different calls of this function:\n\n    # alpha_propose = 1.89, alpha_previous = 0.374,\n    # beta_propose = 24.76, beta_previous = 20.04,\n    # x = bioassay$x, y = bioassay$y, n = bioassay$n\n    1.305179\n\n    # alpha_propose = 0.374, alpha_previous = 1.89,\n    # beta_propose = 20.04, beta_previous = 24.76,\n    # x = bioassay$x, y = bioassay$y, n = bioassay$n\n    0.7661784\n    ### {.content-hidden when-profile=\"public\"}\n    prior_mean = c(0, 10)\n    prior_sigma = cbind(c(4, 12), c(12, 100))\n    exp(\n        bioassaylp(alpha_propose, beta_propose, x, y, n)\n        - bioassaylp(alpha_previous, beta_previous, x, y, n)\n        + dmvnorm(c(alpha_propose, beta_propose), prior_mean, prior_sigma, TRUE)\n        - dmvnorm(c(alpha_previous, beta_previous), prior_mean, prior_sigma, TRUE)\n    )\n    ###\n}\n# Then implement a function called `metropolis_bioassay()` which\n# implements the Metropolis algorithm using the `density_ratio()`:\nmetropolis_bioassay &lt;- function(alpha_initial, beta_initial, alpha_sigma, beta_sigma, no_draws, x, y, n){\n    # Do computation here, and return as below.\n    # Below are \"wrong\" values (unlikely to actually occur)\n    # in the \"correct\" format (such that they work with the plotting functions further down).\n    data.frame(\n        alpha=c(alpha_initial, alpha_initial+alpha_sigma, alpha_initial-alpha_sigma),\n        beta=c(beta_initial, beta_initial+beta_sigma, beta_initial-beta_sigma)\n    )\n    ### {.content-hidden when-profile=\"public\"}\n    alpha_previous = alpha_initial\n    beta_previous = beta_initial\n    alpha_rv = c()\n    beta_rv = c()\n    for(draw in 1:no_draws){\n        alpha_propose = rnorm(1, alpha_previous, alpha_sigma)\n        beta_propose = rnorm(1, beta_previous, beta_sigma)\n        if(runif(1) &lt; density_ratio(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n)){\n            alpha_previous = alpha_propose\n            beta_previous = beta_propose\n        }\n        alpha_rv = c(alpha_rv, alpha_previous)\n        beta_rv = c(beta_rv, beta_previous)\n    }\n    data.frame(alpha=alpha_rv, beta=beta_rv)\n    ###\n}\ndf = metropolis_bioassay(0, 0, 1, 1, 1000, bioassay$x, bioassay$y, bioassay$n)\n\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nInclude in the report the following:\n\nDescribe in your own words in one paragraph the basic idea of the Metropolis algorithm (see BDA3 Section 11.2, and Lecture video 5.1).\nThe proposal distribution (related to jumping rule) you used. Describe briefly in words how you chose the final proposal distribution you used for the reported results.\nThe initial points of your Metropolis chains (or the explicit mechanism for generating them).\nReport the chain length or the number of iterations for each chain. Run the simulations long enough for approximate convergence (see BDA Section 11.4, and Lecture 5.2).\nReport the warm-up length (see BDA Section 11.4, and Lecture 5.2).\nThe number of Metropolis chains used. It is important that multiple Metropolis chains are run for evaluating convergence (see BDA Section 11.4, and Lecture 5.2).\nPlot all chains for \\(\\alpha\\) in a single line-plot. Overlapping the chains in this way helps in visually assessing whether chains have converged or not.\nDo the same for \\(\\beta\\).\n\n\n\nWrite your answers/code here!\nHave a look at bayesplot trace plot examples and tune your plot if wanted/needed. Don’t forget to include a title/caption/description.\nThe below example plot only includes a single chain, but your report should include a plot with multiple chains overlayed!\n\n# Useful functions: mcmc_trace (from bayesplot)\nmcmc_trace(df, pars=c(\"alpha\", \"beta\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.c)\n\n\n\nIn complex scenarios, visual assessment is not sufficient and \\(\\widehat{R}\\) is a more robust indicator of convergence of the Markov chains. Use \\(\\widehat{R}\\) for convergence analysis. You can either use Eq. (11.4) in BDA3 or the more recent version described in the article Rank-normalization, folding, and localization: An improved \\(\\widehat{R}\\) for assessing convergence of MCMC. You should specify which \\(\\widehat{R}\\) you used. In R the best choice is to use function rhat_basic() from the package posterior (this function implements the version described in the above mentioned article). Remember to remove the warm-up sample before computing \\(\\widehat{R}\\). Report the \\(\\widehat{R}\\) values for \\(\\alpha\\) and \\(\\beta\\) separately. Report the values for the proposal distribution you finally used.\n\nDescribe briefly in your own words the basic idea of \\(\\widehat{R}\\) and how to to interpret the obtained \\(\\widehat{R}\\) values.\nTell whether you obtained good \\(\\widehat{R}\\) with first try, or whether you needed to run more iterations or how did you modify the proposal distribution.\n\n\n\nWrite your answers/code here!\n\n# Useful functions: rhat_basic (from posterior)\n\n\n\n\n\n\n\nSubtask 2.d)\n\n\n\nPlot the draws for \\(\\alpha\\) and \\(\\beta\\) (scatter plot) and include this plot in your report. You can compare the results to BDA3 Figure 3.3b to verify that your code gives sensible results. Notice though that the results in Figure 3.3b are generated from the posterior with a uniform prior, so even when if your algorithm works perfectly, the results will look slightly different (although fairly similar).\n\n\nWrite your answers/code here!\nHave a look at bayesplot scatter plot examples and tune your plot if wanted/needed. Don’t forget to include a title/caption/description.\n\n# Useful functions: mcmc_scatter (from bayesplot)\nmcmc_scatter(df, pars=c(\"alpha\", \"beta\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the implementation of density_ratio function included ?\n\nNo\nYes\n\nIs the implementation of metropolis_bioassay function included ?\n\nNo\nYes\n\n2 a) Is the brief description of Metropolis-Hastings algorithm included (and it’s not complete nonsense)? Provide also a brief comment on how clear you think that description is (and potentially mention errors if you see them).\n\nNo\nYes\n\n2 b) Is the proposal/jumping distribution reported?\n\nNo\nYes\n\n2 c) Are the starting points or the mechanism how they are generated reported?\n\nNo\nYes\n\n2 d) Is the number of draws per chain reported?\n\nNo\nYes\n\n2 e) Is the warm-up length reported?\n\nNo\nYes\n\n2 f) Is the number of chains reported?\n\nNo\nYes\n\n2 g) and 2 h) Are line plots of the chains included? (Separate plots for alpha and beta)\n\nNo plots are included\nYes, but both plots are in a single figure, or the plots are scatter plots (scatter plots aren’t useful for visual convergence evaluation).\nYes, but only a plot for alpha or beta is included.\nYes, separate line plots for both alpha and beta are included.\n\nIs there a discussion on the convergence of the chains?\n\nNo discussion on convergence.\nYes, but the discussion is not convincing.\nYes, discussed in the report.\n\nIs it mentioned which implementation of Rhat is used? Two possible ways to compute R-hat would be:\n\n\n\n\nIt is OK as long as it is mentioned (or evident from the code) which of the above is used.\n\nNo\nYes\n\nIs the brief description of Rhat included (and it’s not complete nonsense)? Provide also a brief comment on how clear you think that description is (and potentially mention errors if you see them).\n\nNo\nYes\n\nAre the Rhat-values for alpha and beta reported?\n\nNo\nYes, but incorrectly computed\nYes, but computed separately for each chain\nYes, but only for alpha or beta\nYes, single values both for alpha and beta\n\nIs the interpretation of R-hat values correct ()?\n\nNo interpretation or discussion about the R-hat values, or conclusions clearly wrong\nInterpretation somewhat correct\nInterpretation correct\n\nDoes the report contain a scatter plot about the draws? Do the results look reasonable, that is, roughly like in the Figure below ?\n\nNo plot included\nPlot included, but the results do not look like in the figure above\nPlot included, and the results look roughly like in the figure above\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n3 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Assignments",
      "Assignment 5, 2023"
    ]
  },
  {
    "objectID": "template4.html",
    "href": "template4.html",
    "title": "Assignment 4, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 4 and Chapters 3 and 10.\nThe maximum amount of points from this assignment is 6.\nWe have prepared a quarto template specific for this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 3.\nThe reading instructions for BDA3 Chapter 10.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 4. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment4.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\n\n\n\n\n\n2 Bioassay model\nIn this exercise, you will use a dose-response relation model that is used in BDA3 Section 3.7 and in the chapter reading instructions. The used likelihood is the same, but instead of uniform priors, we will use a bivariate normal distribution as the joint prior distribution of the parameters \\(\\alpha\\) and \\(\\beta\\).\nIn the prior distribution for \\((\\alpha,\\beta)\\), the marginal distributions are \\(\\alpha \\sim N(0,2^2)\\) and \\(\\beta \\sim N(10,10^2)\\), and the correlation between them is \\(\\mathrm{corr}(\\alpha, \\beta)=0.6\\).\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nReport the mean (vector of two values) and covariance (two by two matrix) of the bivariate normal distribution.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe mean and covariance of the bivariate normal distribution are a length–\\(2\\) vector and a \\(2 \\times 2\\) matrix. The elements of the covariance matrix can be computed using the relation of correlation and covariance.\n\n\n\nYou are given 4000 independent draws from the posterior distribution of the model in the dataset bioassay_posterior in the aaltobda package.\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nReport\n\nthe mean as well as\n5 \\(\\%\\) and 95 \\(\\%\\) quantiles separately\n\nfor both\n\n\\(\\alpha\\) and\n\\(\\beta\\).\n\nReport also the Monte Carlo standard errors (MCSEs) for the mean and quantile estimates and explain in text what does Monte Carlo standard error mean and how you decided the number of digits to show.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe answer is graded as correct only if the number of digits reported is correct. The number of significant digits can be different for the mean and quantile estimates. In some other cases, the number of digits reported can be less than MCSE allows for practical reasons as discussed in the lecture.\nHint:\nQuantiles can be computed with the quantile function. With \\(S\\) draws, the MCSE for \\(\\text{E}[\\theta]\\) is \\(\\sqrt{\\text{Var} [\\theta]/S}\\). MCSE for the quantile estimates can be computed with the mcse_quantile function from the aaltobda package.\n\n\n\nLoading the library and the data.\n\n# Useful functions: quantile()\n# and mcse_quantile() (from aaltobda)\n\ndata(\"bioassay_posterior\")\n# The 4000 draws are now stored in the variable `bioassay_posterior`.\n# The below displays the first rows of the data:\nhead(bioassay_posterior)\n\n        alpha      beta\n1 -0.02050577 10.032841\n2  1.21738518  4.504546\n3  3.04829407 16.239424\n4  1.32272770  4.924268\n5  1.36274817 12.880561\n6  1.08593225  5.943731\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nAre the mean and covariance of the prior in a) reported? The correct answers are :\n\nNot reported\nYes, but they are not correct\nYes, and they are correct\n\nAre the means and their MCSEs of alpha and beta in b) reported? Note that the number of digits reported for the means must follow the rule given in the assignment. The correct answers are alpha: mean and beta: mean .\n\nNot reported\nYes, but one or both means are incorrect\nYes, and the means are correct\n\nAre the quantiles and their MCSEs of alpha and beta in b) reported? Note that the number of digits reported for the quantiles must follow the rule given in the assignment. The correct answers are alpha: 5% quantile and beta: 5% quantile , 95% quantile .\n\nNot reported\nYes, but one or more quantiles are incorrect\nYes, and the quantiles are correct\n\n\n\n\n\n\n3 Importance sampling\nNow we discard our posterior draws and switch to importance sampling.\n\n\n\n\n\n\nSubtask 3.c)\n\n\n\nImplement a function for computing the log importance ratios (log importance weights) when the importance sampling target distribution is the posterior distribution, and the proposal distribution is the prior distribution from a). Explain in words why it’s better to compute log ratios instead of ratios.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNon-log importance ratios are given by equation (10.3) in the course book. The fact that our proposal distribution is the same as the prior distribution makes this task easier. The logarithm of the likelihood can be computed with the bioassaylp function from the aaltobda package. The data required for the likelihood can be loaded with data(\"bioassay\").\n\n\n\n\n# Useful functions: bioassaylp (from aaltobda)\nalpha_test = c(1.896, -3.6,  0.374, 0.964, -3.123, -1.581)\nbeta_test = c(24.76, 20.04, 6.15, 18.65, 8.16, 17.4)\n\n\nlog_importance_weights &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(-8.95, -23.47, -6.02, -8.13, -16.61, -14.57)\n}\n\n\n\n\n\n\n\nSubtask 3.d)\n\n\n\nImplement a function for computing normalized importance ratios from the unnormalized log ratios in c). In other words, exponentiate the log ratios and scale them such that they sum to one. Explain in words what is the effect of exponentiating and scaling so that sum is one.\n\n\n\nnormalized_importance_weights &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.045, 0.000, 0.852, 0.103, 0.000, 0.000)\n}\n\n\n\n\n\n\n\nSubtask 3.e)\n\n\n\nSample 4000 draws of \\(\\alpha\\) and \\(\\beta\\) from the prior distribution from a). Compute and plot a histogram of the 4000 normalized importance ratios. Use the functions you implemented in c) and d).\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUse the function rmvnorm from the aaltobda package for sampling.\n\n\n\nWrite your answers and code here!\n\n\n\n\n\n\nSubtask 3.f)\n\n\n\nUsing the importance ratios, compute the importance sampling effective sample size \\(S_{\\text{eff}}\\) and report it.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEquation (10.4) in the course book.\nBDA3 1st (2013) and 2nd (2014) printing have an error for \\(\\tilde{w}(\\theta^s)\\) used in the effective sample size equation (10.4). The normalized weights equation should not have the multiplier S (the normalized weights should sum to one). The later printings, the online version, and the slides have the correct equation.\n\n\n\n\nS_eff &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    1.354\n}\n\n\n\n\n\n\n\nSubtask 3.g)\n\n\n\nExplain in your own words what the importance sampling effective sample size represents. Also explain how the effective sample size is seen in the histogram of the weights that you plotted in e).\n\n\n\n\n\n\n\n\nSubtask 3.h)\n\n\n\nImplement a function for computing the posterior mean using importance sampling, and compute the mean using your 4000 draws. Explain in your own words the computation for importance sampling. Report the means for \\(\\alpha\\) and \\(\\beta\\), and also the Monte Carlo standard errors (MCSEs) for the mean estimates. Report the number of digits for the means based on the MCSEs.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe values below are only a test case, you need to use 4000 draws for \\(\\alpha\\) and \\(\\beta\\) in the final report.\nUse the same equation for the MCSE of \\(\\text{E}[\\theta]\\) as earlier (\\(\\sqrt{\\text{Var} [\\theta]/S}\\)), but now replace \\(S\\) with \\(S_{\\text{eff}}\\). To compute \\(\\text{Var} [\\theta]\\) with importance sampling, use the identity \\(\\text{Var}[\\theta] = \\text{E}[\\theta^2] - \\text{E}[\\theta]^2\\).\n\n\n\n\nposterior_mean &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.503, 8.275)\n}\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code for the function in c) reported?\n\nNo\nYes\n\nIs the source code for the function in d) reported?\n\nNo\nYes\n\nDoes the histogram in e) look something like this figure? If it is evident that the normalized importance ratios are computed correctly, but the prior was incorrect, you can still grade “Reported and looks similar”.\n\nNot reported\nReported, but looks different\nReported and looks similar\n\nIs the effective sample size in f) reported? The correct range for the effective sample size is between . However, if it is evident that the effective sample size is computed correctly, but the prior was incorrect, you can still grade “Yes, and it is correct”.\n\nNo\nYes, but it is not correct\nYes, and it is correct\n\nThe correct explanation for g) is roughly the following: \nWhat is the connection between S_eff and the histogram of weights: How is the answer?\n\nTotally wrong/has not tried\nSomething is a bit wrong\nExplanation is sensible\n\nIs the source code for the function in h) reported?\n\nNo\nYes\n\nAre the means and their MCSEs of alpha and beta in h) reported? Note that the number of digits reported for the means must follow the rule given in the assignment. The correct answers should be close to these: alpha: mean\n\nNot reported\nYes, but they are incorrect\nYes, and they are correct\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n4 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Templates",
      "Assignment 4, 2023"
    ]
  },
  {
    "objectID": "template6.html",
    "href": "template6.html",
    "title": "Assignment 6, 2023",
    "section": "",
    "text": "1 General information\nThe maximum amount of points from this assignment is 6.\nThis is for BDA 2023\nWe have prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nWe recommend Aalto students use jupyter.cs.aalto.fi, for all others we also provide a docker container.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 10.\nThe reading instructions for BDA3 Chapter 11.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\nInstalling and using CmdStanR:\nSee the Stan demos on how to use Stan in R (or Python). Aalto JupyterHub has working R and CmdStanR/RStan environment and is probably the easiest way to use Stan. * To use CmdStanR in Aalto JupyterHub: library(cmdstanr) set_cmdstan_path('/coursedata/cmdstan')\nThe Aalto Ubuntu desktops also have the necessary libraries installed.\nTo install Stan on your laptop, run ‘install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))’ in R. If you encounter problems, see additional answers in FAQ. For Aalto students, if you don’t succeed in short amount of time, it is probably easier to use Aalto JupyterHub.\nIf you use Aalto JupyterHub, all necessary packages have been pre-installed. In your laptop, install package cmdstanr. Installation instructions on Linux, Mac and Windows can be found at https://mc-stan.org/cmdstanr/. Additional useful packages are loo, bayesplot and posterior (but you don’t need these in this assignment). For Python users, PyStan, CmdStanPy, and ArviZ packages are useful.\nStan manual can be found at https://mc-stan.org/users/documentation/. From this website, you can also find a lot of other useful material about Stan.\nIf you edit files ending .stan in RStudio, you can click “Check” in the editor toolbar to make syntax check. This can significantly speed-up writing a working Stan model.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\nThis is the template for assignment 6. You can download the broken stan-file and the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nJupyterHub has all the needed packages pre-installed.\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\nThe following installs and loads the posterior package which imports the rhat_basic() function:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggplot2 package, the bayesplot package and the dplyr package\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nif(!require(bayesplot)){\n    install.packages(\"bayesplot\")\n    library(bayesplot)\n}\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:posterior':\n\n    rhat\n\nif(!require(dplyr)){\n    install.packages(\"dplyr\")\n    library(dplyr)\n}\n\nLoading required package: dplyr\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nif(!require(tidyr)){\n    install.packages(\"tidyr\")\n    library(tidyr)\n}\n\nLoading required package: tidyr\n\n# Some additional set-up to make plots legible\nggplot2::theme_set(theme_minimal(base_size = 14))\nbayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))\n# register_knitr_engine()\n\nThe following installs and loads the cmdstanr package and tries to install cmdstan.\n\nif(!require(cmdstanr)){\n    install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n    library(cmdstanr)\n}\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /u/77/ave/unix/.cmdstan/cmdstan-2.35.0-rc3\n\n\n- CmdStan version: 2.35.0\n\ncmdstan_installed &lt;- function(){\n  res &lt;- try(out &lt;- cmdstanr::cmdstan_path(), silent = TRUE)\n  !inherits(res, \"try-error\")\n}\nif(!cmdstan_installed()){\n    install_cmdstan()\n}\n\n\n\n\n\n\n2 Stan warm-up: linear model of BDA retention with Stan (2 points)\nFrom 2018 to 2022, we have been keeping track of assignment submissions for the BDA course given the number of submissions for the 1st assignment. We will fit a simple linear model to answer two questions of interest:\n\nWhat is the trend of student retention as measured by assignment submissions?\nGiven the submission rates for assignments 1–8, how many students will complete the final 9th assignment (and potentially pass the course)?\n\nThe author has given you the broken Stan code below, which they intend to encode the following linear model: \\[\n\\begin{aligned}\np(\\alpha,\\beta,\\sigma) &= \\mathrm{const.}\n      & \\text{(improper flat prior)}&\\text{ and}\\\\\np(y|x,\\alpha,\\beta,\\sigma) &= p_\\mathrm{normal}(y|\\alpha + \\beta x, \\sigma)\n      & \\text{(normal likelihood)} &\\text{.}\n\\end{aligned}\n\\] In both the statistical model above and in the Stan model below, \\(x \\in \\mathbb{R}^N\\) and \\(y \\in \\mathbb{R}^N\\) are vectors of the covariates / predictors (the assignment number) and vectors of the observation (proportions of students who have handed in the respective assignment). \\(\\alpha \\in \\mathbb{R}\\) is the unknown scalar intercept, \\(\\beta \\in \\mathbb{R}\\) is the unknown scalar slope and \\(\\sigma \\in \\mathbb{R}_{&gt;0}\\) is the unknown scalar observation standard deviation. The statistical model further implies \\[\np(y_\\mathrm{pred.}|x_\\mathrm{pred.},\\alpha,\\beta,\\sigma) = p_\\mathrm{normal}(y_\\mathrm{pred.}|\\alpha + \\beta x_\\mathrm{pred.}, \\sigma)\n\\] as the predictive distribution for a new observation \\(y_\\mathrm{pred.}\\) at a given new covariate value \\(x_\\mathrm{pred.}\\).\nYou can download the broken stan file from github.\n1data {\n    // number of data points\n    int&lt;lower=0&gt; N;\n    // covariate / predictor\n    vector[N] x;\n    // observations\n    vector[N] y;\n    // number of covariate values to make predictions at\n    int&lt;lower=0&gt; no_predictions;\n    // covariate values to make predictions at\n    vector[no_predictions] x_predictions;\n}\n2parameters {\n    // intercept\n    real alpha;\n    // slope\n    real beta;\n    // the standard deviation should be constrained to be positive\n    real&lt;upper=0&gt; sigma;\n}\n3transformed parameters {\n    // deterministic transformation of parameters and data\n    vector[N] mu = alpha + beta * x // linear model\n}\n4model {\n    // observation model / likelihood\n    y ~ normal(mu, sigma);\n}\n5generated quantities {\n    // compute the means for the covariate values at which to make predictions\n    vector[no_predictions] mu_pred = alpha + beta * x_predictions;\n    // sample from the predictive distribution, a normal(mu_pred, sigma).\n    array[no_predictions] real y_pred = normal_rng(mu, sigma);\n}\n\n1\n\nThis is Stan’s data block: “The data block is for the declaration of variables that are read in as data. […] Each variable’s value is validated against its declaration as it is read. For example, if a variable sigma is declared as real&lt;lower=0&gt;, then trying to assign it a negative value will raise an error. As a result, data type errors will be caught as early as possible. Similarly, attempts to provide data of the wrong size for a compound data structure will also raise an error.” For more information, follow the link.\n\n2\n\nThis is Stan’s parameters block: “The variables declared in the parameters program block correspond directly to the variables being sampled by Stan’s samplers (HMC and NUTS). From a user’s perspective, the parameters in the program block are the parameters being sampled by Stan.” For more information, follow the link.\n\n3\n\nThis is Stan’s transformed parameters block: “The transformed parameters program block consists of optional variable declarations followed by statements. After the statements are executed, the constraints on the transformed parameters are validated. Any variable declared as a transformed parameter is part of the output produced for draws.” For more information, follow the link.\n\n4\n\nThis is Stan’s model block: “The model program block consists of optional variable declarations followed by statements. The variables in the model block are local variables and are not written as part of the output. […] The statements in the model block typically define the model. This is the block in which probability (sampling notation) statements are allowed.” For more information, follow the link.\n\n5\n\nThis is Stan’s generated quantities block: “The generated quantities program block is rather different than the other blocks. Nothing in the generated quantities block affects the sampled parameter values. The block is executed only after a sample has been generated.” For more information, follow the link.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nA normal linear model is actually not the best model to use for this type of data, but we will use it here to illustrate the first step in building up to more appropriate, complicated models.\n\n\n\n\n\n\n\n\n\nSubtask 2.a\n\n\n\n\nFind the three mistakes in the code and fix them. Report the original mistakes and your fixes clearly in your report. Include the full corrected Stan code in your report. Verify that sampling was successful.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou may find some of the mistakes in the code using Stan syntax checker. If you copy the Stan code to a file ending .stan and open it in RStudio (you can also choose from RStudio menu File\\(\\rightarrow\\)New File\\(\\rightarrow\\)Stan file to create a new Stan file), the editor will show you some syntax errors. More syntax errors might be detected by clicking `Check’ in the bar just above the Stan file in the RStudio editor. Note that some of the errors in the presented Stan code may not be syntax errors.\n\n\n\nWrite your answers/code here!\n\nThe author runs the corrected Stan file using the following R code and plots the returned MCMC sample. Read through the code below to understand what is being plotted.\n\n\n\n\n\n\nData preparation and sampling from the posterior\n\n\n\n\n\nData assembly happens here:\n\n# These are our observations y: the proportion of students handing in each assignment (1-8),\n# sorted by year (row-wise) and assignment (column-wise).\n# While the code suggest a matrix structure,\n# the result will actually be a vector of length N = no_years * no_assignments\npropstudents&lt;-c(c(176, 174, 158, 135, 138, 129, 126, 123)/176,\n                c(242, 212, 184, 177, 174, 172, 163, 156)/242,\n                c(332, 310, 278, 258, 243, 242, 226, 224)/332,\n                c(301, 269, 231, 232, 217, 208, 193, 191)/301,\n                c(245, 240, 228, 217, 206, 199, 191, 182)/245)\n# These are our predictors x: for each observation, the corresponding assignment number.\nassignment &lt;- rep(1:8, 5)\n# These are in some sense our test data: the proportion of students handing in the last assignment (9),\n# sorted by year.\n# Usually, we would not want to split our data like that and instead\n# use e.g. Leave-One-Out Cross-Validation (LOO-CV, see e.g. http://mc-stan.org/loo/index.html)\n# to evaluate model performance.\npropstudents9 = c(121/176, 153/242, 218/332, 190/301, 175/245)\n# The total number of assignments\nno_assignments = 9\n# The assignment numbers for which we want to generate predictions\nx_predictions = 1:no_assignments\n# (Cmd)Stan(R) expects the data to be passed in the below format:\nmodel_data = list(N=length(assignment),\n                 x=assignment,\n                 y=propstudents,\n                 no_predictions=no_assignments,\n                 x_predictions=x_predictions)\n\nSampling from the posterior distribution happens here:\n\n# This reads the file at the specified path and tries to compile it.\n# If it fails, an error is thrown.\nretention_model = cmdstan_model(\"./additional_files/assignment6_linear_model.stan\")\n\nError in initialize(...): Assertion on 'stan_file' failed: File does not exist: './additional_files/assignment6_linear_model.stan'.\n\n# This \"out &lt;- capture.output(...)\" construction suppresses output from cmdstanr\n# See also https://github.com/stan-dev/cmdstanr/issues/646\nout &lt;- capture.output(\n    # Sampling from the posterior distribution happens here:\n    fit &lt;- retention_model$sample(data=model_data, refresh=0, show_messages=FALSE)\n)\n\nError in eval(expr, envir, enclos): object 'retention_model' not found\n\n\nDraws postprocessing happens here:\n\n# This extracts the draws from the sampling result as a data.frame.\ndraws_df = fit$draws(format=\"draws_df\")\n\nError in eval(expr, envir, enclos): object 'fit' not found\n\n# This does some data/draws wrangling to compute the 5, 50 and 95 percentiles of\n# the mean at the specified covariate values (x_predictions).\n# It can be instructive to play around with each of the data processing steps\n# to find out what each step does, e.g. by removing parts from the back like \"|&gt;  gather(pct,y,-x)\"\n# and printing the resulting data.frame.\nmu_quantiles_df = draws_df |&gt;\n      subset_draws(variable = c(\"mu_pred\")) |&gt;\n      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |&gt;\n      mutate(x = 1:9) |&gt;\n      pivot_longer(c(q5, q50, q95), names_to = c(\"pct\"))\n\nError in UseMethod(\"subset_draws\"): no applicable method for 'subset_draws' applied to an object of class \"function\"\n\n# Same as above, but for the predictions.\ny_quantiles_df = draws_df |&gt;\n      subset_draws(variable = c(\"y_pred\")) |&gt;\n      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |&gt;\n      mutate(x = 1:9) |&gt;\n      pivot_longer(c(q5, q50, q95), names_to = c(\"pct\"))\n\nError in UseMethod(\"subset_draws\"): no applicable method for 'subset_draws' applied to an object of class \"function\"\n\n\n\n\n\nPlotting happens here:\n\nggplot() +\n  # scatter plot of the training data:\n  geom_point(\n    aes(x, y, color=assignment),\n    data=data.frame(x=assignment, y=propstudents, assignment=\"1-8\")\n) +\n  # scatter plot of the test data:\n  geom_point(\n    aes(x, y, color=assignment),\n    data=data.frame(x=no_assignments, y=propstudents9, assignment=\"9\")\n) +\n  # you have to tell us what this plots:\n  geom_line(aes(x,y=value,linetype=pct), data=mu_quantiles_df, color='grey', linewidth=1.5) +\n  # you have to tell us what this plots:\n  geom_line(aes(x,y=value,linetype=pct), data=y_quantiles_df, color='red') +\n  # adding xticks for each assignment:\n  scale_x_continuous(breaks=1:no_assignments) +\n  # adding labels to the plot:\n  labs(y=\"assignment submission %\", x=\"assignment number\") +\n  # specifying that line types repeat:\n  scale_linetype_manual(values=c(2,1,2)) +\n  # Specify colours of the observations:\n  scale_colour_manual(values = c(\"1-8\"=\"black\", \"9\"=\"blue\")) +\n  # remove the legend for the linetypes:\n  guides(linetype=\"none\")\n\nError in eval(expr, envir, enclos): object 'mu_quantiles_df' not found\n\n\n\n\n\n\n\n\nQuick check for sampling convergence\n\n\n\n\n\nIf your model is correctly implemented, sampling from the posterior distribution should have been successful. You can check whether Stan thinks that sampling succeeded by inspecting the output of the below command, which you should be able to interpret with a little help from the CmdStan User’s Guide.\n\nfit$cmdstan_diagnose()\n\nError in eval(expr, envir, enclos): object 'fit' not found\n\n\n\n\n\nBased on the above plot, answer the following questions:\n\n\n\n\n\n\nSubtask 2.b\n\n\n\n\nWhat is the solid red line plotting? What are the dashed red lines? How and why are these different from the corresponding grey lines?\nWhat is the general trend of student retention as measured by assignment submissions?\nGiven a model fitted to the submission data for assignments 1-8, does it do a good job predicting the proportion of students who submit the final 9th assignment?\nName one different modeling choice you could make to improve the prediction.\n\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code included?\n\nNo\nYes\n\nIs the full resulting modified Stan model code presented in the report?\n\nNo\nYes, but partially\nYes, with a few mistakes\nYes, and it is correct\n\nHas the sampling success been verified/summarized (e.g. by inspecting and summarizing the output of CmdStan’s diagnose method).\n\nNo\nYes, but partially\nYes, and it is correctly verified\n\nFix #1: Is there a fix for line .\n\nIt has not been discussed, that this line should be fixed.\nIt has been discussed, that this line should be fixed, but there is no fix presented for it or the fix is clearly wrong.\nThere is a fix presented for this line, that clearly solves the problem.\n\nFix #2: Is there a fix for line .\n\nIt has not been discussed, that this line should be fixed.\nIt has been discussed, that this line should be fixed, but there is no fix presented for it or the fix is clearly wrong.\nThere is a fix presented for this line, that clearly solves the problem.\n\nFix #3: Is there a fix for line .\n\nIt has not been discussed, that this line should be fixed.\nIt has been discussed, that this line should be fixed, but there is no fix presented for it or the fix is clearly wrong.\nThere is a fix presented for this line, that clearly solves the problem.\n\nHave the red lines been correctly described ()?\nHave the grey lines been correctly described ()?\nHas the difference between the red and grey lines been explained ()?\nHas the student retention trend been described ()\nHas the predictive performance for the held out data been discussed and assessed satisfactorily ()?\n\nNo\nSomewhat\nYes\n\nHas at least one way to improve the model been mentioned (E.g. )?\n\n\n\n\n\n3 Generalized linear model: Bioassay with Stan (4 points)\nReplicate the computations for the bioassay example of section 3.7 (BDA3) using Stan.\n\n\n\n\n\n\nSubtask 3.a\n\n\n\nWrite down the model for the bioassay data in Stan syntax. For instructions in reporting your implementation, you can refer to parts 2c.3 - 2c.6 in Assignment 5. Use the Gaussian prior as in Assignment 4 and 5, that is \\[\n\\begin{aligned}\n    \\begin{bmatrix}\n    \\alpha \\\\ \\beta\n    \\end{bmatrix}\n    \\sim\n    \\text{N} \\left( \\mu_0,  \\Sigma_0 \\right), \\qquad\n    \\text{where} \\quad\n     \\mu_0 = \\begin{bmatrix} 0 \\\\ 10 \\end{bmatrix} \\quad \\text{and} \\quad\n     \\Sigma_0 = \\begin{bmatrix} 2^2 & 12 \\\\ 12 & 10^2 \\end{bmatrix}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou will need Stan functions multi_normal and binomial_logit for implementing the prior and observation model, respectively. In Stan code, it is easiest to declare a variable (say theta) which is a two-element vector so that the first value denotes \\(\\alpha\\) and latter one \\(\\beta\\). This is because the multi_normal function that you need for implementing the prior requires a vector as an input.\n\n\n\nWrite your answers/code here!\n\ndata(\"bioassay\")\n\n\n\n\n\n\n\nSubtask 3.b\n\n\n\nUse \\(\\widehat{R}\\) for convergence analysis. You can either use Eq. (11.4) in BDA3 or the later version that can be found in a recent article. You should specify which \\(\\widehat{R}\\) you used. In R the best choice is to use function rhat_basic() or rhat() from the posterior package (see ?posterior::rhat_basic). To check \\(\\widehat{R}\\) and other diagnostics, you can also call fit$summary(), where fit is the fit object returned by Stan’s sampling function. Report the \\(\\widehat{R}\\) values both for \\(\\alpha\\) and \\(\\beta\\) and discuss the convergence of the chains. Briefly explain in your own words how to interpret the obtained \\(\\widehat{R}\\) values.\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nSubtask 3.c\n\n\n\nPlot the draws for \\(\\alpha\\) and \\(\\beta\\) (scatter plot) and include this plot in your report. You can compare the results to Figure 3.3b in BDA3 to verify that your code gives sensible results. Notice though that the results in Figure 3.3b are generated from posterior with a uniform prior, so even when your algorithm works perfectly, the results will look slightly different (although fairly similar).\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nSubtask 3.d\n\n\n\nTo develop the course and provide feedback to Stan developers, we collect information on which Stan setup you used and whether you had any problems in setting it up or using it. Please report,\n\nOperating system (Linux, Mac, Windows) or jupyter.cs.aalto.fi?\nProgramming environment used: R or Python?\nInterface used: RStan, CmdStanR, PyStan, or CmdStanPy?\nDid you have installation or compilation problems? Did you try first installing locally, but switched to jupyter.cs.aalto.fi?\nIn addition of these you can write what other things you found out difficult (or even frustrating) when making this assignment with Stan.\n\n\n\nWrite your answers/code here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the Stan model code included?\n\nNo\nYes\n\nDoes the implemented Stan-model seem to be working?\n\nNo implementation\nModel implemented but results not visualized/reported\nModel implemented, but the results seem weird\nModel seems to work correctly\n\nAre the R_hat-values reported (potential scale reduction factor, Eq. (11.4) in the BDA3)?\n\nNo\nYes, but only for alpha or beta\nYes, single values both for alpha and beta\n\nIs the interpretation of R_hat values correct ()?\n\nNo interpretation or discussion about the R_hat-values, or conclusions clearly wrong\nSomewhat correct\nInterpretation correct\n\nDoes the report contain a scatter plot about the draws? Do the results look reasonable, that is, roughly like in the Figure below ?\n\nNo plot included\nPlot included, but the results do not look like in the figure above\nPlot included, and the results look roughly like in the figure above\n\nDoes the report contain description of Stan setup used and whether there were any problems in setting it up or using it?\n\nNo\nYes\n\nEven if the Stan model code is correct, there might be ways to give improve the layout or write the model in more elegant ways. This optional feedback box can be used to give additional suggestions for better Stan code.\n\n\n\n\n\n4 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Templates",
      "Assignment 6, 2023"
    ]
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "Assignment 4, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 4 and Chapters 3 and 10.\nThe maximum amount of points from this assignment is 6.\nWe have prepared a quarto template specific for this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 3.\nThe reading instructions for BDA3 Chapter 10.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 4. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment4.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\n\n\n\n\n\n2 Bioassay model\nIn this exercise, you will use a dose-response relation model that is used in BDA3 Section 3.7 and in the chapter reading instructions. The used likelihood is the same, but instead of uniform priors, we will use a bivariate normal distribution as the joint prior distribution of the parameters \\(\\alpha\\) and \\(\\beta\\).\nIn the prior distribution for \\((\\alpha,\\beta)\\), the marginal distributions are \\(\\alpha \\sim N(0,2^2)\\) and \\(\\beta \\sim N(10,10^2)\\), and the correlation between them is \\(\\mathrm{corr}(\\alpha, \\beta)=0.6\\).\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nReport the mean (vector of two values) and covariance (two by two matrix) of the bivariate normal distribution.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe mean and covariance of the bivariate normal distribution are a length–\\(2\\) vector and a \\(2 \\times 2\\) matrix. The elements of the covariance matrix can be computed using the relation of correlation and covariance.\n\n\n\nYou are given 4000 independent draws from the posterior distribution of the model in the dataset bioassay_posterior in the aaltobda package.\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nReport\n\nthe mean as well as\n5 \\(\\%\\) and 95 \\(\\%\\) quantiles separately\n\nfor both\n\n\\(\\alpha\\) and\n\\(\\beta\\).\n\nReport also the Monte Carlo standard errors (MCSEs) for the mean and quantile estimates and explain in text what does Monte Carlo standard error mean and how you decided the number of digits to show.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe answer is graded as correct only if the number of digits reported is correct. The number of significant digits can be different for the mean and quantile estimates. In some other cases, the number of digits reported can be less than MCSE allows for practical reasons as discussed in the lecture.\nHint:\nQuantiles can be computed with the quantile function. With \\(S\\) draws, the MCSE for \\(\\text{E}[\\theta]\\) is \\(\\sqrt{\\text{Var} [\\theta]/S}\\). MCSE for the quantile estimates can be computed with the mcse_quantile function from the aaltobda package.\n\n\n\nLoading the library and the data.\n\n# Useful functions: quantile()\n# and mcse_quantile() (from aaltobda)\n\ndata(\"bioassay_posterior\")\n# The 4000 draws are now stored in the variable `bioassay_posterior`.\n# The below displays the first rows of the data:\nhead(bioassay_posterior)\n\n        alpha      beta\n1 -0.02050577 10.032841\n2  1.21738518  4.504546\n3  3.04829407 16.239424\n4  1.32272770  4.924268\n5  1.36274817 12.880561\n6  1.08593225  5.943731\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nAre the mean and covariance of the prior in a) reported? The correct answers are :\n\nNot reported\nYes, but they are not correct\nYes, and they are correct\n\nAre the means and their MCSEs of alpha and beta in b) reported? Note that the number of digits reported for the means must follow the rule given in the assignment. The correct answers are alpha: mean and beta: mean .\n\nNot reported\nYes, but one or both means are incorrect\nYes, and the means are correct\n\nAre the quantiles and their MCSEs of alpha and beta in b) reported? Note that the number of digits reported for the quantiles must follow the rule given in the assignment. The correct answers are alpha: 5% quantile , 95% quantile and beta: 5% quantile , 95% quantile .\n\nNot reported\nYes, but one or more quantiles are incorrect\nYes, and the quantiles are correct\n\n\n\n\n\n\n3 Importance sampling\nNow we discard our posterior draws and switch to importance sampling.\n\n\n\n\n\n\nSubtask 3.c)\n\n\n\nImplement a function for computing the log importance ratios (log importance weights) when the importance sampling target distribution is the posterior distribution, and the proposal distribution is the prior distribution from a). Explain in words why it’s better to compute log ratios instead of ratios.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNon-log importance ratios are given by equation (10.3) in the course book. The fact that our proposal distribution is the same as the prior distribution makes this task easier. The logarithm of the likelihood can be computed with the bioassaylp function from the aaltobda package. The data required for the likelihood can be loaded with data(\"bioassay\").\n\n\n\n\n# Useful functions: bioassaylp (from aaltobda)\nalpha_test = c(1.896, -3.6,  0.374, 0.964, -3.123, -1.581)\nbeta_test = c(24.76, 20.04, 6.15, 18.65, 8.16, 17.4)\n\n\nlog_importance_weights &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(-8.95, -23.47, -6.02, -8.13, -16.61, -14.57)\n}\n\n\n\n\n\n\n\nSubtask 3.d)\n\n\n\nImplement a function for computing normalized importance ratios from the unnormalized log ratios in c). In other words, exponentiate the log ratios and scale them such that they sum to one. Explain in words what is the effect of exponentiating and scaling so that sum is one.\n\n\n\nnormalized_importance_weights &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.045, 0.000, 0.852, 0.103, 0.000, 0.000)\n}\n\n\n\n\n\n\n\nSubtask 3.e)\n\n\n\nSample 4000 draws of \\(\\alpha\\) and \\(\\beta\\) from the prior distribution from a). Compute and plot a histogram of the 4000 normalized importance ratios. Use the functions you implemented in c) and d).\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUse the function rmvnorm from the aaltobda package for sampling.\n\n\n\nWrite your answers and code here!\n\n\n\n\n\n\nSubtask 3.f)\n\n\n\nUsing the importance ratios, compute the importance sampling effective sample size \\(S_{\\text{eff}}\\) and report it.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEquation (10.4) in the course book.\nBDA3 1st (2013) and 2nd (2014) printing have an error for \\(\\tilde{w}(\\theta^s)\\) used in the effective sample size equation (10.4). The normalized weights equation should not have the multiplier S (the normalized weights should sum to one). The later printings, the online version, and the slides have the correct equation.\n\n\n\n\nS_eff &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    1.354\n}\n\n\n\n\n\n\n\nSubtask 3.g)\n\n\n\nExplain in your own words what the importance sampling effective sample size represents. Also explain how the effective sample size is seen in the histogram of the weights that you plotted in e).\n\n\n\n\n\n\n\n\nSubtask 3.h)\n\n\n\nImplement a function for computing the posterior mean using importance sampling, and compute the mean using your 4000 draws. Explain in your own words the computation for importance sampling. Report the means for \\(\\alpha\\) and \\(\\beta\\), and also the Monte Carlo standard errors (MCSEs) for the mean estimates. Report the number of digits for the means based on the MCSEs.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe values below are only a test case, you need to use 4000 draws for \\(\\alpha\\) and \\(\\beta\\) in the final report.\nUse the same equation for the MCSE of \\(\\text{E}[\\theta]\\) as earlier (\\(\\sqrt{\\text{Var} [\\theta]/S}\\)), but now replace \\(S\\) with \\(S_{\\text{eff}}\\). To compute \\(\\text{Var} [\\theta]\\) with importance sampling, use the identity \\(\\text{Var}[\\theta] = \\text{E}[\\theta^2] - \\text{E}[\\theta]^2\\).\n\n\n\n\nposterior_mean &lt;- function(alpha, beta) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.503, 8.275)\n}\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code for the function in c) reported?\n\nNo\nYes\n\nIs the source code for the function in d) reported?\n\nNo\nYes\n\nDoes the histogram in e) look something like this figure? If it is evident that the normalized importance ratios are computed correctly, but the prior was incorrect, you can still grade “Reported and looks similar”.\n\nNot reported\nReported, but looks different\nReported and looks similar\n\nIs the effective sample size in f) reported? The correct range for the effective sample size is between . However, if it is evident that the effective sample size is computed correctly, but the prior was incorrect, you can still grade “Yes, and it is correct”.\n\nNo\nYes, but it is not correct\nYes, and it is correct\n\nThe correct explanation for g) is roughly the following: \nWhat is the connection between S_eff and the histogram of weights: How is the answer?\n\nTotally wrong/has not tried\nSomething is a bit wrong\nExplanation is sensible\n\nIs the source code for the function in h) reported?\n\nNo\nYes\n\nAre the means and their MCSEs of alpha and beta in h) reported? Note that the number of digits reported for the means must follow the rule given in the assignment. The correct answers should be close to these: alpha: mean and beta: mean\n\nNot reported\nYes, but they are incorrect\nYes, and they are correct\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n4 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Assignments",
      "Assignment 4, 2023"
    ]
  },
  {
    "objectID": "template8.html",
    "href": "template8.html",
    "title": "Assignment 8, 2023",
    "section": "",
    "text": "This is for BDA 2023\nThe maximum amount of points from this assignment is 6.\nWe have prepared a quarto template specific to this assignment (html, qmd, pdf) to help you get started.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nWe recommend Aalto students use jupyter.cs.aalto.fi, for all others we also provide a docker container.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 6 (posterior predictive checking).\nThe reading instructions for BDA3 Chapter 7 (predictive performance).\nThe ’loo‘ package vignette on the basics of LOO shows an example of how to modify Stan code and use the package with Stan models.\nAlso read about PSIS-LOO in the PSIS-LOO paper.\nCV-FAQ includes a lot of informative answers to frequent questions and misconceptions.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\nInstalling and using CmdStanR:\nSee the Stan demos on how to use Stan in R (or Python). Aalto JupyterHub has working R and CmdStanR/RStan environment and is probably the easiest way to use Stan. * To use CmdStanR in Aalto JupyterHub: library(cmdstanr) set_cmdstan_path('/coursedata/cmdstan')\nThe Aalto Ubuntu desktops also have the necessary libraries installed.\nTo install Stan on your laptop, run ‘install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))’ in R. If you encounter problems, see additional answers in FAQ. For Aalto students, if you don’t succeed in short amount of time, it is probably easier to use Aalto JupyterHub.\nIf you use Aalto JupyterHub, all necessary packages have been pre-installed. In your laptop, install package cmdstanr. Installation instructions on Linux, Mac and Windows can be found at https://mc-stan.org/cmdstanr/. Additional useful packages are loo, bayesplot and posterior (but you don’t need these in this assignment). For Python users, PyStan, CmdStanPy, and ArviZ packages are useful.\nStan manual can be found at https://mc-stan.org/users/documentation/. From this website, you can also find a lot of other useful material about Stan.\nIf you edit files ending .stan in RStudio, you can click “Check” in the editor toolbar to make syntax check. This can significantly speed-up writing a working Stan model.\n\n\n\n\n\n\n\n\n\nReporting accuracy\n\n\n\n\n\nFor posterior statistics of interest, only report digits that are not completely random based on the Monte Carlo standard error (MCSE).\nExample: If you estimate \\(E(\\mu) \\approx 1.234\\) with MCSE(\\(E(\\mu)\\)) = 0.01, then the true expectation is likely to be between \\(1.204\\) and \\(1.264\\), it makes sense to report \\(E(\\mu) \\approx 1.2\\).\nSee Lecture video 4.1, the chapter notes, and a case study for more information.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\nThis is the template for assignment 8. You can download the qmd-file or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThe following loads several needed packages:\n\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1.9000\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /u/77/ave/unix/.cmdstan/cmdstan-2.35.0-rc3\n\n\n- CmdStan version: 2.35.0\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(ggdist) # for stat_dotsinterval\nlibrary(posterior)\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\nlibrary(brms)\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.21.6). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following objects are masked from 'package:ggdist':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\n# Globally specfiy cmdstan backend for brms\noptions(brms.backend=\"cmdstanr\")\n# Tell brms to cache results if possible\noptions(brms.file_refit=\"on_change\")\n\n# Set more readable themes with bigger font for plotting packages\nggplot2::theme_set(theme_minimal(base_size = 14))\nbayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template8.html#exploratory-data-analysis",
    "href": "template8.html#exploratory-data-analysis",
    "title": "Assignment 8, 2023",
    "section": "2.1 Exploratory data analysis",
    "text": "2.1 Exploratory data analysis\nIn the first part of this assignment, you will explore the dataset ChickWeight. In particular, you will see what information is recorded in the dataset, and how you can use visualisation to learn more about the dataset. More information can be found on the corresponding page of the R documentation.\n\nhead(ChickWeight, 10)\n\nGrouped Data: weight ~ Time | Chick\n   weight Time Chick Diet\n1      42    0     1    1\n2      51    2     1    1\n3      59    4     1    1\n4      64    6     1    1\n5      76    8     1    1\n6      93   10     1    1\n7     106   12     1    1\n8     125   14     1    1\n9     149   16     1    1\n10    171   18     1    1\n\n\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nCreate a histogram to explore the range of chicken weights. Describe what you see in the plot. What is the qualitative range of the data?\n\n\n\n# Useful functions: ggplot, aes(x=...), geom_histogram\n\n### {.content-hidden when-profile=\"public\"}\nggplot(data = ChickWeight, aes(x=ChickWeight$weight)) +\n  geom_histogram()\n\nWarning: Use of `ChickWeight$weight` is discouraged.\nℹ Use `weight` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nHas it been stated that the data takes on only values which are ?\n\n\n\n\n\n\n\n\n\nSubtask 2.b\n\n\n\nPlot the weight of each chicken over time in a line plot. Add colours based on the diet. Describe what you see in the plot.\n\n\n\n# Useful functions: ggplot, aes(x=...,y=...,group=...,color=...), geom_line\n\n### {.content-hidden when-profile=\"public\"}\nggplot(data = ChickWeight, aes(x=Time, y=weight, group = Chick, color=Diet)) +\n  geom_line()\n\n\n\n\n\n\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template8.html#linear-regression",
    "href": "template8.html#linear-regression",
    "title": "Assignment 8, 2023",
    "section": "2.2 Linear regression",
    "text": "2.2 Linear regression\nIn this section, you will build a model that predicts the weight of a chicken over time and depending on the diet. After sampling from the posteriors, you will use posterior predictive checks to see how well the predictions match the observations. Then you will adjust the model by adding more complexity, and check again.\n\n\n\n\n\n\nSubtask 2.c\n\n\n\nUsing brms, implement a pooled linear regression with a normal model and weight as the predicted variable using Diet and Time as predictors. Try to use weakly informative priors.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFor the prior on Time, consider how much the weight of a chicken (in grams) could possibly change each day. For the priors on the effects of different diets, consider how much average weight difference would be possible between diets.\nNote that as Diet is a categorical variable, the priors need to be specified for each category (apart from Diet1 which is taken to be the baseline).\n\n\n\nIn brms, a regression can be specified as below, see also below (#m) or the last template. Fill in the appropriate variables, data, and likelihood family. Specify the priors, then run the model (by removing #| eval: false below).\n\npriors &lt;- c(\n  prior(normal(0, &lt;value&gt;), coef = \"Time\"),\n  prior(normal(0, &lt;value&gt;), coef = \"Diet2\"),\n  prior(normal(0, &lt;value&gt;), coef = \"Diet3\"),\n  prior(normal(0, &lt;value&gt;), coef = \"Diet4\")\n)\n\nf1 &lt;- brms::brm(\n  # This specifies the formula\n  &lt;OUTCOME&gt; ~ 1 + &lt;PREDICTOR&gt; + &lt;PREDICTOR&gt;,\n  # This specifies the dataset\n  data = &lt;data&gt;,\n  # This specifies the observation model family\n  family = &lt;observation_family&gt;,\n  # This passes the priors specified above to brms\n  prior = priors,\n  # This causes brms to cache the results\n  file = \"additional_files/assignment8/f1\"\n)\n\n### {.content-hidden when-profile=\"public\"}\npriors &lt;- c(\n  prior(normal(0, 10), coef = \"Time\"),\n  prior(normal(0, 50), coef = \"Diet2\"),\n  prior(normal(0, 50), coef = \"Diet3\"),\n  prior(normal(0, 50), coef = \"Diet4\")\n)\n\nf1 &lt;- brms::brm(\n  weight ~ 1 + Diet + Time,\n  data = ChickWeight,\n  family = \"gaussian\",\n  prior = priors\n)\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the brms-formula ?\nIs the family ?\nAre the prior standard deviations reasonable, e.g. around ?\n\n\n\nNext, you can use the bayesplot package to check the posterior predictions in relation to the observed data using the pp_check function. The function plots the \\(y\\) values, which are the observed data, and the \\(y_\\text{rep}\\) values, which are replicated data sets from the posterior predictive distribution.\n\n\n\n\n\n\nSubtask 2.d\n\n\n\nPerform the posterior predictive check with the default arguments. What do you observe? Based on the plot, do the posterior predictions encapsulate the main features of the observed data? Point out any major differences between the predictions and the observed data. Answer the following questions:\n\nAre there qualitative differences between the observed data and the predicted data?\nDo the observed data seem quantitatively similar?\n\n\n\n\n# Useful functions: brms::pp_check\n\n### {.content-hidden when-profile=\"public\"}\nbrms::pp_check(f1, plotfun=\"hist\")\n\nError in eval(expr, envir, enclos): object 'f1' not found\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nHas it been recognized that the predicted data include ?\nHas it been recognized that the observed and predicted data ?\n\n\n\nThe default density plot is not always informative, but bayesplot has different settings that can be used to create plots more appropriate for specific data.\n\n\n\n\n\n\nSubtask 2.e\n\n\n\nCreate another plot with grouping to the PPC plot using the arguments type = \"intervals_grouped\" and group = \"Diet\". What do you observe? Point out any major differences between the predictions and the observed data. Based on your visualisations, how could the model be improved?\n\n\n\n# Useful functions: brms::pp_check(..., type = ..., group=...)\n\n### {.content-hidden when-profile=\"public\"}\nbrms::pp_check(..., type = \"intervals_grouped\", group=\"Diet\")\n\nError in eval(expr, envir, enclos): '...' used in an incorrect context\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nIs there at least one reasonable way to improve the model, e.g. ?",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template8.html#log-normal-linear-regression",
    "href": "template8.html#log-normal-linear-regression",
    "title": "Assignment 8, 2023",
    "section": "2.3 Log-normal linear regression",
    "text": "2.3 Log-normal linear regression\nBased on the identified issues from the posterior predictive check, the model can be improved. It is advisable to change only one or a few things about a model at once. At this stage, focus on changing the observation model family to better account for the observed data.\nOne option is to use the lognormal observation model, which only allows positive values. In brms you can change the observation model family to this by setting the argument family = \"lognormal\". Note that when using the log-normal observation model, the regression coefficients represent the change in the log weight of a chicken. The priors have been adjusted accordingly in the template.\n\n\n\n\n\n\nSubtask 2.f\n\n\n\nAdjust the model, sample from the posterior and create the same two posterior predictive check plots. Comment on your observations. Does the new model better capture some aspects of the data?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n\n\n\nlog_priors &lt;- c(\n  prior(normal(0, log(3)), coef = \"Time\"),\n  prior(normal(0, log(5)), coef = \"Diet2\"),\n  prior(normal(0, log(5)), coef = \"Diet3\"),\n  prior(normal(0, log(5)), coef = \"Diet4\")\n)\n\n### {.content-hidden when-profile=\"public\"}\nf2 &lt;- brm(\n  weight ~ Diet + Time,\n  data = ChickWeight,\n  family = \"lognormal\",\n  prior = priors\n)\n\nError in eval(expr, envir, enclos): object 'priors' not found\n\n# criticism with ppc density (not grouped)\nbrms::pp_check(f2)\n\nError in eval(expr, envir, enclos): object 'f2' not found\n\n# information for each chicken\nbrms::pp_check(f2, type = \"intervals_grouped\", group = \"Diet\")\n\nError in eval(expr, envir, enclos): object 'f2' not found\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the plots look correct and are they readable?\nHas it been recognized that the fit to data is ?",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template8.html#hierarchical-log-normal-linear-regression",
    "href": "template8.html#hierarchical-log-normal-linear-regression",
    "title": "Assignment 8, 2023",
    "section": "2.4 Hierarchical log-normal linear regression",
    "text": "2.4 Hierarchical log-normal linear regression\nThe model can further be improved by directly considering potential differences in growth rate for individual chicken. Some chickens may innately grow faster than others, and this difference can be included by including both population and group level effects in to the model.\nTo include a group effect in brms, the code + (predictor|group) can be added to the model formula. In this case, the predictor is Time and the group is Chick.\n\n\n\n\n\n\nSubtask 2.g\n\n\n\nCreate the same two plots as for the previous models. Comment on what you see. Do the predictions seem to better capture the observed data? Are there remaining discrepancies between the predictions and observed data that could be addressed?\n\n2.4.1 \n\npriors &lt;- c(\n  prior(normal(0, log(3)), coef = \"Time\"),\n  prior(normal(0, log(5)), coef = \"Diet2\"),\n  prior(normal(0, log(5)), coef = \"Diet3\"),\n  prior(normal(0, log(5)), coef = \"Diet4\")\n)\n\nf3 &lt;-  brm(\n  weight ~ Diet + Time + (Time|Chick),\n  data = ChickWeight,\n  family = \"lognormal\",\n  prior = priors\n)\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 9.5 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 10.6 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 8.7 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 9.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 9.6 seconds.\nTotal execution time: 39.0 seconds.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.35.0.9000 (Stan version 2.35.0)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following objects are masked from 'package:posterior':\n\n    ess_bulk, ess_tail\n\n\n\n\n2.4.2 \n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the plots look correct and are they readable?\nHas it been recognized that the fit to data is ?\n\n\n\n\n\n\n\n\n\nSubtask 2.h\n\n\n\nHave you encountered any convergence issues in the above models? Report and comment.\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nHas there been a potentially brief discussion of the standard convergence criteria (Rhat, ESS, divergent transitions) for all models?",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template8.html#model-comparison-using-the-elpd",
    "href": "template8.html#model-comparison-using-the-elpd",
    "title": "Assignment 8, 2023",
    "section": "2.5 Model comparison using the ELPD",
    "text": "2.5 Model comparison using the ELPD\nThere are many ways of comparing models1. Commonly, we evaluate point predictions, such as the mean of the predictive distribution2, or accuracy of the whole posterior predictive. Whether we prioritise point or density predictive accuracy may serve different purposes and lead to different outcomes for model choice 3. It is common, however, to report predictive accuracy via log-scores and point-predictive accuracy via root-mean-squared-error based on the empirical average of the predictive distribution. To cross-validate both metrics on left out observations without need to sample from each leave-one-out posterior, we use Pareto-smoothed importance sampling as discussed in the course materials (see Lecture 8).\nWe start comparing models based on the log-score. Use loo::loo() and loo::loo_compare() to quantify the differences in predictive performance.\n\n\n\n\n\n\nSubtask 2.i\n\n\n\nAnswer the following questions using loo/loo_compare:\n\nWhich model has the best predictive performance?\nDoes the uncertainty influence the decision of which model is best?\n\n\n\n\n# Useful functions: loo, loo_compare\n\n### {.content-hidden when-profile=\"public\"}\nloo_f1 &lt;- loo(f1)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f1' not found\n\nloo_f1\n\nError in eval(expr, envir, enclos): object 'loo_f1' not found\n\nloo_f2 &lt;- loo(f2)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f2' not found\n\nloo_f2\n\nError in eval(expr, envir, enclos): object 'loo_f2' not found\n\nloo_f3 &lt;- loo(f3)\n\nWarning: Found 3 observations with a pareto_k &gt; 0.7 in model 'f3'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\nloo_f3\n\n\nComputed from 4000 by 578 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo  -2253.7 27.0\np_loo        77.8  6.5\nlooic      4507.5 54.0\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.3, 1.5]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     575   99.5%   63      \n   (0.7, 1]   (bad)        3    0.5%   &lt;NA&gt;    \n   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\nloo_compare(loo_f1, loo_f2, loo_f3)\n\nError in eval(expr, envir, enclos): object 'loo_f1' not found\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the results look correct and have they been presented in a readable way? They should be roughly .\nHas it been recognized that the best model is ?\n\n\n\n\n\n\n\n\n\nSubtask 2.j\n\n\n\nAssess whether the approximation to the LOO-CV distributions are reliable. Consult the \\(\\hat{k}\\) statistic which informs on the reliability of PSIS computation in PSIS-LOO. Plot the \\(\\hat{k}\\) values for each model against the data point ID and discuss. Are they as expected?\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFor hierarchical models, it may be more important to think about how well the individual group is predicted and how many observations there are in a group compared to the number of parameters estimated. Also check out CV-FAQ on high Pareto-\\(\\hat{k}\\) values.\n\n\n\n\n# Useful functions: plot(loo(...), label_points = TRUE)\n### {.content-hidden when-profile=\"public\"}\nplot(loo(f1), label_points = TRUE)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f1' not found\n\nplot(loo(f2), label_points = TRUE)\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': error in evaluating the argument 'x' in selecting a method for function 'loo': object 'f2' not found\n\nplot(loo(f3), label_points = TRUE)\n\nWarning: Found 3 observations with a pareto_k &gt; 0.7 in model 'f3'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\n\n\n\n\n\n\n\n###\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the plots look correct and are they readable?\nHas it been explained why the \\(\\hat{k}\\) values are highest for the .\n\n\n\n\n\n\n\n\n\nSubtask 2.k\n\n\n\nPerform a PPC for the hierarchical model for\n\na few of the chickens with the highest \\(\\hat{k}\\) values and\na few of the chickens with the lowest \\(\\hat{k}\\) values\n\nusing the code in the template. What do you observe?\n\n\n\n\n\n\n\n\nCreating a dummy example plot\n\n\n\n\n\nCreating a dummy fit just to be able to generate an example plot below. Generate a similar plot for your hierarchical model.\n\n# The brms-formula (weights ~ ...) below is not one that you should be using in your models!\ndummy_fit &lt;- brms::brm(\n  weight ~ 1 + Time + Chick,\n  data = ChickWeight,\n  file=\"additional_files/assignment8/dummy_fit\"\n)\n# Adjust the chicken_idxs variable to select appropriate chickens\nchicken_idxs = c(1,3,11,43)\n# Create this plot for your hierarchical model for selected chickens\nbrms::pp_check(\n  dummy_fit, type = \"intervals_grouped\", group = \"Chick\",\n  newdata=ChickWeight |&gt; filter(Chick %in% chicken_idxs)\n)\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the plot look correct and is it readable?\nHas it been recognized that the chickens with high \\(\\hat{k}\\) values ?",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template8.html#model-comparison-using-the-rmse",
    "href": "template8.html#model-comparison-using-the-rmse",
    "title": "Assignment 8, 2023",
    "section": "2.6 Model comparison using the RMSE",
    "text": "2.6 Model comparison using the RMSE\n\n\n\n\n\n\nSubtask 2.l\n\n\n\nUse the function in the template to compare the RMSE and the LOO-RMSE for the three models. Explain the difference between the RMSE and the LOO-RMSE in 1–3 sentences. Is one generally lower than the other? Why?\n\n\n\n\n\n\n\n\nrmse function implementation\n\n\n\n\n\nThe below function takes a brms fit object and computes either the root-mean-square error (RMSE) or the PSIS-LOO-RMSE, i.e. the RMSE using LOO-CV estimated using PSIS-LOO.\n\n# Compute RMSE or LOO-RMSE\nrmse &lt;- function(fit, use_loo=FALSE){\n  mean_y_pred &lt;- if(use_loo){\n    brms::loo_predict(fit)\n  }else{\n    colMeans(brms::posterior_predict(fit))\n  }\n  sqrt(mean(\n    (mean_y_pred - brms::get_y(fit))^2\n  ))\n}\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nDo the results look correct and have they been presented in a readable way? They should be roughly: .\nHas it been recognized that the RMSE is ?",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template8.html#footnotes",
    "href": "template8.html#footnotes",
    "title": "Assignment 8, 2023",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn principle, when comparing models based on accuracy in predictions or parameter estimation (if true parameter values are available to you, as e.g. in simulation studies), we want to use so called strictly proper scoring rules that will always indicate when a “better” model is better and the score reaches its uniquely defined best value at the “true” model, if it is also well defined. See Gneiting and Raftery, (2007) for an in depth treatment of this topic.↩︎\nNOT predictions based on the mean of the posterior parameters, but first generating the predictive distribution and then computing an average.↩︎\nFor instance, a unimodal and bimodal predictive density may have the same expected value, but very different areas of high posterior density and therefore very different log-scores.↩︎",
    "crumbs": [
      "Templates",
      "Assignment 8, 2023"
    ]
  },
  {
    "objectID": "template3.html",
    "href": "template3.html",
    "title": "Assignment 3, 2023",
    "section": "",
    "text": "1 General information\nThis is for BDA 2023\nThis assignment is related to Lecture 3 and BDA3 Chapters 2 and 3. Use Frank Harrell’s recommendations on how to state results in Bayesian two group comparisons (and note that there is no point null hypothesis testing in this assignment).\nThe maximum amount of points from this assignment is 9.\nWe have prepared two quarto templates specific to this assignment to help you get started:\n\nA recommended template (html, qmd, pdf) which uses some additional packages, which however requires a bit more set-up work to run and\na simple template (html, qmd, pdf) which doesn’t use those additional packages and is therefore easier to get to run.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nReading instructions:\n\nThe reading instructions for BDA3 Chapter 1.\nThe reading instructions for BDA3 Chapter 2.\n\nGrading instructions:\nThe grading will be done in peergrade. All grading questions and evaluations for this assignment are contained within this document in the collapsible Rubric blocks.\n\n\n\n\n\n\n\n\n\nFurther information\n\n\n\n\n\n\nThe recommended tool in this course is R (with the IDE RStudio).\nInstead of installing R and RStudio on you own computer, see how to use R and RStudio remotely.\nIf you want to install R and RStudio locally, download R and RStudio.\nThere are tons of tutorials, videos and introductions to R and RStudio online. You can find some initial hints from RStudio Education pages.\nWhen working with R, we recommend writing the report using quarto and the provided template. The template includes the formatting instructions and how to include code and figures.\nInstead of quarto, you can use other software to make the PDF report, but the the same instructions for formatting should be used.\nReport all results in a single, anonymous *.pdf -file and submit it in peergrade.io.\nThe course has its own R package aaltobda with data and functionality to simplify coding. The package is pre-installed in JupyterHub. To install the package on your own system, run the following code (upgrade=\"never\" skips question about updating other packages):\n\ninstall.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n\nMany of the exercises can be checked automatically using the R package markmyassignment (pre-installed in JupyterHub). Information on how to install and use the package can be found in the markmyassignment documentation. There is no need to include markmyassignment results in the report.\nRecommended additional self study exercises for each chapter in BDA3 are listed in the course web page. These will help to gain deeper understanding of the topic.\nCommon questions and answers regarding installation and technical problems can be found in Frequently Asked Questions (FAQ).\nDeadlines for all assignments can be found on the course web page and in Peergrade. You can set email alerts for the deadlines in Peergrade settings.\nYou are allowed to discuss assignments with your friends, but it is not allowed to copy solutions directly from other students or from internet.\nYou can copy, e.g., plotting code from the course demos, but really try to solve the actual assignment problems with your own code and explanations.\nDo not share your answers publicly.\nDo not copy answers from the internet or from previous years. We compare the answers to the answers from previous years and to the answers from other students this year.\nUse of AI is allowed on the course, but the most of the work needs to by the student, and you need to report whether you used AI and in which way you used them (See points 5 and 6 in Aalto guidelines for use of AI in teaching).\nAll suspected plagiarism will be reported and investigated. See more about the Aalto University Code of Academic Integrity and Handling Violations Thereof.\nDo not submit empty PDFs, almost empty PDFs, copy of the questions, nonsense generated by yourself or AI, as these are just harming the other students as they can’t do peergrading for the empty or nonsense submissions. Violations of this rule will be reported and investigated in the same way was plagiarism.\nIf you have any suggestions or improvements to the course material, please post in the course chat feedback channel, create an issue, or submit a pull request to the public repository!\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nCan you open the PDF and it’s not blank nor nonsense? If the pdf is blank, nonsense, or something like only a copy of the questions, 1) report it as problematic in Peergrade-interface to get another report to review, and 2) send a message to TAs.\nIs the report anonymous?\n\n\n\n\n\n\n\n\n\nSetup\n\n\n\n\n\nThis is the template for assignment 3. You can download qmd-files (full, simple) or copy the code from this rendered document after clicking on &lt;/&gt; Code in the top right corner.\nPlease replace the instructions in this template by your own text, explaining what you are doing in each exercise.\nThe following will set-up markmyassignment to check your functions at the end of the notebook:\n\nif(!require(markmyassignment)){\n    install.packages(\"markmyassignment\")\n    library(markmyassignment)\n}\n\nLoading required package: markmyassignment\n\nassignment_path = paste(\"https://github.com/avehtari/BDA_course_Aalto/\",\n\"blob/master/assignments/tests/assignment3.yml\", sep=\"\")\nset_assignment(assignment_path)\n\nError in get_file.path_github(path = path, dest = temp_file): Not Found (HTTP 404).\n\n\nThe following installs and loads the aaltobda package:\n\nif(!require(aaltobda)){\n    install.packages(\"aaltobda\", repos = c(\"https://avehtari.github.io/BDA_course_Aalto/\", getOption(\"repos\")))\n    library(aaltobda)\n}\n\nLoading required package: aaltobda\n\n\nThe following installs and loads the latex2exp package, which allows us to use LaTeX in plots:\n\nif(!require(latex2exp)){\n    install.packages(\"latex2exp\")\n    library(latex2exp)\n}\n\nLoading required package: latex2exp\n\n\n\n\n\n\n\n\n\n\n\nSetting up advanced packages (posterior and ggdist)\n\n\n\n\n\nThe following installs and loads the posterior package, which allows us to use its rvar Random Variable Datatype:\n\nif(!require(posterior)){\n    install.packages(\"posterior\")\n    library(posterior)\n}\n\nLoading required package: posterior\n\n\nThis is posterior version 1.6.0\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:aaltobda':\n\n    mcse_quantile\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nThe following installs and loads the ggdist package for advanced plotting functions:\n\nif(!require(ggplot2)){\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n}\n\nLoading required package: ggplot2\n\nggplot2::theme_set(theme_minimal(base_size = 14))\nif(!require(ggdist)){\n    install.packages(\"ggdist\")\n    library(ggdist)\n}\n\nLoading required package: ggdist\n\n\n\n\n\n\n\n2 Inference for normal mean and deviation (3 points)\nA factory has a production line for manufacturing car windshields. A sample of windshields has been taken for testing hardness. The observed hardness values \\(\\mathbf{y}_1\\) can be found in the dataset windshieldy1 in the aaltobda package.\nWe may assume that the observations follow a normal distribution with an unknown standard deviation \\(\\sigma\\). We wish to obtain information about the unknown average hardness \\(\\mu\\). For simplicity we assume standard uninformative prior discussed in the book, that is, \\(p(\\mu, \\sigma) \\propto \\sigma^{-1}\\). It is not necessary to derive the posterior distribution in the report, as it has already been done in the book (see section 3.2).\nLoading the library and the data.\n\ndata(\"windshieldy1\")\n# The data are now stored in the variable `windshieldy1`.\n# The below displays the data:\nwindshieldy1\n\n[1] 13.357 14.928 14.896 15.297 14.820 12.067 14.824 13.865 17.447\n\n\nThe below data is only for the tests, you need to change to the full data windshieldy1 when reporting your results.\n\nwindshieldy_test &lt;- c(13.357, 14.928, 14.896, 14.820)\n\n\n\n\n\n\n\nSubtask 2.a)\n\n\n\nFormulate\n\nthe likelihood,\nthe prior, and\nthe resulting posterior.\n\n\n\nWrite your answers here!\n\n\n\n\n\n\nSubtask 2.b)\n\n\n\nWhat can you say about the unknown \\(\\mu\\)?\n\nCompute and report the point estimate \\(E(\\mu|y)\\),\ncompute and report a posterior 95%-interval,\nplot the density, and\nwrite interpretation of the result in text.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nPosterior intervals are also called credible intervals and are different from confidence intervals.\n\n\n\nWrite your answers and code here!\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful functions: mean(), length(), sqrt(), sum()\n# and qtnew(), dtnew() (from aaltobda)\n\nmu_point_est &lt;- function(data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    14.5\n    ### {.content-hidden when-profile=\"public\"}\n    mean(data)\n    ###\n}\nmu_interval &lt;- function(data, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(13.3, 15.7)\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-location)^2)\n    )/n)\n    ql = (1-prob)/2\n    qu = prob + (1-prob)/2\n    qtnew(c(ql, qu), df, location, scale)\n    ###\n}\n\nYou can plot the density as below if you implement mu_pdf to compute the PDF of the posterior \\(p(\\mu|y)\\) of the average hardness \\(\\mu\\).\n\nmu_pdf &lt;- function(data, x){\n    # Compute necessary parameters here.\n    # These are the correct parameters for `windshieldy_test`\n    # with the provided uninformative prior.\n    df = 3\n    location = 14.5\n    scale = 0.3817557\n    # Use the computed parameters as below to compute the PDF:\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-location)^2)\n    )/n)\n    ###\n    dtnew(x, df, location, scale)\n}\n\nx_interval = mu_interval(windshieldy1, .999)\nlower_x = x_interval[1]\nupper_x = x_interval[2]\nx = seq(lower_x, upper_x, length.out=1000)\nplot(\n    x, mu_pdf(windshieldy1, x), type=\"l\",\n    xlab=TeX(r'(average hardness $\\mu$)'),\n    ylab=TeX(r'(PDF of the posterior $p(\\mu|y)$)')\n)\n\n\n\n\n\n\n\nFigure 1: PDF of the posterior \\(p(\\mu|y)\\) of the average hardness \\(\\mu\\)\n\n\n\n\n\n\n\n\n\n\n\nSubtask 2.c)\n\n\n\nWhat can you say about the hardness of the next windshield coming from the production line before actually measuring the hardness?\n\nCompute and report the point estimate \\(E(\\tilde{y}|y)\\),\ncompute and report a posterior predictive 95%-interval,\nplot the density, and\nwrite interpretation of the result in text.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nPredictive intervals are different from posterior intervals.\nWith a conjugate prior a closed form posterior is Student’s \\(t\\) form (see equations in the book).\n\n\n\nWrite your answers and code here!\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful functions: mean(), length(), sqrt(), sum()\n# and qtnew(), dtnew() (from aaltobda)\n\nmu_pred_point_est &lt;- function(data) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    14.5\n    ### {.content-hidden when-profile=\"public\"}\n    mean(data)\n    ###\n}\nmu_pred_interval &lt;- function(data, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(11.8, 17.2)\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-location)^2)\n    )*(1+1/n))\n    ql = (1-prob)/2\n    qu = prob + (1-prob)/2\n    qtnew(c(ql, qu), df, location, scale)\n    ###\n}\n\nYou can plot the density as below if you implement mu_pred_pdf to compute the PDF of the posterior predictive \\(p(\\tilde{y}|y)\\) of a new hardness observation \\(\\tilde{y}\\).\n\nmu_pred_pdf &lt;- function(data, x){\n    # Compute necessary parameters here.\n    # These are the correct parameters for `windshieldy_test`\n    # with the provided uninformative prior.\n    df = 3\n    location = 14.5\n    scale = 0.8536316\n    # Use the computed parameters as below to compute the PDF:\n    ### {.content-hidden when-profile=\"public\"}\n    n = length(data)\n    df = n-1\n    location = mean(data)\n    scale = sqrt((\n        1/(n-1) * sum((data-mean(data))^2)\n    )*(1+1/n))\n    ###\n    dtnew(x, df, location, scale)\n}\n\nx_interval = mu_pred_interval(windshieldy1, .999)\nlower_x = x_interval[1]\nupper_x = x_interval[2]\nx = seq(lower_x, upper_x, length.out=1000)\nplot(\n    x, mu_pred_pdf(windshieldy1, x), type=\"l\",\n    xlab=TeX(r'(new hardness observation $\\tilde{y}$)'),\n    ylab=TeX(r'(PDF of the posterior predictive $p(\\tilde{y}|y)$)')\n)\n\n\n\n\n\n\n\nFigure 2: PDF of the posterior predictive \\(p(\\tilde{y}|y)\\) of a new hardness observation \\(\\tilde{y}\\)\n\n\n\n\n\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code included?\n\nNo\nYes\n\nAre the likelihood, prior and the posterior for computing the average hardness value reported? It is ok to refer to the book instead of deriving the distributions.\n\nNo\nYes, but some are missing\nYes\n\nIn part a), were the point estimates and posterior interval provided? (The posterior mean should be close to )\n\nNo\nYes, but seem incorrect or only one estimate was reported\nYes, and the reported values seem plausible\n\nIn part b), was the density plotted?\n\nNo\nYes, but seem incorrect\nYes, and the plot seems plausible\n\nFor b)-part, was a formula or a simulation method presented for computing the posterior predictive distribution? It is ok to refer to the book.\n\nNo\nYes, but seems incorrect\nYes\n\nFor c)-part, were the point estimate and predictive interval provided? (95% predictive interval should be around and the mean the same as in a)-part).\n\nNo\nYes, but seems incorrect\nYes, and the reported values seem plausible\n\nFor c)-part, was the density plotted?\n\nNo\nYes, but seems incorrect\nYes, and the plot seem plausible\n\n\n\n\n\n\n3 Inference for the difference between proportions (3 points)\nAn experiment was performed to estimate the effect of beta-blockers on mortality of cardiac patients. A group of patients was randomly assigned to treatment and control groups: out of 674 patients receiving the control, 39 died, and out of 680 receiving the treatment, 22 died. Assume that the outcomes are independent and binomially distributed, with probabilities of death of \\(p_0\\) and \\(p_1\\) under the control and treatment, respectively. Set up a noninformative or weakly informative prior distribution on \\((p_0,p_1)\\).\n\n\n\n\n\n\nSubtask 3.a)\n\n\n\nFormulate\n\nthe likelihood,\nthe prior, and\nthe resulting posterior.\n\n\n\nWrite your answers here!\n\n\n\n\n\n\nSubtask 3.b)\n\n\n\nSummarize the posterior distribution for the odds ratio, \\[\n\\mathrm{OR} = (p_1/(1-p_1))/(p_0/(1-p_0)).\n\\]\n\nCompute and report the point estimate \\(E(\\mathrm{OR}|y_0,y_1)\\),\ncompute and report a posterior 95%-interval,\nplot the histogram, and\nwrite interpretation of the result in text.\n\nUse Frank Harrell’s recommendations how to state results in Bayesian two group comparison.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWith a conjugate prior, a closed-form posterior is the Beta form for each group separately (see equations in the book). You can use rbeta() to sample from the posterior distributions of \\(p_0\\) and \\(p_1\\), and use this sample and odds ratio equation to get a sample from the distribution of the odds ratio.\n\n\n\nWrite your answers and code here!\nThe below data is only for the tests:\n\nset.seed(4711)\nndraws = 1000\np0 = rbeta(ndraws, 5, 95)\np1 = rbeta(ndraws, 10, 90)\n### {.content-hidden when-profile=\"public\"}\nset.seed(4711)\np0 = rbeta(ndraws, 40, 675)\np1 = rbeta(ndraws, 23, 681)\n###\n\nKeep the below name and format for the functions to work with markmyassignment:\n\n# Useful function: mean(), quantile()\n\nposterior_odds_ratio_point_est &lt;- function(p0, p1) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    2.650172\n    ### {.content-hidden when-profile=\"public\"}\n    odds_ratios = p1/(1-p1)/(p0/(1-p0))\n    mean(odds_ratios)\n    ###\n}\nposterior_odds_ratio_interval &lt;- function(p0, p1, prob = 0.95) {\n    # Do computation here, and return as below.\n    # This is the correct return value for the test data provided above.\n    c(0.6796942,7.3015964)\n    ### {.content-hidden when-profile=\"public\"}\n    odds_ratios = p1/(1-p1)/(p0/(1-p0))\n    ql = (1-prob)/2\n    qu = prob + (1-prob)/2\n    quantile(odds_ratios, c(ql, qu))\n    ###\n}\n\n\n\n\n\n\n\nadvanced tools (posterior’s rvar, ggdist’s stat_dotsinterval)\n\n\n\n\n\nThe posterior package’s random variable datatype rvar is a “sample-based representation of random variables” which makes handling of random samples (of draws) such as the ones contained in the above variables p0 and p1 easier. By default, it prints as the mean and standard deviation of the draws, such that rvar(p0) prints as 0.056 ± 0.0086 and rvar(p1) prints as 0.033 ± 0.0066.\nThe datatype is “designed to […] be able to be used inside data.frame()s and tibble()s, and to be used with distribution visualizations in the ggdist package.” The code below sets up an R data.frame() with the draws in p0 and p1 wrapped in an rvar, and uses that data frame to visualize the draws using ggdist, an R package building on ggplot2 and “designed for both frequentist and Bayesian uncertainty visualization”.\nThe below plot, Figure 3 uses ggdist’s stat_dotsinterval(), which by default visualizes\n\nan rvar’s median and central 66% and 95% intervals using a black dot and lines of varying thicknesses as when using ggdist’s stat_pointinterval() and\nan rvar’s draws using grey dots as when using ggdist’s stat_dots():\n\n\nr0 = rvar(p0)\nr1 = rvar(p1)\nggplot(data.frame(\n    rv_name=c(\"control\", \"treatment\"), rv=c(r0, r1)\n)) +\n    aes(xdist=rv, y=rv_name) +\n    labs(x=\"probabilities of death\", y=\"patient group\") +\n    stat_dotsinterval()\n\n\n\n\n\n\n\nFigure 3: Probabilities of death for the two patient groups.\n\n\n\n\n\nrvars make it easy to compute functions of random variables, such as\n\ndifferences, e.g. \\(p_0 - p_1\\): r0 - r1 computes an rvar which prints as 0.023 ± 0.011, indicating the sample mean and the sample standard deviation of the difference of the probabilities of death,\nproducts, e.g. \\(p_0 \\, p_1\\): r0 * r1 computes an rvar which prints as 0.0018 ± 0.00048 which in this case has no great interpretation, or\nthe odds ratios needed in task 3.b).\n\nBelow, in Figure 4, we compute the odds ratios using the rvars and visualize its median, central intervals and draws, as above in Figure 3:\n\nrodds_ratio = (r1/(1-r1))/(r0/(1-r0))\nggplot(data.frame(\n    rv=c(rodds_ratio)\n)) +\n    aes(xdist=rv) +\n    labs(x=\"odds ratio\", y=\"relative amount of draws\") +\n    stat_dotsinterval()\n\n\n\n\n\n\n\nFigure 4: Odds ratios of the two patient groups.\n\n\n\n\n\nYou can use Figure 4 to visually check whether the answers you computed for 3.b) make sense.\n\n\n\n\n\n\n\n\n\nSubtask 3.c)\n\n\n\nUse at least two different priors, and discuss the sensitivity of your inference to your choice of prior density with a couple of sentences.\n\n\nWrite your answers and code here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs the source code included?\n\nNo\nYes\n\nAre the likelihood, prior and the posterior for the death probabilities reported? It is ok to refer to the book instead of deriving the distributions.\n\nNo\nYes, but some are missing\nYes\n\nIn part a), was the simulation algorithm for computing the posterior of the odds ratio presented or implemented?\n\nNo\nYes, but seems incorrect\nYes\n\nIn part a), was the odds ratio summarized with a point estimate and a posterior interval? (The mean should be close to )\n\nNo\nYes, but results seem incorrect\nYes, and the results seem plausible\n\nIn part b), was some discussion about testing alternative priors provided? (For example, one could have repeated the computations in a)-part with a couple of alternative priors and reported these results or some related general conclusions briefly)\n\nNot at all\nSome analysis was provided but it was lacking or did not make sense\nSome alternative priors were tested and some sensible discussion provided\n\n\n\n\n\n\n4 Inference for the difference between normal means (3 points)\nConsider a case where the same factory has two production lines for manufacturing car windshields. Independent samples from the two production lines were tested for hardness. The hardness measurements for the two samples \\(\\mathbf{y}_1\\) and \\(\\mathbf{y}_2\\) be found in the datasets windshieldy1 and windshieldy2 in the aaltobda package.\nWe assume that the samples have unknown standard deviations \\(\\sigma_1\\) and \\(\\sigma_2\\). Use uninformative or weakly informative priors and answer the following questions:\nLoading the library and the data.\n\ndata(\"windshieldy2\")\n# The new data are now stored in the variable `windshieldy2`.\n# The below displays the first few rows of the new data:\nhead(windshieldy2)\n\n[1] 15.980 14.206 16.011 17.250 15.993 15.722\n\n\n\n\n\n\n\n\nSubtask 4.a)\n\n\n\nFormulate\n\nthe likelihood,\nthe prior, and\nthe resulting posterior.\n\n\n\nWrite your answers here!\n\n\n\n\n\n\nSubtask 4.b)\n\n\n\nWhat can you say about \\(\\mu_d = \\mu_1 - \\mu_2\\)?\n\nCompute and report the point estimate \\(E(\\mu_d|y_1, y_2)\\),\ncompute and report a posterior 95%-interval,\nplot the histogram, and\nwrite interpretation of the result in text.\n\nUse Frank Harrell’s recommendations how to state results in Bayesian two group comparison.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWith a conjugate prior, a closed-form posterior is Student’s \\(t\\) form for each group separately (see equations in the book). You can use the rtnew() function to sample from the posterior distributions of \\(\\mu_1\\) and \\(\\mu_2\\), and use this sample to get a sample from the distribution of the difference \\(\\mu_d = \\mu_1 - \\mu_2\\).\n\n\n\nWrite your answers and code here!\n\n# Useful functions: mean(), length(), sqrt(), sum(),\n# rtnew() (from aaltobda), quantile() and hist().\n\n\n\n\n\n\n\nSubtask 4.c)\n\n\n\nGiven this specific model, what is the probability that the means are exactly the same (\\(\\mu_1 = \\mu_2\\))? Explain your reasoning.\n\n\nWrite your answers here!\n\n\n\n\n\n\nRubric\n\n\n\n\nIs source code included?\n\nNo\nYes\n\nAre the likelihood, prior and the posterior for the windshield hardness values reported? (It is also ok to refer to the book or related formulas from exercise 1)\n\nNo\nYes, but some are missing\nYes\n\nIn part a), was the simulation algorithm for computing the difference in the means presented or implemented?\n\nNo\nYes, but seems to be incorrect\nYes\n\nIn part a), was the posterior for the difference between the means summarized with point and interval estimates? (The mean should be close to or something close to it)\n\nNo answer\nYes, but results seem incorrect or only one estimate was given\nYes, and results seem reasonable\n\nWere some analysis or discussion provided for assessing whether the means could be the same?\n\nNo analysis or explanation is given\nYes, but the analysis or explanation seems incorrect\nYes, and the analysis or explanation seems plausible\n\n\n\n\n\n\n\n\n\n\nmarkmyassignment\n\n\n\n\n\nThe following will check the functions for which markmyassignment has been set up:\n\nmark_my_assignment()\n\nError: No assignment has been set. Please use set_assignment().\n\n\n\n\n\n\n\n5 Overall quality of the report\n\n\n\n\n\n\nRubric\n\n\n\n\nDoes the report include comment on whether AI was used, and if AI was used, explanation on how it was used?\n\nNo\nYes\n\nDoes the report follow the formatting instructions?\n\nNot at all\nLittle\nMostly\nYes\n\nIn case the report doesn’t fully follow the general and formatting instructions, specify the instructions that have not been followed. If applicable, specify the page of the report, where this difference is visible. This will help the other student to improve their reports so that they are easier to read and review. If applicable, specify the page of the report, where this difference in formatting is visible.\nPlease also provide feedback on the presentation (e.g. text, layout, flow of the responses, figures, figure captions). Part of the course is practicing making data analysis reports. By providing feedback on the report presentation, other students can learn what they can improve or what they already did well. You should be able to provide constructive or positive feedback for all non-empty and non-nonsense reports. If you think the report is perfect, and you can’t come up with any suggestions how to improve, you can provide feedback on what you liked and why you think some part of the report is better than yours.",
    "crumbs": [
      "Templates",
      "Assignment 3, 2023"
    ]
  }
]